<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ravi Kalia">
<meta name="dcterms.date" content="2025-04-09">
<meta name="description" content="Understanding the strengths, weaknesses, and appropriate use cases of various evaluation metrics in machine learning">

<title>Model Evaluation Metrics – Blog Directory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-86daaaaad7353f9cc0c554efc1dd6d94.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-da46e9beb7ca87c904339412541837e2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog Directory</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/project-delphi"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ravi-kalia-phd"> <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://project-delphi.github.io"> <i class="bi bi-house-fill" role="img" aria-label="LinkedIn">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Model Evaluation Metrics</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                  <div>
        <div class="description">
          Understanding the strengths, weaknesses, and appropriate use cases of various evaluation metrics in machine learning
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ravi Kalia </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 9, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#regression-metrics" id="toc-regression-metrics" class="nav-link" data-scroll-target="#regression-metrics">Regression Metrics</a>
  <ul class="collapse">
  <li><a href="#mean-squared-error-mse" id="toc-mean-squared-error-mse" class="nav-link" data-scroll-target="#mean-squared-error-mse">Mean Squared Error (MSE)</a></li>
  <li><a href="#root-mean-squared-error-rmse" id="toc-root-mean-squared-error-rmse" class="nav-link" data-scroll-target="#root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</a></li>
  <li><a href="#mean-absolute-error-mae" id="toc-mean-absolute-error-mae" class="nav-link" data-scroll-target="#mean-absolute-error-mae">Mean Absolute Error (MAE)</a></li>
  <li><a href="#r-squared-r²" id="toc-r-squared-r²" class="nav-link" data-scroll-target="#r-squared-r²">R-squared (R²)</a></li>
  </ul></li>
  <li><a href="#classification-metrics" id="toc-classification-metrics" class="nav-link" data-scroll-target="#classification-metrics">Classification Metrics</a>
  <ul class="collapse">
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy">Accuracy</a></li>
  <li><a href="#precision-and-recall" id="toc-precision-and-recall" class="nav-link" data-scroll-target="#precision-and-recall">Precision and Recall</a></li>
  <li><a href="#f1-score" id="toc-f1-score" class="nav-link" data-scroll-target="#f1-score">F1 Score</a></li>
  <li><a href="#roc-auc" id="toc-roc-auc" class="nav-link" data-scroll-target="#roc-auc">ROC-AUC</a></li>
  </ul></li>
  <li><a href="#specialized-metrics" id="toc-specialized-metrics" class="nav-link" data-scroll-target="#specialized-metrics">Specialized Metrics</a>
  <ul class="collapse">
  <li><a href="#log-loss-cross-entropy-loss" id="toc-log-loss-cross-entropy-loss" class="nav-link" data-scroll-target="#log-loss-cross-entropy-loss">Log Loss (Cross-Entropy Loss)</a></li>
  <li><a href="#mean-absolute-percentage-error-mape" id="toc-mean-absolute-percentage-error-mape" class="nav-link" data-scroll-target="#mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</a></li>
  </ul></li>
  <li><a href="#considerations-for-different-scenarios" id="toc-considerations-for-different-scenarios" class="nav-link" data-scroll-target="#considerations-for-different-scenarios">Considerations for Different Scenarios</a>
  <ul class="collapse">
  <li><a href="#class-imbalance" id="toc-class-imbalance" class="nav-link" data-scroll-target="#class-imbalance">Class Imbalance</a></li>
  <li><a href="#changing-variance" id="toc-changing-variance" class="nav-link" data-scroll-target="#changing-variance">Changing Variance</a></li>
  <li><a href="#multi-class-problems" id="toc-multi-class-problems" class="nav-link" data-scroll-target="#multi-class-problems">Multi-class Problems</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/project-delphi/ml-blog/edit/main/posts/evaluation-metrics/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Evaluation metrics are the cornerstone of machine learning model assessment. They help us quantify how well our models perform and make informed decisions about model selection and improvement. However, choosing the right metric is not always straightforward - different metrics have different strengths, weaknesses, and are appropriate for different scenarios.</p>
<p>In this post, we’ll explore various evaluation metrics across different types of machine learning tasks, discuss their mathematical foundations, and understand when to use each one.</p>
</section>
<section id="regression-metrics" class="level1">
<h1>Regression Metrics</h1>
<section id="mean-squared-error-mse" class="level2">
<h2 class="anchored" data-anchor-id="mean-squared-error-mse">Mean Squared Error (MSE)</h2>
<p>The Mean Squared Error is one of the most commonly used metrics for regression problems. It calculates the average of the squared differences between predicted and actual values.</p>
<div id="3e742b69" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example calculation</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">3</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">7</span>])</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.array([<span class="fl">2.5</span>, <span class="fl">0.0</span>, <span class="dv">2</span>, <span class="dv">8</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_true, y_pred)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MSE: 0.38</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Penalizes larger errors more heavily (due to squaring) - Differentiable, making it suitable for optimization - Mathematically convenient for analysis</p>
<p><strong>Cons:</strong> - Sensitive to outliers - Not in the same units as the target variable - Can be misleading when dealing with data of different scales</p>
</section>
<section id="root-mean-squared-error-rmse" class="level2">
<h2 class="anchored" data-anchor-id="root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</h2>
<p>RMSE is simply the square root of MSE, bringing the metric back to the original units of the target variable.</p>
<div id="91197dc9" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>RMSE: 0.61</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - In the same units as the target variable - Easier to interpret than MSE - Still penalizes larger errors</p>
<p><strong>Cons:</strong> - Still sensitive to outliers - Not as mathematically convenient as MSE</p>
</section>
<section id="mean-absolute-error-mae" class="level2">
<h2 class="anchored" data-anchor-id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h2>
<p>MAE calculates the average absolute difference between predicted and actual values.</p>
<div id="e1f6d31e" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_true, y_pred)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAE: </span><span class="sc">{</span>mae<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MAE: 0.50</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - More robust to outliers than MSE/RMSE - Easy to interpret - In the same units as the target variable</p>
<p><strong>Cons:</strong> - Less sensitive to large errors - Not differentiable at zero - May not penalize large errors enough in some applications</p>
</section>
<section id="r-squared-r²" class="level2">
<h2 class="anchored" data-anchor-id="r-squared-r²">R-squared (R²)</h2>
<p>R-squared measures the proportion of variance in the dependent variable that is predictable from the independent variables.</p>
<div id="05707b44" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_true, y_pred)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R²: </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>R²: 0.95</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Provides a relative measure of model performance - Scale-independent - Intuitive interpretation (percentage of variance explained)</p>
<p><strong>Cons:</strong> - Can be misleading with non-linear relationships - Can be artificially high with many features - Doesn’t indicate whether the model is appropriate</p>
</section>
</section>
<section id="classification-metrics" class="level1">
<h1>Classification Metrics</h1>
<section id="accuracy" class="level2">
<h2 class="anchored" data-anchor-id="accuracy">Accuracy</h2>
<p>Accuracy measures the proportion of correct predictions.</p>
<div id="7570089a" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_true, y_pred)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.75</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Simple to understand and interpret - Works well with balanced classes</p>
<p><strong>Cons:</strong> - Misleading with imbalanced classes - Doesn’t distinguish between types of errors - Not suitable for multi-class problems with varying class importance</p>
</section>
<section id="precision-and-recall" class="level2">
<h2 class="anchored" data-anchor-id="precision-and-recall">Precision and Recall</h2>
<p>Precision measures the proportion of positive predictions that are actually positive, while recall measures the proportion of actual positives that are correctly predicted.</p>
<div id="8645034d" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_true, y_pred)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_true, y_pred)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Precision: 1.00
Recall: 0.50</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - More informative than accuracy for imbalanced data - Can be tuned based on business requirements - Useful for different types of errors (false positives vs false negatives)</p>
<p><strong>Cons:</strong> - Need to choose between precision and recall - May not capture the full picture alone - Can be sensitive to threshold selection</p>
</section>
<section id="f1-score" class="level2">
<h2 class="anchored" data-anchor-id="f1-score">F1 Score</h2>
<p>The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both.</p>
<div id="353a9770" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_true, y_pred)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score: 0.67</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Balances precision and recall - Useful for imbalanced datasets - Single metric for comparison</p>
<p><strong>Cons:</strong> - May not be appropriate when precision and recall have different importance - Can be misleading with very imbalanced classes - Doesn’t consider true negatives</p>
</section>
<section id="roc-auc" class="level2">
<h2 class="anchored" data-anchor-id="roc-auc">ROC-AUC</h2>
<p>The Receiver Operating Characteristic Area Under Curve measures the ability of the model to distinguish between classes.</p>
<div id="4c41bd6c" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>y_scores <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.8</span>])</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_true, y_scores)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC-AUC: </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>ROC-AUC: 1.00</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Threshold-independent - Works well with imbalanced data - Provides a single number for model comparison</p>
<p><strong>Cons:</strong> - May not reflect actual business requirements - Can be misleading with very imbalanced classes - Doesn’t consider predicted probabilities directly</p>
</section>
</section>
<section id="specialized-metrics" class="level1">
<h1>Specialized Metrics</h1>
<section id="log-loss-cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="log-loss-cross-entropy-loss">Log Loss (Cross-Entropy Loss)</h2>
<p>Log loss measures the performance of a classification model where the prediction is a probability between 0 and 1.</p>
<div id="f84fc79d" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.8</span>])</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>logloss <span class="op">=</span> log_loss(y_true, y_pred_proba)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log Loss: </span><span class="sc">{</span>logloss<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Log Loss: 0.16</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Penalizes confident wrong predictions heavily - Works well with probabilistic predictions - Suitable for multi-class problems</p>
<p><strong>Cons:</strong> - Sensitive to predicted probabilities - Can be difficult to interpret - May be too harsh in some applications</p>
</section>
<section id="mean-absolute-percentage-error-mape" class="level2">
<h2 class="anchored" data-anchor-id="mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</h2>
<p>MAPE measures the average percentage difference between predicted and actual values.</p>
<div id="27d6f731" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_absolute_percentage_error(y_true, y_pred):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(np.<span class="bu">abs</span>((y_true <span class="op">-</span> y_pred) <span class="op">/</span> y_true)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> mean_absolute_percentage_error(y_true, y_pred)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAPE: </span><span class="sc">{</span>mape<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MAPE: nan%</code></pre>
</div>
</div>
<p><strong>Pros:</strong> - Easy to interpret as percentage error - Scale-independent - Useful for business communication</p>
<p><strong>Cons:</strong> - Undefined when actual values are zero - Can be misleading with small actual values - Asymmetric (penalizes over-prediction differently than under-prediction)</p>
</section>
</section>
<section id="considerations-for-different-scenarios" class="level1">
<h1>Considerations for Different Scenarios</h1>
<section id="class-imbalance" class="level2">
<h2 class="anchored" data-anchor-id="class-imbalance">Class Imbalance</h2>
<p>When dealing with imbalanced classes, certain metrics become more important:</p>
<ul>
<li>Precision and Recall become crucial</li>
<li>ROC-AUC can be misleading</li>
<li>F1 score or balanced accuracy might be better choices</li>
<li>Consider using class weights or sampling techniques</li>
</ul>
</section>
<section id="changing-variance" class="level2">
<h2 class="anchored" data-anchor-id="changing-variance">Changing Variance</h2>
<p>For data with non-constant variance:</p>
<ul>
<li>MSE/RMSE might be less appropriate</li>
<li>Consider weighted versions of metrics</li>
<li>Look into robust regression metrics</li>
<li>Consider transforming the target variable</li>
</ul>
</section>
<section id="multi-class-problems" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-problems">Multi-class Problems</h2>
<p>For multi-class classification:</p>
<ul>
<li>Micro/macro averaging of metrics</li>
<li>Confusion matrix becomes more important</li>
<li>Consider class-specific metrics</li>
<li>Weighted metrics based on class importance</li>
</ul>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Choosing the right evaluation metric is crucial for model assessment and should be based on:</p>
<ol type="1">
<li>The nature of the problem (regression vs classification)</li>
<li>The distribution of the data (balanced vs imbalanced)</li>
<li>Business requirements (cost of different types of errors)</li>
<li>The scale and variance of the target variable</li>
</ol>
<p>Remember that no single metric tells the whole story - it’s often valuable to look at multiple metrics and understand their trade-offs. Always consider the context and requirements of your specific problem when selecting evaluation metrics.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb21" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Model Evaluation Metrics"</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Understanding the strengths, weaknesses, and appropriate use cases of various evaluation metrics in machine learning"</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ravi Kalia"</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-04-09"</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-link: true</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: cosmo</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight-style: github</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>Evaluation metrics are the cornerstone of machine learning model assessment. They help us quantify how well our models perform and make informed decisions about model selection and improvement. However, choosing the right metric is not always straightforward - different metrics have different strengths, weaknesses, and are appropriate for different scenarios.</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>In this post, we'll explore various evaluation metrics across different types of machine learning tasks, discuss their mathematical foundations, and understand when to use each one.</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression Metrics</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mean Squared Error (MSE)</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>The Mean Squared Error is one of the most commonly used metrics for regression problems. It calculates the average of the squared differences between predicted and actual values.</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Example calculation</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">3</span>, <span class="op">-</span><span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">7</span>])</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.array([<span class="fl">2.5</span>, <span class="fl">0.0</span>, <span class="dv">2</span>, <span class="dv">8</span>])</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_true, y_pred)</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Penalizes larger errors more heavily (due to squaring)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Differentiable, making it suitable for optimization</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Mathematically convenient for analysis</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sensitive to outliers</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not in the same units as the target variable</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be misleading when dealing with data of different scales</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="fu">## Root Mean Squared Error (RMSE)</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>RMSE is simply the square root of MSE, bringing the metric back to the original units of the target variable.</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In the same units as the target variable</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Easier to interpret than MSE</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Still penalizes larger errors</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Still sensitive to outliers</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not as mathematically convenient as MSE</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mean Absolute Error (MAE)</span></span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>MAE calculates the average absolute difference between predicted and actual values.</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_true, y_pred)</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAE: </span><span class="sc">{</span>mae<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>More robust to outliers than MSE/RMSE</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Easy to interpret</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In the same units as the target variable</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Less sensitive to large errors</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not differentiable at zero</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May not penalize large errors enough in some applications</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-squared (R²)</span></span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>R-squared measures the proportion of variance in the dependent variable that is predictable from the independent variables.</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_true, y_pred)</span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R²: </span><span class="sc">{</span>r2<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Provides a relative measure of model performance</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Scale-independent</span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Intuitive interpretation (percentage of variance explained)</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be misleading with non-linear relationships</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be artificially high with many features</span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Doesn't indicate whether the model is appropriate</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification Metrics</span></span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a><span class="fu">## Accuracy</span></span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a>Accuracy measures the proportion of correct predictions.</span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_true, y_pred)</span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simple to understand and interpret</span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works well with balanced classes</span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Misleading with imbalanced classes</span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Doesn't distinguish between types of errors</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not suitable for multi-class problems with varying class importance</span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a><span class="fu">## Precision and Recall</span></span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a>Precision measures the proportion of positive predictions that are actually positive, while recall measures the proportion of actual positives that are correctly predicted.</span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score</span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_true, y_pred)</span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_true, y_pred)</span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>More informative than accuracy for imbalanced data</span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be tuned based on business requirements</span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Useful for different types of errors (false positives vs false negatives)</span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Need to choose between precision and recall</span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May not capture the full picture alone</span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be sensitive to threshold selection</span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a><span class="fu">## F1 Score</span></span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a>The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both.</span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-179"><a href="#cb21-179" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_true, y_pred)</span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-185"><a href="#cb21-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-186"><a href="#cb21-186" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-187"><a href="#cb21-187" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Balances precision and recall</span>
<span id="cb21-188"><a href="#cb21-188" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Useful for imbalanced datasets</span>
<span id="cb21-189"><a href="#cb21-189" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Single metric for comparison</span>
<span id="cb21-190"><a href="#cb21-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-191"><a href="#cb21-191" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-192"><a href="#cb21-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May not be appropriate when precision and recall have different importance</span>
<span id="cb21-193"><a href="#cb21-193" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be misleading with very imbalanced classes</span>
<span id="cb21-194"><a href="#cb21-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Doesn't consider true negatives</span>
<span id="cb21-195"><a href="#cb21-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-196"><a href="#cb21-196" aria-hidden="true" tabindex="-1"></a><span class="fu">## ROC-AUC</span></span>
<span id="cb21-197"><a href="#cb21-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-198"><a href="#cb21-198" aria-hidden="true" tabindex="-1"></a>The Receiver Operating Characteristic Area Under Curve measures the ability of the model to distinguish between classes.</span>
<span id="cb21-199"><a href="#cb21-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-202"><a href="#cb21-202" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-203"><a href="#cb21-203" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb21-204"><a href="#cb21-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-205"><a href="#cb21-205" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb21-206"><a href="#cb21-206" aria-hidden="true" tabindex="-1"></a>y_scores <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.8</span>])</span>
<span id="cb21-207"><a href="#cb21-207" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_true, y_scores)</span>
<span id="cb21-208"><a href="#cb21-208" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC-AUC: </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-209"><a href="#cb21-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-210"><a href="#cb21-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-211"><a href="#cb21-211" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-212"><a href="#cb21-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Threshold-independent</span>
<span id="cb21-213"><a href="#cb21-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works well with imbalanced data</span>
<span id="cb21-214"><a href="#cb21-214" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Provides a single number for model comparison</span>
<span id="cb21-215"><a href="#cb21-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-216"><a href="#cb21-216" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-217"><a href="#cb21-217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May not reflect actual business requirements</span>
<span id="cb21-218"><a href="#cb21-218" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be misleading with very imbalanced classes</span>
<span id="cb21-219"><a href="#cb21-219" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Doesn't consider predicted probabilities directly</span>
<span id="cb21-220"><a href="#cb21-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-221"><a href="#cb21-221" aria-hidden="true" tabindex="-1"></a><span class="fu"># Specialized Metrics</span></span>
<span id="cb21-222"><a href="#cb21-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-223"><a href="#cb21-223" aria-hidden="true" tabindex="-1"></a><span class="fu">## Log Loss (Cross-Entropy Loss)</span></span>
<span id="cb21-224"><a href="#cb21-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-225"><a href="#cb21-225" aria-hidden="true" tabindex="-1"></a>Log loss measures the performance of a classification model where the prediction is a probability between 0 and 1.</span>
<span id="cb21-226"><a href="#cb21-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-229"><a href="#cb21-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-230"><a href="#cb21-230" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb21-231"><a href="#cb21-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-232"><a href="#cb21-232" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb21-233"><a href="#cb21-233" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.8</span>])</span>
<span id="cb21-234"><a href="#cb21-234" aria-hidden="true" tabindex="-1"></a>logloss <span class="op">=</span> log_loss(y_true, y_pred_proba)</span>
<span id="cb21-235"><a href="#cb21-235" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log Loss: </span><span class="sc">{</span>logloss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-236"><a href="#cb21-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-237"><a href="#cb21-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-238"><a href="#cb21-238" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-239"><a href="#cb21-239" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Penalizes confident wrong predictions heavily</span>
<span id="cb21-240"><a href="#cb21-240" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works well with probabilistic predictions</span>
<span id="cb21-241"><a href="#cb21-241" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suitable for multi-class problems</span>
<span id="cb21-242"><a href="#cb21-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-243"><a href="#cb21-243" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-244"><a href="#cb21-244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sensitive to predicted probabilities</span>
<span id="cb21-245"><a href="#cb21-245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be difficult to interpret</span>
<span id="cb21-246"><a href="#cb21-246" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May be too harsh in some applications</span>
<span id="cb21-247"><a href="#cb21-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-248"><a href="#cb21-248" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mean Absolute Percentage Error (MAPE)</span></span>
<span id="cb21-249"><a href="#cb21-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-250"><a href="#cb21-250" aria-hidden="true" tabindex="-1"></a>MAPE measures the average percentage difference between predicted and actual values.</span>
<span id="cb21-251"><a href="#cb21-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-254"><a href="#cb21-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-255"><a href="#cb21-255" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_absolute_percentage_error(y_true, y_pred):</span>
<span id="cb21-256"><a href="#cb21-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(np.<span class="bu">abs</span>((y_true <span class="op">-</span> y_pred) <span class="op">/</span> y_true)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb21-257"><a href="#cb21-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-258"><a href="#cb21-258" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> mean_absolute_percentage_error(y_true, y_pred)</span>
<span id="cb21-259"><a href="#cb21-259" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAPE: </span><span class="sc">{</span>mape<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb21-260"><a href="#cb21-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-261"><a href="#cb21-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-262"><a href="#cb21-262" aria-hidden="true" tabindex="-1"></a>**Pros:**</span>
<span id="cb21-263"><a href="#cb21-263" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Easy to interpret as percentage error</span>
<span id="cb21-264"><a href="#cb21-264" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Scale-independent</span>
<span id="cb21-265"><a href="#cb21-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Useful for business communication</span>
<span id="cb21-266"><a href="#cb21-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-267"><a href="#cb21-267" aria-hidden="true" tabindex="-1"></a>**Cons:**</span>
<span id="cb21-268"><a href="#cb21-268" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Undefined when actual values are zero</span>
<span id="cb21-269"><a href="#cb21-269" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can be misleading with small actual values</span>
<span id="cb21-270"><a href="#cb21-270" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Asymmetric (penalizes over-prediction differently than under-prediction)</span>
<span id="cb21-271"><a href="#cb21-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-272"><a href="#cb21-272" aria-hidden="true" tabindex="-1"></a><span class="fu"># Considerations for Different Scenarios</span></span>
<span id="cb21-273"><a href="#cb21-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-274"><a href="#cb21-274" aria-hidden="true" tabindex="-1"></a><span class="fu">## Class Imbalance</span></span>
<span id="cb21-275"><a href="#cb21-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-276"><a href="#cb21-276" aria-hidden="true" tabindex="-1"></a>When dealing with imbalanced classes, certain metrics become more important:</span>
<span id="cb21-277"><a href="#cb21-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-278"><a href="#cb21-278" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Precision and Recall become crucial</span>
<span id="cb21-279"><a href="#cb21-279" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ROC-AUC can be misleading</span>
<span id="cb21-280"><a href="#cb21-280" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>F1 score or balanced accuracy might be better choices</span>
<span id="cb21-281"><a href="#cb21-281" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Consider using class weights or sampling techniques</span>
<span id="cb21-282"><a href="#cb21-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-283"><a href="#cb21-283" aria-hidden="true" tabindex="-1"></a><span class="fu">## Changing Variance</span></span>
<span id="cb21-284"><a href="#cb21-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-285"><a href="#cb21-285" aria-hidden="true" tabindex="-1"></a>For data with non-constant variance:</span>
<span id="cb21-286"><a href="#cb21-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-287"><a href="#cb21-287" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>MSE/RMSE might be less appropriate</span>
<span id="cb21-288"><a href="#cb21-288" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Consider weighted versions of metrics</span>
<span id="cb21-289"><a href="#cb21-289" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Look into robust regression metrics</span>
<span id="cb21-290"><a href="#cb21-290" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Consider transforming the target variable</span>
<span id="cb21-291"><a href="#cb21-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-292"><a href="#cb21-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-class Problems</span></span>
<span id="cb21-293"><a href="#cb21-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-294"><a href="#cb21-294" aria-hidden="true" tabindex="-1"></a>For multi-class classification:</span>
<span id="cb21-295"><a href="#cb21-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-296"><a href="#cb21-296" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Micro/macro averaging of metrics</span>
<span id="cb21-297"><a href="#cb21-297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Confusion matrix becomes more important</span>
<span id="cb21-298"><a href="#cb21-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Consider class-specific metrics</span>
<span id="cb21-299"><a href="#cb21-299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Weighted metrics based on class importance</span>
<span id="cb21-300"><a href="#cb21-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-301"><a href="#cb21-301" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb21-302"><a href="#cb21-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-303"><a href="#cb21-303" aria-hidden="true" tabindex="-1"></a>Choosing the right evaluation metric is crucial for model assessment and should be based on:</span>
<span id="cb21-304"><a href="#cb21-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-305"><a href="#cb21-305" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The nature of the problem (regression vs classification)</span>
<span id="cb21-306"><a href="#cb21-306" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The distribution of the data (balanced vs imbalanced)</span>
<span id="cb21-307"><a href="#cb21-307" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Business requirements (cost of different types of errors)</span>
<span id="cb21-308"><a href="#cb21-308" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>The scale and variance of the target variable</span>
<span id="cb21-309"><a href="#cb21-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-310"><a href="#cb21-310" aria-hidden="true" tabindex="-1"></a>Remember that no single metric tells the whole story - it's often valuable to look at multiple metrics and understand their trade-offs. Always consider the context and requirements of your specific problem when selecting evaluation metrics. </span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/project-delphi/ml-blog/edit/main/posts/evaluation-metrics/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>