[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code and Plot",
    "section": "",
    "text": "Let‚Äôs see if blogging with code and plots works here:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(0, 10, 100)\n\nfig = plt.figure()\nplt.plot(x, np.sin(x), '-')\nplt.plot(x, np.cos(x), '--')\n\n\n\n\n\n\n\n\n\n\nkindly taken from Jake Vanderplas‚Äôs blog\n\nSuccess!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Synthetic Musings",
    "section": "",
    "text": "Featured Writing\n\n\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nSep 20, 2024\n\n\nTrain Dev Test Data Splits\n\n\n9 min\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nModel Speciation\n\n\n7 min\n\n\n\n\n\n\n\nApr 22, 2024\n\n\nGit Repository Search\n\n\n5 min\n\n\n\n\n\n\n\nApr 11, 2024\n\n\nSparsity with PyTorch Tensors\n\n\n9 min\n\n\n\n\n\n\n\nMar 3, 2024\n\n\nDeveloping Pytorch Geometric on M1 Apple Silicon\n\n\n7 min\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nPost With Code and Plot\n\n\n1 min\n\n\n\n\n\n\n\nFeb 6, 2024\n\n\nWelcome To Synthetic Musings\n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/model-speciation/index.html",
    "href": "posts/model-speciation/index.html",
    "title": "Model Speciation",
    "section": "",
    "text": "Made with ‚ù§Ô∏è and GitHub Copilot"
  },
  {
    "objectID": "posts/model-speciation/index.html#tldr-machine-learning-model-selection-as-evolution",
    "href": "posts/model-speciation/index.html#tldr-machine-learning-model-selection-as-evolution",
    "title": "Model Speciation",
    "section": "TL;DR: Machine Learning Model Selection as Evolution",
    "text": "TL;DR: Machine Learning Model Selection as Evolution\nViewing machine learning through the lens of evolution:\n\nProto-programs = protocells: Basic building blocks of ML algorithms, like affine transformations, recursion, iteration, object templates; small modular reusable code pieces represent the ‚Äúsimplest forms of life.‚Äù\nModels = Species: Each ML model (e.g., linear regression, neural networks) represents a distinct ‚Äúspecies‚Äù in the ecosystem.\nData = Environment: The dataset shapes and tests models just as environments influence species‚Äô survival and adaptation.\nTraining = Maturation: During training, models learn and become more capable to fit and predict their data environment.\nHyperparameter tuning = Sub-speciation: Tuning hyperparameters is akin to the development of sub-species, where small variations emerge for optimization.\nModel selection = Survival of the fittest: Only the best-performing hyperparameter tuned (sub-species) models that can generalize to a an unseen environment (validation data) ‚Äúsurvive‚Äù and are selected for deployment.\n\nThis evolutionary perspective on model selection suggests that phylogenetics ‚Äî the study of evolutionary relationships - could offer novel insights into understanding and categorizing machine learning model families, possibly even for generating novel models."
  },
  {
    "objectID": "posts/model-speciation/index.html#the-evolutionary-analogy",
    "href": "posts/model-speciation/index.html#the-evolutionary-analogy",
    "title": "Model Speciation",
    "section": "The Evolutionary Analogy",
    "text": "The Evolutionary Analogy\nIn the world of machine learning, the process of selecting and refining models can be complex and nuanced. To better understand this process, let‚Äôs draw an analogy to biological evolution. This comparison can provide an intuitive framework for grasping the key concepts of model selection and optimization.\n\nProto-programs as protocells\nSimple programs or algorithms can be seen as the building blocks of more complex models. These proto-programs are like protocells in nature, capable of basic functions but not yet fully adapted to their environment.\nThese would be the building blocks of more complex models, like the simplest organisms in nature, capable of basic functions but not yet fully adapted to their environment. Examples might be:\n\nTensor arithmetic\nBranching logic\nBasic object templates\nEncapsulation\nRecursion\n\nThey combine to form more complex species, such as models - templates for a ML algorithm is run.\n\n\nModels as Species\nJust as the natural world is populated by various species, the realm of machine learning is filled with different types of models. Each model type, like a species, has its own characteristics, strengths, and weaknesses. These models depend on receiving data and hyper-parameters, then learning parameters which mature to enable learned prediction function.\n\n\nModel Instances as Complex Organisms\nWithin each model type (species), we can create multiple instances. These instances are akin to individual organisms within a species. Each has its own set of parameters, just as organisms have their own genetic makeup.\n\n\nData as the Environment\nThe data we use to train and evaluate our models serves as the environment in which our ‚Äúmodel organisms‚Äù must survive and thrive. Different datasets present different resources and challenges, much like varied ecological niches in nature.\n\n\nTraining as Maturation\nThe process of training a model is analogous to the maturation of an organism. Through repeated exposure to the training data (environment), the model adjusts its parameters and improves its performance, much like an organism adapting to its surroundings as it grows. Once mature, these species gain the ability to predict unseen data.\nHowever if they are over matured, then they may memorize the training environment data and fail to generalize to unseen validation environment. This would render them unfit for survival in the validation environment.\n\n\nScore Function as Survival Fitness\nIn nature, organisms that are better adapted to their environment are more likely to survive. Similarly, in machine learning, we use a score function to evaluate how well a model performs. Models with better scores are more likely to be selected for further use or refinement.\nThe score function does not depend on the model itself, but on the model‚Äôs predictions vs observed reality relevant to some task of interest for a given the validation data environment. This is similar to how an organism‚Äôs fitness is determined by its ability to survive in its habitat.\nThere are many different score functions, each of which can be seen as a different measure of fitness at a task for a model in a given environment.\n\n\nHyperparameters as Creating Subspecies\nWhen we select the hyperparameters of a model, we‚Äôre essentially creating a subspecies of the main model species. These subspecies share the basic characteristics of the base model species but have unique traits that may make them better suited to certain types of tasks given the model family and data environment.\n\n\n\n‚ÄúDarwin‚Äôs Finches: Speciation‚Äù\n\n\nDarwin‚Äôs Finches from Wikipedia by John Gould\nHere‚Äôs an analogy from evolution. Darwin‚Äôs finches evolved from a common ancestor to adapt to different food sources on the Galapagos Islands. They all go through a maturation phase, but become specialized to their particular validation environment. Similarly, hyperparameters are like the genetic variations that allow models to adapt to different data environments.\nDefault hyperparameters are like the default genetic code of an organism, expected to do reasonably well in most common environments, while tuned hyperparameters are like genetic mutations that have performed well in the validation (data) environment.\n\n\nData Splitting as Creating Different Habitats\nThe practice of splitting our data into training, validation, and test sets is akin to creating different habitats for our models:\n\nTraining Data: This is the primary environment where our model ‚Äúorganisms‚Äù mature and adapt.\nValidation Data: This represents a similar but distinct habitat where we score each model‚Äôs fitness, the best model selected to survive for downstream use.\nTest Data: This is an unseen habitat to report unbiased fitness estimate of the selected model subspecies.\n\n\n\nBest Scored Model as Natural Selection\nThe process of selecting the best-performing model based on validation scores mirrors natural selection. The model that best adapts to both the training and validation environments is chosen to proceed to the test phase, much like the fittest organisms in nature are more likely to survive and change their environment."
  },
  {
    "objectID": "posts/model-speciation/index.html#implications-of-the-evolutionary-perspective",
    "href": "posts/model-speciation/index.html#implications-of-the-evolutionary-perspective",
    "title": "Model Speciation",
    "section": "Implications of the Evolutionary Perspective",
    "text": "Implications of the Evolutionary Perspective\nViewing model selection through this evolutionary lens can provide several insights:\n\nDiversity is Valuable: Just as biodiversity is crucial in ecosystems, having a diverse set of models can be beneficial in machine learning. We just don‚Äôt know a priori which model will be the best for a given dataset.\nScoring is Key: The best model or model subspecies for one dataset may not be the best for another, just as organisms adapted to one environment may struggle in a different one.\nOverfitting as Over-specialization: When a model performs well on training data but poorly on validation data, it‚Äôs like an organism that‚Äôs over-specialized for a very specific data environment and can‚Äôt adapt to realistic changes in data.\nEnsemble Methods as Ecosystems: Ensemble methods, which combine multiple models, can be seen as creating a balanced ecosystem where different ‚Äúspecies‚Äù of models cooperate to solve a problem.\nContinuous Improvement: The field of machine learning, like the process of evolution, is one of continuous adaptation and improvement as we develop new models and techniques."
  },
  {
    "objectID": "posts/model-speciation/index.html#conclusion",
    "href": "posts/model-speciation/index.html#conclusion",
    "title": "Model Speciation",
    "section": "Conclusion",
    "text": "Conclusion\nWhile the analogy between model selection and biological evolution isn‚Äôt perfect, it provides a rich metaphor for understanding many aspects of the machine learning process. By thinking in these terms, we can gain new insights into how to approach model selection, hyperparameter tuning, and the overall process of developing effective machine learning solutions.\nIt would be an interesting exercise to create a phylogenetic tree of models, showing how different models have evolved from simpler proto-programs and how they have adapted to different data environments over time. This could provide a fascinating perspective on the history and development of machine learning algorithms. Perhaps even find horizontal gene transfer between models, where ideas from one model are incorporated directly into another.\nFrom this perspective, geometric learning relates to encoding data regularities into model species internals, another way to view the inductive bias of a model.\nAs a practical takeaway, expect that there is no perfect single model for all datasets and tasks, the best model is the one that is best adapted to the specific data environment at hand, while being able to generalize to similar environments."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "",
    "text": "TLDR: My investigation indicates that the library pytorch geometric (also referred to as pyg, using package name torch_geometric) on Apple Silicon (AS) - particularly the M1 chip - has partial developer support.\nA bit more: It is now feasible to perform a full developer installation of torch_geometric using PyTorch on AS with Apple‚Äôs native GPU compute framework, Metal Performance Shaders - mps - (which includes its own kind of embedded BLAS). The only remaining challenge is testing with a developer installation. The test suite does not currently build for AS.\nI‚Äôve been talking with the pyg-team and they are interested in supporting AS more fully. It‚Äôs a matter of time and resources. rusty1s (the lead developer) has been very helpful and responsive, adding a test runner for Apple Silicon."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#user-installation",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#user-installation",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "User Installation",
    "text": "User Installation\nThe installation of the package as a user, utilizing a wheels distribution, is generally straightforward across most CPU/GPU architectures, including AS. Here are the steps:\n\nCheck for conda, install if missing.\nEstablish a clean Python virtual environment.\nActivate the newly created virtual environment.\nInstall the latest version of PyTorch.\nProceed with the installation of PyTorch Geometric.\nCheck that it imports without errors.\n\nThere‚Äôs a gist of what worked for me. The cell below uses the %load magic command to load the bash script into the code cell, followed by running it with insertion of the %%bash magic command at the top of the code block.\n\n%%bash\n\n# %load https://gist.githubusercontent.com/project-delphi/38d1db47ed28dde3c8418d5f435c865c/raw/665c079a1f6eff72207309ed97dd6b49194df812/pyg_user_install.sh\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-user-install\"\nPYTHON_VERSION=3.11\nRECENT_TORCH_VERSION=2.2.0\n\n# install miniconda for apple silicon, if not already installed\nif [ -d \"$HOME/anaconda3\" ] || [ -d \"$HOME/miniconda3\" ]\nthen\n    echo \"Conda is installed\"\nelse\n    curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n    sh Miniconda3-latest-MacOSX-arm64.sh -b -u  &gt; /dev/null 2&gt;&1\nfi\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nconda create --yes  -p $DIR/.venv python=$PYTHON_VERSION &gt; /dev/null 2&gt;&1\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\npip install -q --upgrade pip\n\n##### TORCH BUILD AND INSTALL ON M1, to use GPUs #####\npip install -q numpy # to remove user warning with torch install\npip install -q mpmath==1.3.0 # bugfix\nxcode-select --install  &gt; /dev/null 2&gt;&1 # if xcode not installed\n\n###### install torch ######\npip install -q --pre torch==$RECENT_TORCH_VERSION torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu \n\n# install torch geometric\npip install -q torch-geometric\n\n# check\npython --version\npython -c \"import torch; print(f'torch version: {torch.__version__}')\"\npython -c \"import torch_geometric as pyg; print(f'torch geometric version: {pyg.__version__}')\"\n\nConda is installed\nPython 3.11.8\ntorch version: 2.2.0\ntorch geometric version: 2.5.1\n\n\nWhich is great for using torch_geometric on my M1 Pro.\nThe problem is that I want to develop (and not just use) locally - that is to have an editable local install on my 2021 16 inch Macbook Pro M1 Pro. Sadly the M1 architecture does not have official support by pyg-team üòî (I suspect the issues observed also apply to later Apple Silicon too.)\nLet‚Äôs see how far we can get with the installation process."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#developer-installation",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#developer-installation",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "Developer Installation",
    "text": "Developer Installation\n\nNon Apple Silicon Machines\nFrom the project contributing guidelines, the instructions are clear.\n\nInstall a recent version of PyTorch\nOptionally install some dependencies if changes make use of them\nBe sure to uninstall the pytorch_geometric package\nClone the repo\nRun an editable install command for the repo\nRun pytest: local testing is kind of essential for a developer install.\n\nDevelop away - (as long as it‚Äôs a supported architecture).\n\n\nM1, Possibly All Apple Silicon\nThis M1 hardware problem for developers has been noted.\nFor developers, if feature development on pytorch_geometric makes use of the listed package dependencies, several M1/AS issues have been raised.\n\npyg-lib\npytorch scatter\npytorch sparse\npytorch cluster\n\n(It‚Äôs likely that the package torch-spline-conv, another package dependency, is also an issue for M1/AS users - though no issues mentioning this are given.)\nThese dependencies are being subsumed into other packages (for example torch.scatter); at some point they won‚Äôt be a problem.\n\nWhy is Apple Silicon a Problem?\nTo develop locally, I need a an editable install version of pytorch geometric. This editable install needs additional dependencies (for fuller developer functionality such as testing, type checking, compiling, linting and documentation) some of which depend on C++ extensions which are not compiled for the M1/AS architecture. The project founder (@rusty1s) has noted that M1 was not supported from the onset - when it wasn‚Äôt available on github actions, and there are no plans to support it now. Later Apple Silicon is supported, but developer build are variable.\n\n\nThe Solution\npyg-team suggested earlier that M1 users wanting the fuller editable version of the package can use the cmake & ninja build systems to create libraries and dependencies that target M1 - this will give a working modifiable install of pytorch geometric. Some OS and compiler flags need to be set.\nLet‚Äôs see if I can do this and get a development environment setup.\nWhat I‚Äôll do is as follows:\n\ncheck the OS & Hardware\nmake sure to uninstall all versions of pytorch geometric for all locations.\ncreate and activate a clean Python virtual environment (seems that conda is the best way to go)\ninstall a specific version of PyTorch using conda, as recommended by Apple\nbuild dependencies for clang and macos on my M1 Pro\nbuild the editable install\n\n\nOS and Hardware\nLet‚Äôs start by listing my hardware:\n\n%%bash\necho \"Operating System: $(uname -s)\"\necho \"Hardware: $(uname -m)\"\necho \"macOS Version: $(sw_vers -productVersion)\"\necho \"Chipset: $(sysctl -n machdep.cpu.brand_string)\"\n\nOperating System: Darwin\nHardware: arm64\nmacOS Version: 14.4\nChipset: Apple M1 Pro\n\n\n\n\nEditable Developer Install\nI‚Äôve put this gist together from responses in github issues raised relating to AS. It installs, but doesn‚Äôt pass all tests - it seems because the tests are composed from objects that don‚Äôt work well with Apple Silicon, rather than anything fundamentally broken in AS.\n\n%%bash\n# %load https://gist.githubusercontent.com/project-delphi/b3b5cc91386997ff882f0a3f04a4b89a/raw/6146ec6cf950c2eeb184e0da3e59ff6fdd69550a/pytorch_geometric_apple_silicon_developer_install.sh\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-developer-install\"\nPYTHON_VERSION=3.11\nRECENT_TORCH_VERSION=2.2.0\nGITHUB_USERNAME=\"project-delphi\"\nMIN_MACOSX_DEPLOYMENT_TARGET=$(sw_vers -productVersion)\n\n# install miniconda for apple silicon, if not already installed\nif [ ! -d \"$HOME/anaconda3\" ] && [ ! -d \"$HOME/miniconda3\" ]\nthen\n    echo \"installing conda...\"\n    curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n    sh Miniconda3-latest-MacOSX-arm64.sh -b -u  &gt; /dev/null 2&gt;&1\nfi\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nconda create --yes  -p $DIR/.venv python=$PYTHON_VERSION  &gt; /dev/null 2&gt;&1\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\n\npip install -q --upgrade pip\n\n##### TORCH BUILD AND INSTALL ON M1, to use GPUs #####\npip install -q numpy # to remove user warning with torch install\npip install -q mpmath==1.3.0 # bugfix\nxcode-select --install  &gt; /dev/null 2&gt;&1 # if xcode not installed\n\n###### install pytorch ######\npip install -q --pre torch==$RECENT_TORCH_VERSION torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n\n# install dev build dependencies\npip install -q cmake\npip install -q ninja wheel\npip install -q git+https://github.com/pyg-team/pyg-lib.git\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-scatter\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-sparse\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-cluster\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-spline-conv\n\n# clone the forked repository and rebase to original\ngit clone \"https://github.com/$GITHUB_USERNAME/pytorch_geometric.git\"  2&gt;/dev/null\ncd pytorch_geometric\nif ! git remote | grep -q 'upstream'; then\n    git remote add upstream \"https://github.com/pyg-team/pytorch_geometric\"\nfi\ngit fetch upstream  -q\ngit rebase upstream/master\n\n# build dev install\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip install -q --no-cache-dir -e \".[dev,full]\"  #&gt; /dev/null 2&gt;&1\n\n# check\npython --version\npython -c \"import torch; print(f'torch version: {torch.__version__}')\"\npython -c \"import torch_geometric as pyg; print(f'torch geometric version: {pyg.__version__}')\"\n\nSo a kind of success. I can install a full developer version pytorch_geometric on my M1 Pro.\nHowever, we also need to check regarding testing (of which there are several undocumented flavours in the project).\nFor the standard set of tests, today I get this:\n\n%%bash\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-developer-install\"\ncd \"$DIR\"\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\n# install missing packages needed for testing\npip install -q matplotlib-inline ipython\npytest -q --tb=no | tail -n 1\n\nFatal Python error: Segmentation fault\n\nCurrent thread 0x00000001f82fbac0 (most recent call first):\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/torch/_ops.py\", line 755 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pyg_lib/partition/__init__.py\", line 35 in metis\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/torch_geometric/testing/decorators.py\", line 224 in withMETIS\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/test/distributed/test_dist_link_neighbor_loader.py\", line 140 in &lt;module&gt;\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py\", line 178 in exec_module\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 690 in _load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1147 in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1176 in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1204 in _gcd_import\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/importlib/__init__.py\", line 126 in import_module\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/pathlib.py\", line 584 in import_path\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 520 in importtestmodule\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 573 in _getobj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 315 in obj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 589 in _register_setup_module_fixture\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 576 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 388 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 340 in from_call\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 390 in pytest_make_collect_report\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 565 in collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 839 in _collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 976 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 813 in perform_collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 349 in pytest_collection\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 338 in _main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 285 in wrap_session\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 332 in pytest_cmdline_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 174 in main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 197 in console_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/bin/pytest\", line 8 in &lt;module&gt;\n\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._flinalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, scipy.cluster._vq, scipy.cluster._hierarchy, scipy.cluster._optimal_leaf_ordering, yaml._yaml, numba.core.typeconv._typeconv, numba._helperlib, numba._dynfunc, numba._dispatcher, numba.core.runtime._nrt_python, numba.np.ufunc._internal, numba.experimental.jitclass._box, psutil._psutil_osx, psutil._psutil_posix, markupsafe._speedups, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, matplotlib._c_internal_utils, PIL._imaging, matplotlib._path, kiwisolver._cext, matplotlib._image, rdkit.rdBase (total: 116)\n\n\nA week ago I noticed that the tests were failing, and then a few days ago they were passing. Today they are not passing, due to new tests. This is caused by commit updates which don‚Äôt test on Apple Silicon.\nThis inconsistency is a problem for contributing to the project. As mentioned, @rusty1s has committed changes to the tests which accommodate Apple Silicon using his own device - but this is not a sustainable approach.\nThere‚Äôs not a good solution to variable pytest runs, since feature updates (commits) to the main line branch ‚Äì which don‚Äôt build for Apple Silicon ‚Äì are likely to break some test at least some of the time.\nIn some issues, @rusty1s mentioned a community effort to help test Apple Silicon builds, specifically the M1 architecture. I‚Äôd like to contribute, it‚Äôs just figuring out how to do so for the long term.\nElse, the path of least resistance is to move to the cloud - I‚Äôve recently received cloud credit from major providers."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#more-on-testing",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#more-on-testing",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "More On Testing",
    "text": "More On Testing\nThese test related issues are not unique to the default testing for the package. The package has several kinds of tests, including: full, gpu, previous version, and nightly.\nI looked over the github actions workflows, I noticed that full testing and gpu testing are not set up for apple silicon and also have to install undeclared dependencies, such as graphviz and bugfix pinned versions of packages (e.g.¬†mpmath==1.3.0). These minor issues could be useful to work on - even with current default testing this seems to be the case.\nI‚Äôm thinking of a Makefile to compose the different installation and testing steps into higher level portable grammars. This would be useful for the community, and also for me to use in the future.\nUpdate, @rusty1s suggested more specific testing for mps (and by implication AS), starting with test decorators. That and test documentation could be a good place to start."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#references",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#references",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "References",
    "text": "References\n\npytorch on Apple Metal\npyg-lib M1 issues\npytorch-scatter M1 issue\npytorch-spars M1 issues\npytorch-cluster M1 issues"
  },
  {
    "objectID": "posts/git-search/index.html",
    "href": "posts/git-search/index.html",
    "title": "Git Repository Search",
    "section": "",
    "text": "‚ÄúRobot Magnifying Glass Search‚Äù\n\n\nPhoto by Growtika on Unsplash\nThere are many ways to search a repository, particularly a Git Repo. We will outline some use cases with examples for a ‚ÄúUnix-like‚Äù file directory and also a Git Repo.\nLet‚Äôs do this for a library I‚Äôve been looking at.\nSome unit tests break on Apple Silicon for the open source library pyg. The maintainer disabled some tests. I want to find them. It has something to do with PyTorch not fully supporting compressed sparse tensor representations on Apple‚Äôs mps framework for Apple Silicon. I received the following note:\n\nthere are a few tests that were disabled around test_sparse\n\nand\n\nthe convert_coo_to_csr_indices doesn‚Äôt seem to be supported.\n\nIt‚Äôs likely that test_sparse and convert_coo_to_csr_indices are variable names or tokens inside a code file of the git repository. However, for illustration, we will assume that they could be anywhere in the git repo (filenames, directory names, commit messages, variable names, past commits, current directory).\nThe objective is to find (and then later fix bugs) related to these strings. So find the strings in filenames and/or inside contents of filenames (line numbers of specific files), checking through commit history for occurences of the strings.\nTime to search. The repo can be cloned locally from here and then cd into it.\n\n\nCode\nimport os\n\nos.chdir(\"/Users/ravikalia/Code/github.com/ml-blog/posts/git-search/\")\n\n\n\n\nCode\nprint(os.getcwd())\n\n\n/Users/ravikalia/Code/github.com/ml-blog/posts/git-search\n\n\n\n\nCode\n%%bash\nif [ -d \"pytorch_geometric\" ]; then\n    rm -rf pytorch_geometric\nfi\ngit clone https://github.com/pyg-team/pytorch_geometric.git\ngit -C pytorch_geometric fetch --all\n\n\nCloning into 'pytorch_geometric'...\n\n\nLet‚Äôs change the directory to the root of the cloned repo, which makes searching easier\n\n\nCode\nos.chdir(\"./pytorch_geometric\")\n\n\n\n\nWe can look for the string test_sparse in filenames using the shell command line tool find.\n\n\nCode\n%%bash\nfind . -name \"*test_sparse*\" -o -name \"*convert_coo_to_csr_indices*\"\n\n\n./test/utils/test_sparse.py\n\n\ngreat, so we have a file to look at. Let‚Äôs look at the file test_sparse.py. It seems to be unit tests related to sparsity, possibly testing utility functions for converting between sparse tensor representations.\n\n\n\nString search is a bit more complicated. grep is an awesome tool for this.\n\n\nCode\n%%bash\ngrep -rn . -e \"test_sparse\" -e \"convert_coo_to_csr_indices\"\n\n\n./test/utils/test_cross_entropy.py:9:def test_sparse_cross_entropy_multiclass(with_edge_label_weight):\n./test/utils/test_cross_entropy.py:32:def test_sparse_cross_entropy_multilabel(with_edge_label_weight):\n./test/test_edge_index.py:102:def test_sparse_tensor(dtype, device):\n./test/test_edge_index.py:992:def test_sparse_narrow(device):\n./test/test_edge_index.py:1026:def test_sparse_resize(device):\n./torch_geometric/testing/asserts.py:24:    test_sparse_layouts: Optional[List[Union[str, torch.layout]]] = None,\n./torch_geometric/testing/asserts.py:49:        test_sparse_layouts (List[str or int], optional): The sparse layouts to\n./torch_geometric/testing/asserts.py:62:    if test_sparse_layouts is None:\n./torch_geometric/testing/asserts.py:63:        test_sparse_layouts = SPARSE_LAYOUTS\n./torch_geometric/testing/asserts.py:74:    if len(test_sparse_layouts) &gt; 0 and sparse_size is None:\n./torch_geometric/testing/asserts.py:75:        raise ValueError(f\"Got sparse layouts {test_sparse_layouts}, but no \"\n./torch_geometric/testing/asserts.py:93:    for layout in (test_sparse_layouts or []):\nBinary file ./.git/index matches\n\n\nMany locations matched to 3 files. It‚Äôs possible they aren‚Äôt all relevant for testing purpose. The .git/index is a binary file, which is used by git to store information about the repository, it‚Äôs not relevant for our task.\n\n\n\nGit is a distributed version control system. It is a tool that tracks changes in files and directories. At user-defined snapshots in time, called commits, it records the changes made to the files and directories. As a consequence it is possible to search for changes in the repository across snapshots.\nAlong with grep and find, there are git specific tools for searching snapshots of the repo, commit messages and filtering by date and author, such as:\n\ngit ls-files\ngit log\ngit grep\n\n\n\n\nThe working tree is what you see when you list the files in your project‚Äôs directory that are being tracked. It‚Äôs the version of your project that you‚Äôre currently working on. The git checkout command is used to update the working directory with a specific commit, matching the snapshot recorded in the commit. Untracked files are not affected by git checkout.\nThe git ls-files command lists the files in the working tree that are being tracked by git. The filenames can be searched for a string using the grep command.\n\n\nCode\n%%bash\ngit ls-files | grep \"test_sparse\"\n\n\ntest/utils/test_sparse.py\n\n\nIf we want to log commit messages (including commit ids) where filenames contain the string test_sparse were modified, we can use the following command, truncating the output with pipe to head:\n\n\nCode\n%%bash\ngit log --all -- *test_sparse* | head -n 20\n\n\ncommit 62fa51e0000913e1b3023b817485d2b248322539\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Sun Dec 24 11:56:08 2023 +0100\n\n    Accelerate concatenation of `torch.sparse` tensors (#8670)\n    \n    Fixes #8664\n\ncommit 1c89e751804d1eb2fb626dabc677198a1878c34d\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Wed Oct 4 09:59:36 2023 +0200\n\n    Skip TorchScript bug for PyTorch &lt; 1.12 (#8123)\n\ncommit 51c50c2f9d3372de34f4ac3617f396384a36558c\nAuthor: filipekstrm &lt;filip.ekstrom@hotmail.com&gt;\nDate:   Tue Oct 3 20:39:04 2023 +0200\n\n    Added `mask` argument to `dense_to_sparse` (#8117)\n    \n\n\n\n\n\nTo search for a string inside file contents across commits, we can use the git log and git grep commands. The git log command lists the commits in reverse chronological order.\nThe flag -S, and --all are used to search for change in the number of occurences of the string in the repo across all branches and commits. (Again we‚Äôll pipe to head to truncate the output.)\n\n\nCode\n%%bash\ngit log -S \"test_sparse\" --all | head -n 20\n\n\ncommit dba9659f6c4f29fd2be1f50b5ea12a29a926082f\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Thu Feb 29 14:04:19 2024 +0100\n\n    Fix `EdgeIndex.resize_` linting issues (#8993)\n\ncommit 123e38ef6715f75ed9198d256cc2cb984b431630\nAuthor: Poovaiah Palangappa &lt;98763718+pmpalang@users.noreply.github.com&gt;\nDate:   Sun Feb 11 03:32:44 2024 -0800\n\n    Example of a recommender system (#8546)\n    \n    Hi Everyone,\n    \n    I'm adding a recommender system example with the following salient\n    features\n    \n    1. Dataset MovieLens ‚Äì a heterogenous use case\n    2. Demonstrates the use of edge based temporal sampling\n    3. Visualization\n\n\nto be specific to a branch, replace ‚Äìall with the branch name (master in this case)\n\n\nCode\n%%bash\ngit log master -S \"convert_coo_to_csr_indices\"  | head -n 20\n\n\nIf we just want commit hashes and filenames where a file was added (and has the string in its contents), we can use the --name-only flag, made pretty:\n\n\nCode\n%%bash\ngit log master -S \"test_sparse\" --pretty=format:\"%h\" --name-only --diff-filter=A\n\n\n801723efa\ntest/utils/test_cross_entropy.py\n\n1dadc0705\ntorch_geometric/testing/asserts.py\n\n2c01aa22c\ntest/utils/test_sparse.py\n\n\nWith regular expression search use the flag -G ( * glob is not needed as it‚Äôs implied with regular expressions).\n\n\nCode\n%%bash\ngit log -G \"convert_coo_to_csr_indices\" --pretty=format:\"%h\" --name-only\n\n\nNothing. It seems that the string convert_coo_to_csr_indices is not in the contents of any files in the repo.\n\n\nCode\n%%bash\ngit log -G \"coo_to_csr\" --pretty=format:\"%h\" --name-only | head -n 20\n\n\n390942fc4\ntorch_geometric/data/edge_index.py\n\n699120e25\ntorch_geometric/data/edge_index.py\n\na6f0f4947\ntorch_geometric/data/edge_index.py\n\ncf786b735\ntorch_geometric/data/edge_index.py\n\nb825dc637\ntorch_geometric/data/edge_index.py\n\nb5ecfd9b4\ntorch_geometric/data/graph_store.py\ntorch_geometric/nn/conv/cugraph/base.py\ntorch_geometric/nn/conv/rgcn_conv.py\ntorch_geometric/nn/dense/linear.py\n\n\nLet‚Äôs try a few different strings.\n\n\nCode\n%%bash\ngit log -G \"convert_coo\" --pretty=format:\"%h\" --name-only\n\n\n\n\nCode\n%%bash\ngit log -G \"csr_indices\" --pretty=format:\"%h\" --name-only\n\n\n\n\nCode\n%%bash\ngit log master -G\"test_sparse\" --pretty=format:\"%h\" --name-only\n\n\ndba9659f6\ntest/test_edge_index.py\n\n123e38ef6\ntest/test_edge_index.py\n\n23bbc128d\ntest/test_edge_index.py\n\ned9698d0b\ntorch_geometric/testing/asserts.py\n\n1725f1436\ntest/utils/test_cross_entropy.py\n\n801723efa\ntest/utils/test_cross_entropy.py\n\n1dadc0705\ntorch_geometric/testing/asserts.py\n\n7b4892781\ntest/nn/conv/test_gcn_conv.py\n\n72e8ef33d\ntest/nn/conv/test_gcn_conv.py\n\n93fab2e53\ntest/nn/conv/test_gcn_conv.py\n\nd01ea9dab\ntest/utils/test_sparse.py\n\n2c01aa22c\ntest/utils/test_sparse.py\n\neb4260ce0\ntorch_geometric/nn/functional/pool/voxel_pool_test.py\n\n544f4ad0e\ntorch_geometric/nn/functional/pool/voxel_pool_test.py\n\n\n\n\n\n\n\nCode\n%%bash\ngit log --author=\"ravkalia\"  | head -n 20\n\n\ncommit f0e4c829662df9eb67fd5c0abda002c9b7cd0afb\nAuthor: Ravi Kalia &lt;ravkalia@gmail.com&gt;\nDate:   Sun Mar 24 08:05:12 2024 -0500\n\n    Replace `withCUDA` decorator: `withDevice` (#9082)\n    \n    Replace `withCUDA` for a `withDevice` decorator.\n    \n    Change variable name from devices to processors to reduce confusion\n    against pytorch api (backends/devices) and reflect the hardware choices.\n    \n    Note that at this time:\n    \n    ## Hardware\n    3 repertoires of hardware can be used to run pyTorch code:\n    \n    * CPU only\n    * CPU and GPU\n    * Unified Memory Single Chip\n    \n\n\n\n\nCode\n%%bash\ngit log --author=\"ravkalia\" --since=\"2022-01-01\" --until=\"2024-02-31\" | head -n 20\n\n\ncommit 25b2f208e671eeec285bfafa2e246ea0a234b312\nAuthor: Ravi Kalia &lt;ravkalia@gmail.com&gt;\nDate:   Wed Feb 21 11:11:33 2024 -0500\n\n    docs: fix broken links to source of graph classification datasets (#8946)\n    \n    **Update Broken Dataset Links in Documentation**\n    \n    This PR addresses broken links in the documentation that pointed to the\n    common benchmark datasets. The links were updated to point to the\n    correct URL.\n    \n    Changes were made in the following files:\n    \n    1. `benchmark/kernel/README.md`\n    2. `docs/source/get_started/introduction.rst`\n    \n    The specific changes are as follows:\n    \n    In `benchmark/kernel/README.md`:\n\n\n\n\nCode\n%%bash\ngit log --grep=\"docs\"  --since=\"2022-01-01\" --until=\"2022-02-31\" | head -n 20\n\n\ncommit 24a185e7268f70ee549c7a424b9426b9a18b5706\nAuthor: Ramona Bendias &lt;ramona.bendias@gmail.com&gt;\nDate:   Mon Feb 21 13:03:52 2022 +0000\n\n    Add general `Explainer` Class (#4090)\n    \n    * Add base Explainer\n    \n    * Update Explainer\n    \n    * Fix test\n    \n    * Clean code\n    \n    * Update test/nn/models/test_explainer.py\n    \n    Co-authored-by: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\n    \n    * Update torch_geometric/nn/models/explainer.py\n    \n\n\n\n\nCode\n%%bash\ngit log --oneline --grep=\"docs\"  --since=\"2022-01-01\" --until=\"2022-02-31\" \n\n\n24a185e72 Add general `Explainer` Class (#4090)\n6002170a5 Make models compatible to Captum (#3990)\n14d588d4c Update attention.py (#4009)\n50ff5e6d6 Add `full` extras to install command in contribution docs (#3991)\n1e24b3a16 Refactor: `MLP` initialization (#3957)\n3e4891be6 Doc improvements to set2set layers (#3889)\nfac848c25 Let `TemporalData` inherit from `BaseData` and add docs (#3867)\n0c29b0d5b Updated docstring for shape info - part 2 (#3739)\n\n\n\n\n\nThe main differences between git grep and grep are:\ngit grep only searches through your tracked files, while grep can search through any files. git grep is aware of your Git repository structure and can search through old commits, branches, etc., while grep only searches through the current state of files.\ngit grep is faster than grep when searching through a Git repository because it takes advantage of Git‚Äôs index data structure.\n\n\nCode\n%%time\n%%bash\ngit grep \"test_sparse\" &gt; /dev/null\n\n\nCPU times: user 1.52 ms, sys: 4.44 ms, total: 5.96 ms\nWall time: 22.6 ms\n\n\n\n\nCode\n%%time\n%%bash\ngrep -r \"test_sparse\" . &gt; /dev/null\n\n\nCPU times: user 1.94 ms, sys: 3.26 ms, total: 5.21 ms\nWall time: 346 ms\n\n\n\n\n\nThere are many ways to search a repository, particularly a Git Repo. We outlined some use cases with examples for a ‚ÄúUnix-like‚Äù file directory and also a Git Repo.\nIn most cases use:\n\ngit grep for searching strings in the repository in the current working tree or a specific commit\ngit log for searching across commits.\n\nThere are many flags and options for these commands - some combinations which produce the same output. Be sure to check the documentation for more information.\nFor the strings we are after, the conclusion is:\n\ntest_sparse is in the filename test_sparse.py and in the contents of the file test_sparse.py in the repo.\nconvert_coo_to_csr_indices is not in the contents of any files in the repo.\nstrings similar to convert_coo_to_csr_indices are available.\n\nThe most promising output from the commands tested are:\n\n\nCode\n%%bash\ngrep -rn . -e \"test_sparse\" || echo \"no match\"\n\n\n./test/utils/test_cross_entropy.py:9:def test_sparse_cross_entropy_multiclass(with_edge_label_weight):\n./test/utils/test_cross_entropy.py:32:def test_sparse_cross_entropy_multilabel(with_edge_label_weight):\n./test/test_edge_index.py:102:def test_sparse_tensor(dtype, device):\n./test/test_edge_index.py:992:def test_sparse_narrow(device):\n./test/test_edge_index.py:1026:def test_sparse_resize(device):\n./torch_geometric/testing/asserts.py:24:    test_sparse_layouts: Optional[List[Union[str, torch.layout]]] = None,\n./torch_geometric/testing/asserts.py:49:        test_sparse_layouts (List[str or int], optional): The sparse layouts to\n./torch_geometric/testing/asserts.py:62:    if test_sparse_layouts is None:\n./torch_geometric/testing/asserts.py:63:        test_sparse_layouts = SPARSE_LAYOUTS\n./torch_geometric/testing/asserts.py:74:    if len(test_sparse_layouts) &gt; 0 and sparse_size is None:\n./torch_geometric/testing/asserts.py:75:        raise ValueError(f\"Got sparse layouts {test_sparse_layouts}, but no \"\n./torch_geometric/testing/asserts.py:93:    for layout in (test_sparse_layouts or []):\nBinary file ./.git/index matches\n\n\n\n\nCode\n%%bash\ngrep -rn . -e \"convert_coo_to_csr_indices\" || echo \"no match\"\n\n\nno match\n\n\n\n\nCode\n%%bash\ngit ls-files | grep \"test_sparse\"\n\n\ntest/utils/test_sparse.py\n\n\n\n\nCode\n%%bash\ngit log -G \"coo_to_csr\" --pretty=format:\"%h\" --name-only | head -n 20\n\n\n390942fc4\ntorch_geometric/data/edge_index.py\n\n699120e25\ntorch_geometric/data/edge_index.py\n\na6f0f4947\ntorch_geometric/data/edge_index.py\n\ncf786b735\ntorch_geometric/data/edge_index.py\n\nb825dc637\ntorch_geometric/data/edge_index.py\n\nb5ecfd9b4\ntorch_geometric/data/graph_store.py\ntorch_geometric/nn/conv/cugraph/base.py\ntorch_geometric/nn/conv/rgcn_conv.py\ntorch_geometric/nn/dense/linear.py\n\n\n\n\nCode\n%%bash\ngit log --pretty=format:\"%h\" -G \"coo_to_csr\" --all | while read commit; do\n    echo \"Commit: $commit\"\n    git grep -n \"coo_to_csr\" $commit\ndone | head -n 20\n\n\nCommit: 390942fc4\n390942fc4:torch_geometric/data/edge_index.py:344:        self._indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/data/edge_index.py:382:            rowptr = self._T_indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/data/edge_index.py:403:            colptr = self._T_indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: 699120e25\n699120e25:torch_geometric/data/edge_index.py:323:                self._rowptr = rowptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:351:                self._rowptr = rowptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:375:                self._colptr = colptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:403:                self._colptr = colptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: a6f0f4947\na6f0f4947:torch_geometric/data/edge_index.py:321:                self._rowptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:352:                self._rowptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:379:                self._colptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:410:                self._colptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: cf786b735\ncf786b735:torch_geometric/data/edge_index.py:236:        self._rowptr = torch._convert_indices_from_coo_to_csr(\ncf786b735:torch_geometric/data/edge_index.py:255:        self._colptr = torch._convert_indices_from_coo_to_csr(\n\n\nThis is a good starting point for debugging the issues with the unit tests in the library. Useful and informative :=)\nAnd finally some clean up:\n\n\nCode\nimport shutil\n\nshutil.rmtree(os.getcwd())"
  },
  {
    "objectID": "posts/git-search/index.html#filename-in-unix-like-directory",
    "href": "posts/git-search/index.html#filename-in-unix-like-directory",
    "title": "Git Repository Search",
    "section": "",
    "text": "We can look for the string test_sparse in filenames using the shell command line tool find.\n\n\nCode\n%%bash\nfind . -name \"*test_sparse*\" -o -name \"*convert_coo_to_csr_indices*\"\n\n\n./test/utils/test_sparse.py\n\n\ngreat, so we have a file to look at. Let‚Äôs look at the file test_sparse.py. It seems to be unit tests related to sparsity, possibly testing utility functions for converting between sparse tensor representations."
  },
  {
    "objectID": "posts/git-search/index.html#string-in-unix-like-directory",
    "href": "posts/git-search/index.html#string-in-unix-like-directory",
    "title": "Git Repository Search",
    "section": "",
    "text": "String search is a bit more complicated. grep is an awesome tool for this.\n\n\nCode\n%%bash\ngrep -rn . -e \"test_sparse\" -e \"convert_coo_to_csr_indices\"\n\n\n./test/utils/test_cross_entropy.py:9:def test_sparse_cross_entropy_multiclass(with_edge_label_weight):\n./test/utils/test_cross_entropy.py:32:def test_sparse_cross_entropy_multilabel(with_edge_label_weight):\n./test/test_edge_index.py:102:def test_sparse_tensor(dtype, device):\n./test/test_edge_index.py:992:def test_sparse_narrow(device):\n./test/test_edge_index.py:1026:def test_sparse_resize(device):\n./torch_geometric/testing/asserts.py:24:    test_sparse_layouts: Optional[List[Union[str, torch.layout]]] = None,\n./torch_geometric/testing/asserts.py:49:        test_sparse_layouts (List[str or int], optional): The sparse layouts to\n./torch_geometric/testing/asserts.py:62:    if test_sparse_layouts is None:\n./torch_geometric/testing/asserts.py:63:        test_sparse_layouts = SPARSE_LAYOUTS\n./torch_geometric/testing/asserts.py:74:    if len(test_sparse_layouts) &gt; 0 and sparse_size is None:\n./torch_geometric/testing/asserts.py:75:        raise ValueError(f\"Got sparse layouts {test_sparse_layouts}, but no \"\n./torch_geometric/testing/asserts.py:93:    for layout in (test_sparse_layouts or []):\nBinary file ./.git/index matches\n\n\nMany locations matched to 3 files. It‚Äôs possible they aren‚Äôt all relevant for testing purpose. The .git/index is a binary file, which is used by git to store information about the repository, it‚Äôs not relevant for our task."
  },
  {
    "objectID": "posts/git-search/index.html#what-is-git",
    "href": "posts/git-search/index.html#what-is-git",
    "title": "Git Repository Search",
    "section": "",
    "text": "Git is a distributed version control system. It is a tool that tracks changes in files and directories. At user-defined snapshots in time, called commits, it records the changes made to the files and directories. As a consequence it is possible to search for changes in the repository across snapshots.\nAlong with grep and find, there are git specific tools for searching snapshots of the repo, commit messages and filtering by date and author, such as:\n\ngit ls-files\ngit log\ngit grep"
  },
  {
    "objectID": "posts/git-search/index.html#filename-in-git-repository",
    "href": "posts/git-search/index.html#filename-in-git-repository",
    "title": "Git Repository Search",
    "section": "",
    "text": "The working tree is what you see when you list the files in your project‚Äôs directory that are being tracked. It‚Äôs the version of your project that you‚Äôre currently working on. The git checkout command is used to update the working directory with a specific commit, matching the snapshot recorded in the commit. Untracked files are not affected by git checkout.\nThe git ls-files command lists the files in the working tree that are being tracked by git. The filenames can be searched for a string using the grep command.\n\n\nCode\n%%bash\ngit ls-files | grep \"test_sparse\"\n\n\ntest/utils/test_sparse.py\n\n\nIf we want to log commit messages (including commit ids) where filenames contain the string test_sparse were modified, we can use the following command, truncating the output with pipe to head:\n\n\nCode\n%%bash\ngit log --all -- *test_sparse* | head -n 20\n\n\ncommit 62fa51e0000913e1b3023b817485d2b248322539\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Sun Dec 24 11:56:08 2023 +0100\n\n    Accelerate concatenation of `torch.sparse` tensors (#8670)\n    \n    Fixes #8664\n\ncommit 1c89e751804d1eb2fb626dabc677198a1878c34d\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Wed Oct 4 09:59:36 2023 +0200\n\n    Skip TorchScript bug for PyTorch &lt; 1.12 (#8123)\n\ncommit 51c50c2f9d3372de34f4ac3617f396384a36558c\nAuthor: filipekstrm &lt;filip.ekstrom@hotmail.com&gt;\nDate:   Tue Oct 3 20:39:04 2023 +0200\n\n    Added `mask` argument to `dense_to_sparse` (#8117)"
  },
  {
    "objectID": "posts/git-search/index.html#string-in-file-contents-of-git-repository",
    "href": "posts/git-search/index.html#string-in-file-contents-of-git-repository",
    "title": "Git Repository Search",
    "section": "",
    "text": "To search for a string inside file contents across commits, we can use the git log and git grep commands. The git log command lists the commits in reverse chronological order.\nThe flag -S, and --all are used to search for change in the number of occurences of the string in the repo across all branches and commits. (Again we‚Äôll pipe to head to truncate the output.)\n\n\nCode\n%%bash\ngit log -S \"test_sparse\" --all | head -n 20\n\n\ncommit dba9659f6c4f29fd2be1f50b5ea12a29a926082f\nAuthor: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\nDate:   Thu Feb 29 14:04:19 2024 +0100\n\n    Fix `EdgeIndex.resize_` linting issues (#8993)\n\ncommit 123e38ef6715f75ed9198d256cc2cb984b431630\nAuthor: Poovaiah Palangappa &lt;98763718+pmpalang@users.noreply.github.com&gt;\nDate:   Sun Feb 11 03:32:44 2024 -0800\n\n    Example of a recommender system (#8546)\n    \n    Hi Everyone,\n    \n    I'm adding a recommender system example with the following salient\n    features\n    \n    1. Dataset MovieLens ‚Äì a heterogenous use case\n    2. Demonstrates the use of edge based temporal sampling\n    3. Visualization\n\n\nto be specific to a branch, replace ‚Äìall with the branch name (master in this case)\n\n\nCode\n%%bash\ngit log master -S \"convert_coo_to_csr_indices\"  | head -n 20\n\n\nIf we just want commit hashes and filenames where a file was added (and has the string in its contents), we can use the --name-only flag, made pretty:\n\n\nCode\n%%bash\ngit log master -S \"test_sparse\" --pretty=format:\"%h\" --name-only --diff-filter=A\n\n\n801723efa\ntest/utils/test_cross_entropy.py\n\n1dadc0705\ntorch_geometric/testing/asserts.py\n\n2c01aa22c\ntest/utils/test_sparse.py\n\n\nWith regular expression search use the flag -G ( * glob is not needed as it‚Äôs implied with regular expressions).\n\n\nCode\n%%bash\ngit log -G \"convert_coo_to_csr_indices\" --pretty=format:\"%h\" --name-only\n\n\nNothing. It seems that the string convert_coo_to_csr_indices is not in the contents of any files in the repo.\n\n\nCode\n%%bash\ngit log -G \"coo_to_csr\" --pretty=format:\"%h\" --name-only | head -n 20\n\n\n390942fc4\ntorch_geometric/data/edge_index.py\n\n699120e25\ntorch_geometric/data/edge_index.py\n\na6f0f4947\ntorch_geometric/data/edge_index.py\n\ncf786b735\ntorch_geometric/data/edge_index.py\n\nb825dc637\ntorch_geometric/data/edge_index.py\n\nb5ecfd9b4\ntorch_geometric/data/graph_store.py\ntorch_geometric/nn/conv/cugraph/base.py\ntorch_geometric/nn/conv/rgcn_conv.py\ntorch_geometric/nn/dense/linear.py\n\n\nLet‚Äôs try a few different strings.\n\n\nCode\n%%bash\ngit log -G \"convert_coo\" --pretty=format:\"%h\" --name-only\n\n\n\n\nCode\n%%bash\ngit log -G \"csr_indices\" --pretty=format:\"%h\" --name-only\n\n\n\n\nCode\n%%bash\ngit log master -G\"test_sparse\" --pretty=format:\"%h\" --name-only\n\n\ndba9659f6\ntest/test_edge_index.py\n\n123e38ef6\ntest/test_edge_index.py\n\n23bbc128d\ntest/test_edge_index.py\n\ned9698d0b\ntorch_geometric/testing/asserts.py\n\n1725f1436\ntest/utils/test_cross_entropy.py\n\n801723efa\ntest/utils/test_cross_entropy.py\n\n1dadc0705\ntorch_geometric/testing/asserts.py\n\n7b4892781\ntest/nn/conv/test_gcn_conv.py\n\n72e8ef33d\ntest/nn/conv/test_gcn_conv.py\n\n93fab2e53\ntest/nn/conv/test_gcn_conv.py\n\nd01ea9dab\ntest/utils/test_sparse.py\n\n2c01aa22c\ntest/utils/test_sparse.py\n\neb4260ce0\ntorch_geometric/nn/functional/pool/voxel_pool_test.py\n\n544f4ad0e\ntorch_geometric/nn/functional/pool/voxel_pool_test.py"
  },
  {
    "objectID": "posts/git-search/index.html#filter-git-commit-messages-for-author-date-and-string",
    "href": "posts/git-search/index.html#filter-git-commit-messages-for-author-date-and-string",
    "title": "Git Repository Search",
    "section": "",
    "text": "Code\n%%bash\ngit log --author=\"ravkalia\"  | head -n 20\n\n\ncommit f0e4c829662df9eb67fd5c0abda002c9b7cd0afb\nAuthor: Ravi Kalia &lt;ravkalia@gmail.com&gt;\nDate:   Sun Mar 24 08:05:12 2024 -0500\n\n    Replace `withCUDA` decorator: `withDevice` (#9082)\n    \n    Replace `withCUDA` for a `withDevice` decorator.\n    \n    Change variable name from devices to processors to reduce confusion\n    against pytorch api (backends/devices) and reflect the hardware choices.\n    \n    Note that at this time:\n    \n    ## Hardware\n    3 repertoires of hardware can be used to run pyTorch code:\n    \n    * CPU only\n    * CPU and GPU\n    * Unified Memory Single Chip\n    \n\n\n\n\nCode\n%%bash\ngit log --author=\"ravkalia\" --since=\"2022-01-01\" --until=\"2024-02-31\" | head -n 20\n\n\ncommit 25b2f208e671eeec285bfafa2e246ea0a234b312\nAuthor: Ravi Kalia &lt;ravkalia@gmail.com&gt;\nDate:   Wed Feb 21 11:11:33 2024 -0500\n\n    docs: fix broken links to source of graph classification datasets (#8946)\n    \n    **Update Broken Dataset Links in Documentation**\n    \n    This PR addresses broken links in the documentation that pointed to the\n    common benchmark datasets. The links were updated to point to the\n    correct URL.\n    \n    Changes were made in the following files:\n    \n    1. `benchmark/kernel/README.md`\n    2. `docs/source/get_started/introduction.rst`\n    \n    The specific changes are as follows:\n    \n    In `benchmark/kernel/README.md`:\n\n\n\n\nCode\n%%bash\ngit log --grep=\"docs\"  --since=\"2022-01-01\" --until=\"2022-02-31\" | head -n 20\n\n\ncommit 24a185e7268f70ee549c7a424b9426b9a18b5706\nAuthor: Ramona Bendias &lt;ramona.bendias@gmail.com&gt;\nDate:   Mon Feb 21 13:03:52 2022 +0000\n\n    Add general `Explainer` Class (#4090)\n    \n    * Add base Explainer\n    \n    * Update Explainer\n    \n    * Fix test\n    \n    * Clean code\n    \n    * Update test/nn/models/test_explainer.py\n    \n    Co-authored-by: Matthias Fey &lt;matthias.fey@tu-dortmund.de&gt;\n    \n    * Update torch_geometric/nn/models/explainer.py\n    \n\n\n\n\nCode\n%%bash\ngit log --oneline --grep=\"docs\"  --since=\"2022-01-01\" --until=\"2022-02-31\" \n\n\n24a185e72 Add general `Explainer` Class (#4090)\n6002170a5 Make models compatible to Captum (#3990)\n14d588d4c Update attention.py (#4009)\n50ff5e6d6 Add `full` extras to install command in contribution docs (#3991)\n1e24b3a16 Refactor: `MLP` initialization (#3957)\n3e4891be6 Doc improvements to set2set layers (#3889)\nfac848c25 Let `TemporalData` inherit from `BaseData` and add docs (#3867)\n0c29b0d5b Updated docstring for shape info - part 2 (#3739)"
  },
  {
    "objectID": "posts/git-search/index.html#git-grep-vs-grep",
    "href": "posts/git-search/index.html#git-grep-vs-grep",
    "title": "Git Repository Search",
    "section": "",
    "text": "The main differences between git grep and grep are:\ngit grep only searches through your tracked files, while grep can search through any files. git grep is aware of your Git repository structure and can search through old commits, branches, etc., while grep only searches through the current state of files.\ngit grep is faster than grep when searching through a Git repository because it takes advantage of Git‚Äôs index data structure.\n\n\nCode\n%%time\n%%bash\ngit grep \"test_sparse\" &gt; /dev/null\n\n\nCPU times: user 1.52 ms, sys: 4.44 ms, total: 5.96 ms\nWall time: 22.6 ms\n\n\n\n\nCode\n%%time\n%%bash\ngrep -r \"test_sparse\" . &gt; /dev/null\n\n\nCPU times: user 1.94 ms, sys: 3.26 ms, total: 5.21 ms\nWall time: 346 ms"
  },
  {
    "objectID": "posts/git-search/index.html#takeaways",
    "href": "posts/git-search/index.html#takeaways",
    "title": "Git Repository Search",
    "section": "",
    "text": "There are many ways to search a repository, particularly a Git Repo. We outlined some use cases with examples for a ‚ÄúUnix-like‚Äù file directory and also a Git Repo.\nIn most cases use:\n\ngit grep for searching strings in the repository in the current working tree or a specific commit\ngit log for searching across commits.\n\nThere are many flags and options for these commands - some combinations which produce the same output. Be sure to check the documentation for more information.\nFor the strings we are after, the conclusion is:\n\ntest_sparse is in the filename test_sparse.py and in the contents of the file test_sparse.py in the repo.\nconvert_coo_to_csr_indices is not in the contents of any files in the repo.\nstrings similar to convert_coo_to_csr_indices are available.\n\nThe most promising output from the commands tested are:\n\n\nCode\n%%bash\ngrep -rn . -e \"test_sparse\" || echo \"no match\"\n\n\n./test/utils/test_cross_entropy.py:9:def test_sparse_cross_entropy_multiclass(with_edge_label_weight):\n./test/utils/test_cross_entropy.py:32:def test_sparse_cross_entropy_multilabel(with_edge_label_weight):\n./test/test_edge_index.py:102:def test_sparse_tensor(dtype, device):\n./test/test_edge_index.py:992:def test_sparse_narrow(device):\n./test/test_edge_index.py:1026:def test_sparse_resize(device):\n./torch_geometric/testing/asserts.py:24:    test_sparse_layouts: Optional[List[Union[str, torch.layout]]] = None,\n./torch_geometric/testing/asserts.py:49:        test_sparse_layouts (List[str or int], optional): The sparse layouts to\n./torch_geometric/testing/asserts.py:62:    if test_sparse_layouts is None:\n./torch_geometric/testing/asserts.py:63:        test_sparse_layouts = SPARSE_LAYOUTS\n./torch_geometric/testing/asserts.py:74:    if len(test_sparse_layouts) &gt; 0 and sparse_size is None:\n./torch_geometric/testing/asserts.py:75:        raise ValueError(f\"Got sparse layouts {test_sparse_layouts}, but no \"\n./torch_geometric/testing/asserts.py:93:    for layout in (test_sparse_layouts or []):\nBinary file ./.git/index matches\n\n\n\n\nCode\n%%bash\ngrep -rn . -e \"convert_coo_to_csr_indices\" || echo \"no match\"\n\n\nno match\n\n\n\n\nCode\n%%bash\ngit ls-files | grep \"test_sparse\"\n\n\ntest/utils/test_sparse.py\n\n\n\n\nCode\n%%bash\ngit log -G \"coo_to_csr\" --pretty=format:\"%h\" --name-only | head -n 20\n\n\n390942fc4\ntorch_geometric/data/edge_index.py\n\n699120e25\ntorch_geometric/data/edge_index.py\n\na6f0f4947\ntorch_geometric/data/edge_index.py\n\ncf786b735\ntorch_geometric/data/edge_index.py\n\nb825dc637\ntorch_geometric/data/edge_index.py\n\nb5ecfd9b4\ntorch_geometric/data/graph_store.py\ntorch_geometric/nn/conv/cugraph/base.py\ntorch_geometric/nn/conv/rgcn_conv.py\ntorch_geometric/nn/dense/linear.py\n\n\n\n\nCode\n%%bash\ngit log --pretty=format:\"%h\" -G \"coo_to_csr\" --all | while read commit; do\n    echo \"Commit: $commit\"\n    git grep -n \"coo_to_csr\" $commit\ndone | head -n 20\n\n\nCommit: 390942fc4\n390942fc4:torch_geometric/data/edge_index.py:344:        self._indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/data/edge_index.py:382:            rowptr = self._T_indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/data/edge_index.py:403:            colptr = self._T_indptr = torch._convert_indices_from_coo_to_csr(\n390942fc4:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: 699120e25\n699120e25:torch_geometric/data/edge_index.py:323:                self._rowptr = rowptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:351:                self._rowptr = rowptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:375:                self._colptr = colptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/data/edge_index.py:403:                self._colptr = colptr = torch._convert_indices_from_coo_to_csr(\n699120e25:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: a6f0f4947\na6f0f4947:torch_geometric/data/edge_index.py:321:                self._rowptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:352:                self._rowptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:379:                self._colptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/data/edge_index.py:410:                self._colptr = torch._convert_indices_from_coo_to_csr(\na6f0f4947:torch_geometric/utils/sparse.py:480:    return torch._convert_indices_from_coo_to_csr(\nCommit: cf786b735\ncf786b735:torch_geometric/data/edge_index.py:236:        self._rowptr = torch._convert_indices_from_coo_to_csr(\ncf786b735:torch_geometric/data/edge_index.py:255:        self._colptr = torch._convert_indices_from_coo_to_csr(\n\n\nThis is a good starting point for debugging the issues with the unit tests in the library. Useful and informative :=)\nAnd finally some clean up:\n\n\nCode\nimport shutil\n\nshutil.rmtree(os.getcwd())"
  },
  {
    "objectID": "posts/sparse_tensors/index.html",
    "href": "posts/sparse_tensors/index.html",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Image of Building\n\n\nPhoto by engin akyurt on Unsplash\n\n\nThe canonical format for representing tensors in PyTorch is the dense tensor, with associated contiguous memory proportional to the size of the tensor. However, in many applications, the data is sparse, that is most of the elements are zero. In this notebook, we will see how to work efficiently with sparse tensors in PyTorch.\n\n\nA dataset is considered sparse when most of its elements are zero, for some features of the dataset. The exact threshold for considering a dataset as sparse is not strictly defined and can depend on the context and the specific application. A common rule of thumb is that a dataset is sparse if over 50% of its elements are zero.\nIn many real-world applications, datasets can be extremely sparse, with over 90% or even 99% of elements being zero. For example, in a user-item interaction matrix in a recommendation system, each user typically interacts with only a small fraction of all possible items, so the vast majority of the matrix elements are zero.\nIn PyTorch, datasets are stored in tensors. A tensor is a multi-dimensional array, similar to a NumPy array. PyTorch provides some support for sparse tensors.\n\n\n\nIn a dense tensor, all elements are stored in memory, even if most of them are zero. In a sparse tensor, only the non-zero elements are stored, along with their indices. This can lead to significant memory savings and/or faster compute times, especially for very sparse datasets.\nFor several tasks which are computing on the tensor, sparse tensors can be more efficient than dense tensors. For example, consider matrix multiplication. If the matrices are sparse, then sparse tensors can be orders of magnitude faster than dense tensors - as we will demonstrate at the end.\n\n\n\nIn PyTorch there are several ways to create sparse tensors as containers for sparse data. We will see how to create a sparse tensor from a dense tensor, and how to create a sparse tensor from different formats: COO, CSR, and CSC.\nFirst we‚Äôll need example data to work with - let‚Äôs use a graph dataset as an example to understand sparse tensors.\n\n\n\n\nGraph data is a commonly sparse. A graph is a collection of nodes (or vertices) and edges. The nodes represent entities, and the edges represent relationships between the entities. More often than not, graphs are sparse, i.e.¬†most of the nodes are not connected to each other. It is common to see datasets where less than 1% of the possible edges are present.\nThere are many ways to represent a Graph. One common is an adjacency matrix, A. This is particularly bad for sparse graphs, as most of the elements in the matrix are zero.\nThe adjacency matrix is a square matrix A, of size N x N, where N is the number of nodes in the graph. The element A[i, j] is 1 if there is an edge between node i and node j, and 0 otherwise. Since most nodes are not connected to each other, the adjacency matrix is sparse.\nAnother more memory-efficient way to represent a graph is using a tensor of edges, E. Each edge is represented as a 2 long column (r, s) in E, where r and s are the indices of the nodes connected by the edge. This representation is more memory-efficient than the adjacency matrix, as it only stores the non-zero elements, it‚Äôs size is 2 x number_edges.\nIn this notebook, we will see how to create a sparse tensor from an adjacency matrix, and how to create a sparse tensor from a list of edges. We will also see how to perform basic operations on sparse tensors, such as matrix multiplication and element-wise operations.\nLet‚Äôs consider an example from the ModelNet10 dataset.\n\n\nModelNet10 is a subset of the ModelNet dataset, which is a large-scale 3D CAD model dataset. ModelNet10 specifically consists of 10 categories, with a total of 4899 3D CAD models. The categories include: bed, chair, monitor, desk, dresser, sofa, table, toilet, night stand, and bathtub.\nEach 3D model in the dataset is represented as a graph, where each node represents a point in the 3D object, and each edge represents a relationship between the points. The adjacency matrix of the graph is sparse, as most of the points are not connected to each other.\nThis dataset is commonly used for benchmarking in tasks such as 3D object recognition, shape classification, and other machine learning tasks involving 3D data.\nLet‚Äôs look at a one: a Monitor from the training dataset. We‚Äôll need to install some libraries to visualize the 3D object.\n\n\nCode\n!pip -q install numpy matplotlib networkx\n\n\nThe data is in off format - that is nodes and edges making faces. The particular file can be found here. The corners of the monitor are the nodes and the edges are the connections between the corners. Here‚Äôs a plot using matplotlib and another with trimesh.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n\ndef read_off(file):\n    if 'OFF' != file.readline().strip():\n        raise('Not a valid OFF header')\n    n_verts, n_faces, _ = tuple(map(int, file.readline().strip().split(' ')))\n    verts = [[float(s) for s in file.readline().strip().split(' ')] for _ in range(n_verts)]\n    faces = [[int(s) for s in file.readline().strip().split(' ')[1:]] for _ in range(n_faces)]\n    return verts, faces\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Create a Poly3DCollection object\npolys = [np.array(verts)[face] for face in faces]\ncollection = Poly3DCollection(polys, linewidths=1, alpha=1)\ncollection.set_facecolor((0,0,1,0.5))  # Set the color of the object to blue\ncollection.set_edgecolor((0,0,1,0.5))  # Set the edge color to a darker blue\nax.add_collection3d(collection)\n\n# Add lighting\nax.add_collection3d(Poly3DCollection(polys, facecolors='r', linewidths=1, edgecolors='r', alpha=.20))\n\n# Remove the axes for a cleaner look\nax.axis('off')\n\n# Auto scale to the mesh size\nscale = np.array(verts).flatten()\nax.auto_scale_xyz(scale, scale, scale)\n\n# Add a title to the plot\nax.set_title('3D Model of Monitor')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip -q install trimesh\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport trimesh\n\n# Load the mesh from the OFF file\nmesh = trimesh.load_mesh('./data/monitor_0001.off')\n\n# Plot the mesh\nmesh.show()\n\n\n\n\n\nTo see this data as a graph, we will feed in vertices and faces into the networkx package.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n\ndef off_to_graph(verts, faces):\n    # Create a new graph\n    G = nx.Graph()\n    # Add nodes to the graph\n    for i in range(len(verts)):\n        G.add_node(i)\n    # Add edges to the graph\n    for face in faces:\n        for i in range(len(face)):\n            # Add an edge between each pair of vertices in the face\n            G.add_edge(face[i], face[(i+1)%len(face)])\n    return G\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\n\n\n\n\nCode\nprint(G)\n\n\nGraph with 798 nodes and 1476 edges\n\n\n\n\nCode\n# Draw the graph\nnx.draw(G, edge_color=\"black\", width=1, node_size=5, with_labels=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nSo, that‚Äôs the graph. It‚Äôs difficult to make out the shape of the monitor from the plot above, as we‚Äôre not representing the features of the nodes (3d co-ordinates).\nWhat we can do is list out the edges and vertices of the graph. First in edge list format with the corresponding nodes.\n\n\nCode\nfor index, edge in enumerate(G.edges(), start=0):\n    print(edge, end=\", \")\n    if index == 9:\n        break\n\n\n(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (3, 4), (4, 5), (4, 6), \n\n\n\n\nCode\nfor index, edge in enumerate(G.nodes(), start=0):\n    print(edge, end=\", \")\n    if index == 9:\n        break\n\n\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n\n\nAnd then as a an adjacency matrix.\n\n\nCode\nA = nx.to_numpy_array(G)\n\n\n\n\nCode\nA.shape\n\n\n(798, 798)\n\n\n\n\nCode\nprint(A)\n\n\n[[0. 1. 1. ... 0. 0. 0.]\n [1. 0. 1. ... 0. 0. 0.]\n [1. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 1. 1.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]]\n\n\nLet‚Äôs verify that the number of edges match the adjacency matrix and edge list view.\n\n\nCode\nA.sum()/2 == len(G.edges()) # The number of edges.\n\n\nTrue\n\n\n\n\n\n\nThe adjacency is sparse. We can quantify this sparsity - the ratio of the number of non-zero elements to the total number of elements in the tensor.\n\n\nCode\n# the ratio of the number of non-zero elements to the total number of elements in the tensor A.\nnp.count_nonzero(A) / (A.shape[0] * A.shape[1])\n\n\n0.004635649273559839\n\n\nStoring data in this format is inefficient. We can convert it to a sparse tensor. We‚Äôll create functions for popular formats, as well as look at the native PyTorch implementations.\n\n\n\nSome well known sparse tensor representation formats are:\n\nCoordinate (COO)\nCompressed Sparse Row (CSR)\nCompressed Sparse Column (CSC)\nBlock Compressed Sparse Row (BSR)\nDictionary of Keys (DOK)\nList of Lists (LIL)\n\nWe‚Äôll look at COO, CSR, and CSC formats.\nThe monitor graph is too large and sparse for illustration purposes. We‚Äôll create a smaller graph to demonstrate the conversion back and forth to sparse tensors.\n\n\nCode\n# Create a new graph\nG = nx.Graph()\n\n# Add some edges to the graph\nG.add_edge(0, 1)\nG.add_edge(0, 2)\nG.add_edge(3, 4)\n\n# Draw the graph\nnx.draw(G, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip -q install torch\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport torch\n\nA = nx.to_numpy_array(G)\nprint(torch.from_numpy(A))\nA_torch = torch.from_numpy(A).bool()\nA_torch\n\n\ntensor([[0., 1., 1., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0.]], dtype=torch.float64)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\nCode\nA.sum()/2\n\n\n3.0\n\n\nLet‚Äôs express as a pandas dataframe with source and target nodes for edges.\n\n\nCode\npip -q install pandas\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\n# Get the number of nodes\nnum_nodes = A_torch.shape[0]\n\n# Create a list of all pairs of nodes\nsource_node, destination_node = np.meshgrid(np.arange(num_nodes), np.arange(num_nodes))\n\n# Flatten the arrays\nsource_node = source_node.flatten()\ndestination_node = destination_node.flatten()\n\n# Get the edge values\nhas_edge = A_torch[source_node, destination_node] &gt; 0\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\n\ndf\n\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n0\nFalse\n\n\n1\n1\n0\nTrue\n\n\n2\n2\n0\nTrue\n\n\n3\n3\n0\nFalse\n\n\n4\n4\n0\nFalse\n\n\n5\n0\n1\nTrue\n\n\n6\n1\n1\nFalse\n\n\n7\n2\n1\nFalse\n\n\n8\n3\n1\nFalse\n\n\n9\n4\n1\nFalse\n\n\n10\n0\n2\nTrue\n\n\n11\n1\n2\nFalse\n\n\n12\n2\n2\nFalse\n\n\n13\n3\n2\nFalse\n\n\n14\n4\n2\nFalse\n\n\n15\n0\n3\nFalse\n\n\n16\n1\n3\nFalse\n\n\n17\n2\n3\nFalse\n\n\n18\n3\n3\nFalse\n\n\n19\n4\n3\nTrue\n\n\n20\n0\n4\nFalse\n\n\n21\n1\n4\nFalse\n\n\n22\n2\n4\nFalse\n\n\n23\n3\n4\nTrue\n\n\n24\n4\n4\nFalse\n\n\n\n\n\n\n\n\n\nThe COO format is simple and flexible for sparse matrices. It consists of three arrays: row, col, and data. The row array contains the row indices of the non-zero elements, the col array contains the column indices of the non-zero elements, and the data array contains the values of the non-zero elements.\nLuckily, PyTorch has built in methods for converting between dense and sparse tensors. We can convert the adjacency matrix to a COO sparse tensor using the .to_sparse() method.\n\n\nCode\nA_coo_pytorch = A_torch.to_sparse()\nA_coo_pytorch\n\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\nAnd convert back\n\n\nCode\nA_coo_pytorch.to_dense()\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nLet‚Äôs look at the sparse tensor as a dataframe of source to destination nodes, but this time only for those pairs where there is an edge.\n\n\nCode\n# Get the source and destination nodes and the edge values\nsource_node = A_coo_pytorch.indices()[0].numpy()\ndestination_node = A_coo_pytorch.indices()[1].numpy()\nhas_edge = A_coo_pytorch.values().numpy()\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\ndf\n\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n1\nTrue\n\n\n1\n0\n2\nTrue\n\n\n2\n1\n0\nTrue\n\n\n3\n2\n0\nTrue\n\n\n4\n3\n4\nTrue\n\n\n5\n4\n3\nTrue\n\n\n\n\n\n\n\nWriting our own homebrew function to convert to COO format, is straightforward.\n\n\nCode\ndef to_sparse(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor).t()\n    # Get the values of the non-zero elements\n    values = tensor[indices[0], indices[1]]  # assuming 2D tensor\n    # Get the size of the original tensor\n    size = tensor.size()\n    # Create a sparse tensor\n    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n    return sparse_tensor\n\n\n\n\nCode\nto_sparse(A_torch)\n\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\n\n\nCode\ndef to_dense(sparse_tensor):\n    # Get the size of the original tensor\n    size = sparse_tensor.size()\n    # Get the indices and values from the sparse tensor\n    indices = sparse_tensor.coalesce().indices()\n    values = sparse_tensor.coalesce().values()\n    # Create a dense tensor of the same size and data type as values, initialized with zeros\n    dense_tensor = torch.zeros(size, dtype=values.dtype)\n    # Convert indices to a tuple of tensors\n    indices_tuple = tuple(indices[i] for i in range(indices.shape[0]))\n    # Use index_put_ to put the values in the dense tensor at the right indices\n    dense_tensor.index_put_(indices_tuple, values, accumulate=False)\n    return dense_tensor\n\n\n\n\nCode\nto_dense(A_coo_pytorch)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nCSR is an even more efficient compact format for sparse data. Details can be found here.\nValues and column indices are stored in the same way as COO format. The row indices are stored in a separate array, which can seem strange at first glance.\nBroadly it relies on slicing the values into per row chunks. The row chunk lengths are calculated as the difference between the row indices of the non-zero elements. The row chunk lengths are stored in a separate array, row_ptr.\nSo, if your original matrix has m rows, n columns, and nnz non-zero values, then:\n\nThe shape of values is [nnz].\nThe shape of column_indices is [nnz].\nThe shape of row_pointers is [m+1].\n\nIn index notation, the row pointer array is defined as:\nrow_ptr[i] = row_ptr[i-1] + number of non-zero elements in row i-1\nSo, the row pointer array stores the cumulative sum of the number of non-zero elements in each row.\nthe row and column number can be determined by the index of the non-zero element in the values array. That is the i-th non-zero element (in the values array) is at row row_ptr[i] and column col[i]. That is:\nvalues[i] = A[row_ptr[i], col[i]]\n\n\nCode\nA_torch.to_sparse_csr()\n\n\ntensor(crow_indices=tensor([0, 2, 3, 4, 5, 6]),\n       col_indices=tensor([1, 2, 0, 0, 4, 3]),\n       values=tensor([True, True, True, True, True, True]), size=(5, 5), nnz=6,\n       layout=torch.sparse_csr)\n\n\nWhich can be recovered by chaining with the .to_dense() method.\n\n\nCode\nA_torch.to_sparse_csr().to_dense()\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nAnd here we write our homebrew version of to_csr() and from_csr() functions:\n\n\nCode\ndef to_csr(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor, as_tuple=True)\n    # Get the values of the non-zero elements\n    values = tensor[indices]\n    # Get the column indices of the non-zero elements\n    column_indices = indices[1]\n    # Get the row pointers\n    row_pointers = torch.zeros(tensor.size(0) + 1, dtype=torch.long)\n    row_pointers[1:] = torch.bincount(indices[0])\n    row_pointers = torch.cumsum(row_pointers, dim=0)\n\n    return values, column_indices, row_pointers\n\n\n\n\nCode\nto_csr(A_torch)\n\n\n(tensor([True, True, True, True, True, True]),\n tensor([1, 2, 0, 0, 4, 3]),\n tensor([0, 2, 3, 4, 5, 6]))\n\n\n\n\nCode\ndef from_csr(values, column_indices, row_pointers):\n    # Get the number of rows and columns\n    num_rows = row_pointers.size(0) - 1\n    num_cols = torch.max(column_indices).item() + 1\n    # Create a dense tensor of the right size, initialized with zeros\n    tensor = torch.zeros((num_rows, num_cols), dtype=values.dtype)\n    # Loop over the rows\n    for i in range(num_rows):\n        # Get the start and end indices for this row in the values and column_indices arrays\n        start = row_pointers[i].item()\n        end = row_pointers[i + 1].item()\n        # Set the values in the dense tensor for this row\n        tensor[i, column_indices[start:end]] = values[start:end]\n\n    return tensor\n\n\n\n\nCode\nfrom_csr(*to_csr(A_torch))\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nThe CSC format is similar to the CSR format, but with the rows and columns swapped. The values and row indices are stored in the same way as the CSR format. The column indices are stored in a separate array, col_ptr.\nThis format is efficient for certain slicing operations, such as extracting a column from a matrix.\n\n\n\n\nLet‚Äôs see how much faster it is to perform matrix multiplication on the sparse tensor compared to the dense tensor. For this we‚Äôll use the ModelNet10 monitor graph seen earlier.\n\n\nCode\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\nA = nx.adjacency_matrix(G)\nA\n\n\n&lt;798x798 sparse array of type '&lt;class 'numpy.int64'&gt;'\n    with 2952 stored elements in Compressed Sparse Row format&gt;\n\n\nA is already a sparse matrix, but in numpy. We‚Äôll convert it to a PyTorch dense tensor first.\n\n\nCode\nA_dense = torch.from_numpy(A.toarray())\nA_dense.shape\n\n\ntorch.Size([798, 798])\n\n\n\n\nCode\ndef tensor_memory_usage_str(tensor=None):\n    if tensor is None:\n        return \"No tensor provided\"\n    bytes = tensor.element_size() * tensor.nelement()\n    kilobytes = bytes / 1024\n    return f\"Memory usage: {bytes} bytes ({kilobytes} KB)\"\n\n\n\n\nCode\ntensor_memory_usage_str(A_dense)\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\n\n\nCode\ntensor_memory_usage_str(A_dense.to_sparse())\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nSomewhat unexpectedly, the sparse and dense tensors have the same memory usage.\n\n\nCode\nA_sparse = A_dense.to_sparse_csr()\n\n\n\n\nCode\ntensor_memory_usage_str(A_sparse)\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nOK, so there was no improvement in memory usage for this particular case. Let‚Äôs time the matrix multiplication operations.\n\n\nCode\nimport timeit\n\n\ndef multiply_tensors():\n    return A_dense @ A_dense\n\nnum_runs = 10\ntime_taken_dense = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken_dense} seconds\")\n\n\nTime taken by my_function over 10 runs: 2.746476124972105 seconds\n\n\n\n\nCode\nA_coo = A\n\ndef multiply_tensors():\n    return A_coo@A_coo\n\nnum_runs = 10\ntime_taken_sparse = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken_sparse} seconds\")\n\n\nTime taken by my_function over 10 runs: 0.0038774579879827797 seconds\n\n\n\n\nCode\nf\"Speedup: {time_taken_dense / time_taken_sparse}x\"\n\n\n'Speedup: 708.3187318815902x'\n\n\nWith CSR encoding of sparse tensors, it might be even better - however I‚Äôm on Apple Silicon, and the csr sparse tensor support is not yet available for this architecture.\n\n\n\nWe just saw how to work with sparse tensors in PyTorch. We created a sparse tensor from an adjacency matrix and a list of edges, and converted it to different sparse formats. We also saw the performance benefits of using sparse tensors for matrix multiplication. There‚Äôs a lot more to sparsity, and PyTorch is actively developing its sparse tensor support. Things will break, but expect ramp up in performance gains."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#introduction",
    "href": "posts/sparse_tensors/index.html#introduction",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "The canonical format for representing tensors in PyTorch is the dense tensor, with associated contiguous memory proportional to the size of the tensor. However, in many applications, the data is sparse, that is most of the elements are zero. In this notebook, we will see how to work efficiently with sparse tensors in PyTorch.\n\n\nA dataset is considered sparse when most of its elements are zero, for some features of the dataset. The exact threshold for considering a dataset as sparse is not strictly defined and can depend on the context and the specific application. A common rule of thumb is that a dataset is sparse if over 50% of its elements are zero.\nIn many real-world applications, datasets can be extremely sparse, with over 90% or even 99% of elements being zero. For example, in a user-item interaction matrix in a recommendation system, each user typically interacts with only a small fraction of all possible items, so the vast majority of the matrix elements are zero.\nIn PyTorch, datasets are stored in tensors. A tensor is a multi-dimensional array, similar to a NumPy array. PyTorch provides some support for sparse tensors.\n\n\n\nIn a dense tensor, all elements are stored in memory, even if most of them are zero. In a sparse tensor, only the non-zero elements are stored, along with their indices. This can lead to significant memory savings and/or faster compute times, especially for very sparse datasets.\nFor several tasks which are computing on the tensor, sparse tensors can be more efficient than dense tensors. For example, consider matrix multiplication. If the matrices are sparse, then sparse tensors can be orders of magnitude faster than dense tensors - as we will demonstrate at the end.\n\n\n\nIn PyTorch there are several ways to create sparse tensors as containers for sparse data. We will see how to create a sparse tensor from a dense tensor, and how to create a sparse tensor from different formats: COO, CSR, and CSC.\nFirst we‚Äôll need example data to work with - let‚Äôs use a graph dataset as an example to understand sparse tensors."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#example-graph-data",
    "href": "posts/sparse_tensors/index.html#example-graph-data",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Graph data is a commonly sparse. A graph is a collection of nodes (or vertices) and edges. The nodes represent entities, and the edges represent relationships between the entities. More often than not, graphs are sparse, i.e.¬†most of the nodes are not connected to each other. It is common to see datasets where less than 1% of the possible edges are present.\nThere are many ways to represent a Graph. One common is an adjacency matrix, A. This is particularly bad for sparse graphs, as most of the elements in the matrix are zero.\nThe adjacency matrix is a square matrix A, of size N x N, where N is the number of nodes in the graph. The element A[i, j] is 1 if there is an edge between node i and node j, and 0 otherwise. Since most nodes are not connected to each other, the adjacency matrix is sparse.\nAnother more memory-efficient way to represent a graph is using a tensor of edges, E. Each edge is represented as a 2 long column (r, s) in E, where r and s are the indices of the nodes connected by the edge. This representation is more memory-efficient than the adjacency matrix, as it only stores the non-zero elements, it‚Äôs size is 2 x number_edges.\nIn this notebook, we will see how to create a sparse tensor from an adjacency matrix, and how to create a sparse tensor from a list of edges. We will also see how to perform basic operations on sparse tensors, such as matrix multiplication and element-wise operations.\nLet‚Äôs consider an example from the ModelNet10 dataset.\n\n\nModelNet10 is a subset of the ModelNet dataset, which is a large-scale 3D CAD model dataset. ModelNet10 specifically consists of 10 categories, with a total of 4899 3D CAD models. The categories include: bed, chair, monitor, desk, dresser, sofa, table, toilet, night stand, and bathtub.\nEach 3D model in the dataset is represented as a graph, where each node represents a point in the 3D object, and each edge represents a relationship between the points. The adjacency matrix of the graph is sparse, as most of the points are not connected to each other.\nThis dataset is commonly used for benchmarking in tasks such as 3D object recognition, shape classification, and other machine learning tasks involving 3D data.\nLet‚Äôs look at a one: a Monitor from the training dataset. We‚Äôll need to install some libraries to visualize the 3D object.\n\n\nCode\n!pip -q install numpy matplotlib networkx\n\n\nThe data is in off format - that is nodes and edges making faces. The particular file can be found here. The corners of the monitor are the nodes and the edges are the connections between the corners. Here‚Äôs a plot using matplotlib and another with trimesh.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n\ndef read_off(file):\n    if 'OFF' != file.readline().strip():\n        raise('Not a valid OFF header')\n    n_verts, n_faces, _ = tuple(map(int, file.readline().strip().split(' ')))\n    verts = [[float(s) for s in file.readline().strip().split(' ')] for _ in range(n_verts)]\n    faces = [[int(s) for s in file.readline().strip().split(' ')[1:]] for _ in range(n_faces)]\n    return verts, faces\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Create a Poly3DCollection object\npolys = [np.array(verts)[face] for face in faces]\ncollection = Poly3DCollection(polys, linewidths=1, alpha=1)\ncollection.set_facecolor((0,0,1,0.5))  # Set the color of the object to blue\ncollection.set_edgecolor((0,0,1,0.5))  # Set the edge color to a darker blue\nax.add_collection3d(collection)\n\n# Add lighting\nax.add_collection3d(Poly3DCollection(polys, facecolors='r', linewidths=1, edgecolors='r', alpha=.20))\n\n# Remove the axes for a cleaner look\nax.axis('off')\n\n# Auto scale to the mesh size\nscale = np.array(verts).flatten()\nax.auto_scale_xyz(scale, scale, scale)\n\n# Add a title to the plot\nax.set_title('3D Model of Monitor')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip -q install trimesh\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport trimesh\n\n# Load the mesh from the OFF file\nmesh = trimesh.load_mesh('./data/monitor_0001.off')\n\n# Plot the mesh\nmesh.show()\n\n\n\n\n\nTo see this data as a graph, we will feed in vertices and faces into the networkx package.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n\ndef off_to_graph(verts, faces):\n    # Create a new graph\n    G = nx.Graph()\n    # Add nodes to the graph\n    for i in range(len(verts)):\n        G.add_node(i)\n    # Add edges to the graph\n    for face in faces:\n        for i in range(len(face)):\n            # Add an edge between each pair of vertices in the face\n            G.add_edge(face[i], face[(i+1)%len(face)])\n    return G\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\n\n\n\n\nCode\nprint(G)\n\n\nGraph with 798 nodes and 1476 edges\n\n\n\n\nCode\n# Draw the graph\nnx.draw(G, edge_color=\"black\", width=1, node_size=5, with_labels=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nSo, that‚Äôs the graph. It‚Äôs difficult to make out the shape of the monitor from the plot above, as we‚Äôre not representing the features of the nodes (3d co-ordinates).\nWhat we can do is list out the edges and vertices of the graph. First in edge list format with the corresponding nodes.\n\n\nCode\nfor index, edge in enumerate(G.edges(), start=0):\n    print(edge, end=\", \")\n    if index == 9:\n        break\n\n\n(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (3, 4), (4, 5), (4, 6), \n\n\n\n\nCode\nfor index, edge in enumerate(G.nodes(), start=0):\n    print(edge, end=\", \")\n    if index == 9:\n        break\n\n\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, \n\n\nAnd then as a an adjacency matrix.\n\n\nCode\nA = nx.to_numpy_array(G)\n\n\n\n\nCode\nA.shape\n\n\n(798, 798)\n\n\n\n\nCode\nprint(A)\n\n\n[[0. 1. 1. ... 0. 0. 0.]\n [1. 0. 1. ... 0. 0. 0.]\n [1. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 1. 1.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]]\n\n\nLet‚Äôs verify that the number of edges match the adjacency matrix and edge list view.\n\n\nCode\nA.sum()/2 == len(G.edges()) # The number of edges.\n\n\nTrue"
  },
  {
    "objectID": "posts/sparse_tensors/index.html#sparse-adjacency",
    "href": "posts/sparse_tensors/index.html#sparse-adjacency",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "The adjacency is sparse. We can quantify this sparsity - the ratio of the number of non-zero elements to the total number of elements in the tensor.\n\n\nCode\n# the ratio of the number of non-zero elements to the total number of elements in the tensor A.\nnp.count_nonzero(A) / (A.shape[0] * A.shape[1])\n\n\n0.004635649273559839\n\n\nStoring data in this format is inefficient. We can convert it to a sparse tensor. We‚Äôll create functions for popular formats, as well as look at the native PyTorch implementations."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#sparse-formats",
    "href": "posts/sparse_tensors/index.html#sparse-formats",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Some well known sparse tensor representation formats are:\n\nCoordinate (COO)\nCompressed Sparse Row (CSR)\nCompressed Sparse Column (CSC)\nBlock Compressed Sparse Row (BSR)\nDictionary of Keys (DOK)\nList of Lists (LIL)\n\nWe‚Äôll look at COO, CSR, and CSC formats.\nThe monitor graph is too large and sparse for illustration purposes. We‚Äôll create a smaller graph to demonstrate the conversion back and forth to sparse tensors.\n\n\nCode\n# Create a new graph\nG = nx.Graph()\n\n# Add some edges to the graph\nG.add_edge(0, 1)\nG.add_edge(0, 2)\nG.add_edge(3, 4)\n\n# Draw the graph\nnx.draw(G, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip -q install torch\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport torch\n\nA = nx.to_numpy_array(G)\nprint(torch.from_numpy(A))\nA_torch = torch.from_numpy(A).bool()\nA_torch\n\n\ntensor([[0., 1., 1., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0.]], dtype=torch.float64)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\nCode\nA.sum()/2\n\n\n3.0\n\n\nLet‚Äôs express as a pandas dataframe with source and target nodes for edges.\n\n\nCode\npip -q install pandas\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\n# Get the number of nodes\nnum_nodes = A_torch.shape[0]\n\n# Create a list of all pairs of nodes\nsource_node, destination_node = np.meshgrid(np.arange(num_nodes), np.arange(num_nodes))\n\n# Flatten the arrays\nsource_node = source_node.flatten()\ndestination_node = destination_node.flatten()\n\n# Get the edge values\nhas_edge = A_torch[source_node, destination_node] &gt; 0\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\n\ndf\n\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n0\nFalse\n\n\n1\n1\n0\nTrue\n\n\n2\n2\n0\nTrue\n\n\n3\n3\n0\nFalse\n\n\n4\n4\n0\nFalse\n\n\n5\n0\n1\nTrue\n\n\n6\n1\n1\nFalse\n\n\n7\n2\n1\nFalse\n\n\n8\n3\n1\nFalse\n\n\n9\n4\n1\nFalse\n\n\n10\n0\n2\nTrue\n\n\n11\n1\n2\nFalse\n\n\n12\n2\n2\nFalse\n\n\n13\n3\n2\nFalse\n\n\n14\n4\n2\nFalse\n\n\n15\n0\n3\nFalse\n\n\n16\n1\n3\nFalse\n\n\n17\n2\n3\nFalse\n\n\n18\n3\n3\nFalse\n\n\n19\n4\n3\nTrue\n\n\n20\n0\n4\nFalse\n\n\n21\n1\n4\nFalse\n\n\n22\n2\n4\nFalse\n\n\n23\n3\n4\nTrue\n\n\n24\n4\n4\nFalse\n\n\n\n\n\n\n\n\n\nThe COO format is simple and flexible for sparse matrices. It consists of three arrays: row, col, and data. The row array contains the row indices of the non-zero elements, the col array contains the column indices of the non-zero elements, and the data array contains the values of the non-zero elements.\nLuckily, PyTorch has built in methods for converting between dense and sparse tensors. We can convert the adjacency matrix to a COO sparse tensor using the .to_sparse() method.\n\n\nCode\nA_coo_pytorch = A_torch.to_sparse()\nA_coo_pytorch\n\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\nAnd convert back\n\n\nCode\nA_coo_pytorch.to_dense()\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nLet‚Äôs look at the sparse tensor as a dataframe of source to destination nodes, but this time only for those pairs where there is an edge.\n\n\nCode\n# Get the source and destination nodes and the edge values\nsource_node = A_coo_pytorch.indices()[0].numpy()\ndestination_node = A_coo_pytorch.indices()[1].numpy()\nhas_edge = A_coo_pytorch.values().numpy()\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\ndf\n\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n1\nTrue\n\n\n1\n0\n2\nTrue\n\n\n2\n1\n0\nTrue\n\n\n3\n2\n0\nTrue\n\n\n4\n3\n4\nTrue\n\n\n5\n4\n3\nTrue\n\n\n\n\n\n\n\nWriting our own homebrew function to convert to COO format, is straightforward.\n\n\nCode\ndef to_sparse(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor).t()\n    # Get the values of the non-zero elements\n    values = tensor[indices[0], indices[1]]  # assuming 2D tensor\n    # Get the size of the original tensor\n    size = tensor.size()\n    # Create a sparse tensor\n    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n    return sparse_tensor\n\n\n\n\nCode\nto_sparse(A_torch)\n\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\n\n\nCode\ndef to_dense(sparse_tensor):\n    # Get the size of the original tensor\n    size = sparse_tensor.size()\n    # Get the indices and values from the sparse tensor\n    indices = sparse_tensor.coalesce().indices()\n    values = sparse_tensor.coalesce().values()\n    # Create a dense tensor of the same size and data type as values, initialized with zeros\n    dense_tensor = torch.zeros(size, dtype=values.dtype)\n    # Convert indices to a tuple of tensors\n    indices_tuple = tuple(indices[i] for i in range(indices.shape[0]))\n    # Use index_put_ to put the values in the dense tensor at the right indices\n    dense_tensor.index_put_(indices_tuple, values, accumulate=False)\n    return dense_tensor\n\n\n\n\nCode\nto_dense(A_coo_pytorch)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nCSR is an even more efficient compact format for sparse data. Details can be found here.\nValues and column indices are stored in the same way as COO format. The row indices are stored in a separate array, which can seem strange at first glance.\nBroadly it relies on slicing the values into per row chunks. The row chunk lengths are calculated as the difference between the row indices of the non-zero elements. The row chunk lengths are stored in a separate array, row_ptr.\nSo, if your original matrix has m rows, n columns, and nnz non-zero values, then:\n\nThe shape of values is [nnz].\nThe shape of column_indices is [nnz].\nThe shape of row_pointers is [m+1].\n\nIn index notation, the row pointer array is defined as:\nrow_ptr[i] = row_ptr[i-1] + number of non-zero elements in row i-1\nSo, the row pointer array stores the cumulative sum of the number of non-zero elements in each row.\nthe row and column number can be determined by the index of the non-zero element in the values array. That is the i-th non-zero element (in the values array) is at row row_ptr[i] and column col[i]. That is:\nvalues[i] = A[row_ptr[i], col[i]]\n\n\nCode\nA_torch.to_sparse_csr()\n\n\ntensor(crow_indices=tensor([0, 2, 3, 4, 5, 6]),\n       col_indices=tensor([1, 2, 0, 0, 4, 3]),\n       values=tensor([True, True, True, True, True, True]), size=(5, 5), nnz=6,\n       layout=torch.sparse_csr)\n\n\nWhich can be recovered by chaining with the .to_dense() method.\n\n\nCode\nA_torch.to_sparse_csr().to_dense()\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nAnd here we write our homebrew version of to_csr() and from_csr() functions:\n\n\nCode\ndef to_csr(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor, as_tuple=True)\n    # Get the values of the non-zero elements\n    values = tensor[indices]\n    # Get the column indices of the non-zero elements\n    column_indices = indices[1]\n    # Get the row pointers\n    row_pointers = torch.zeros(tensor.size(0) + 1, dtype=torch.long)\n    row_pointers[1:] = torch.bincount(indices[0])\n    row_pointers = torch.cumsum(row_pointers, dim=0)\n\n    return values, column_indices, row_pointers\n\n\n\n\nCode\nto_csr(A_torch)\n\n\n(tensor([True, True, True, True, True, True]),\n tensor([1, 2, 0, 0, 4, 3]),\n tensor([0, 2, 3, 4, 5, 6]))\n\n\n\n\nCode\ndef from_csr(values, column_indices, row_pointers):\n    # Get the number of rows and columns\n    num_rows = row_pointers.size(0) - 1\n    num_cols = torch.max(column_indices).item() + 1\n    # Create a dense tensor of the right size, initialized with zeros\n    tensor = torch.zeros((num_rows, num_cols), dtype=values.dtype)\n    # Loop over the rows\n    for i in range(num_rows):\n        # Get the start and end indices for this row in the values and column_indices arrays\n        start = row_pointers[i].item()\n        end = row_pointers[i + 1].item()\n        # Set the values in the dense tensor for this row\n        tensor[i, column_indices[start:end]] = values[start:end]\n\n    return tensor\n\n\n\n\nCode\nfrom_csr(*to_csr(A_torch))\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nThe CSC format is similar to the CSR format, but with the rows and columns swapped. The values and row indices are stored in the same way as the CSR format. The column indices are stored in a separate array, col_ptr.\nThis format is efficient for certain slicing operations, such as extracting a column from a matrix."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#memory-usage-speed-up-with-sparse-tensors-on-the-monitor-graph",
    "href": "posts/sparse_tensors/index.html#memory-usage-speed-up-with-sparse-tensors-on-the-monitor-graph",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Let‚Äôs see how much faster it is to perform matrix multiplication on the sparse tensor compared to the dense tensor. For this we‚Äôll use the ModelNet10 monitor graph seen earlier.\n\n\nCode\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\nA = nx.adjacency_matrix(G)\nA\n\n\n&lt;798x798 sparse array of type '&lt;class 'numpy.int64'&gt;'\n    with 2952 stored elements in Compressed Sparse Row format&gt;\n\n\nA is already a sparse matrix, but in numpy. We‚Äôll convert it to a PyTorch dense tensor first.\n\n\nCode\nA_dense = torch.from_numpy(A.toarray())\nA_dense.shape\n\n\ntorch.Size([798, 798])\n\n\n\n\nCode\ndef tensor_memory_usage_str(tensor=None):\n    if tensor is None:\n        return \"No tensor provided\"\n    bytes = tensor.element_size() * tensor.nelement()\n    kilobytes = bytes / 1024\n    return f\"Memory usage: {bytes} bytes ({kilobytes} KB)\"\n\n\n\n\nCode\ntensor_memory_usage_str(A_dense)\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\n\n\nCode\ntensor_memory_usage_str(A_dense.to_sparse())\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nSomewhat unexpectedly, the sparse and dense tensors have the same memory usage.\n\n\nCode\nA_sparse = A_dense.to_sparse_csr()\n\n\n\n\nCode\ntensor_memory_usage_str(A_sparse)\n\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nOK, so there was no improvement in memory usage for this particular case. Let‚Äôs time the matrix multiplication operations.\n\n\nCode\nimport timeit\n\n\ndef multiply_tensors():\n    return A_dense @ A_dense\n\nnum_runs = 10\ntime_taken_dense = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken_dense} seconds\")\n\n\nTime taken by my_function over 10 runs: 2.746476124972105 seconds\n\n\n\n\nCode\nA_coo = A\n\ndef multiply_tensors():\n    return A_coo@A_coo\n\nnum_runs = 10\ntime_taken_sparse = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken_sparse} seconds\")\n\n\nTime taken by my_function over 10 runs: 0.0038774579879827797 seconds\n\n\n\n\nCode\nf\"Speedup: {time_taken_dense / time_taken_sparse}x\"\n\n\n'Speedup: 708.3187318815902x'\n\n\nWith CSR encoding of sparse tensors, it might be even better - however I‚Äôm on Apple Silicon, and the csr sparse tensor support is not yet available for this architecture."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#conclusion",
    "href": "posts/sparse_tensors/index.html#conclusion",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "We just saw how to work with sparse tensors in PyTorch. We created a sparse tensor from an adjacency matrix and a list of edges, and converted it to different sparse formats. We also saw the performance benefits of using sparse tensors for matrix multiplication. There‚Äôs a lot more to sparsity, and PyTorch is actively developing its sparse tensor support. Things will break, but expect ramp up in performance gains."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To Synthetic Musings",
    "section": "",
    "text": "This is the first blog entry by me Ravi (@project-delphi). Welcome!"
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html",
    "href": "posts/train-dev-test-splits/index.html",
    "title": "Train Dev Test Data Splits",
    "section": "",
    "text": "Made with ‚ù§Ô∏è and GitHub Copilot"
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#introduction",
    "href": "posts/train-dev-test-splits/index.html#introduction",
    "title": "Train Dev Test Data Splits",
    "section": "Introduction",
    "text": "Introduction\nFor good machine learning, selecting the right model and properly splitting your data are crucial steps for success. We explore the process of model selection, drawing parallels between machine learning models and biological [speciation]https://project-delphi.github.io/ml-blog/posts/model-speciation/), and delves into the details of data splitting and hyperparameter tuning."
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#model-selection-an-evolutionary-perspective",
    "href": "posts/train-dev-test-splits/index.html#model-selection-an-evolutionary-perspective",
    "title": "Train Dev Test Data Splits",
    "section": "Model Selection: An Evolutionary Perspective",
    "text": "Model Selection: An Evolutionary Perspective\nTo understand model selection better, let‚Äôs recap an analogy to biological evolution:\n\nModels are like different species\nData represents the environment\nThe score function is akin to survival fitness\n\n\nThe Learning Process\n\nModels start in an ‚Äúnewborn state‚Äù - they begin with random or preset parameters.\nThey mature and learn by adjusting their parameters based on the training data and available compute resources.\nThe learning process follows a predefined path, often using first-order approximations (like Taylor series) and techniques such as stochastic gradient descent (SGD).\nThe goal is to optimize an appropriate loss function, which guides the model‚Äôs adaptation to the data.\n\n\n\nHyperparameters: The Subspecies of Models\nIf models are species, then different hyperparameter configurations can be thought of as subspecies:\n\nEvaluation depends on the score function, similar to how a species‚Äô success depends on its ability to survive in a specific environment.The score function is chosen to reflect the ‚Äúsurvival task‚Äù. It could be the same as the loss function, but often is not.\nWell-chosen hyperparameters allow the model to adapt effectively to the given data and task.\nThe scoring ‚Äúenvironment‚Äù is the validation data, and the fitness‚Äù is determined by the score function.\n\nUnlike model parameters, hyperparameters cannot be ‚Äúlearned‚Äù directly from the data. Instead, they are selected through a process of trial and error, guided by the model‚Äôs performance on the validation set. (The trial and error search can be random, but nowadays, more sophisticated methods like Bayesian optimization are often used.)"
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#the-importance-of-data-splitting",
    "href": "posts/train-dev-test-splits/index.html#the-importance-of-data-splitting",
    "title": "Train Dev Test Data Splits",
    "section": "The Importance of Data Splitting",
    "text": "The Importance of Data Splitting\nBefore we dive deeper into model selection, it‚Äôs essential to understand the concept of data splitting. We typically divide our dataset into three parts:\n\nTraining set\nDevelopment (Validation) set\nTest set\n\n\nWhy Split the Data?\nSplitting the data serves several purposes: - The training set is used to teach the model. - The validation set helps us tune the model and select the best hyperparameters. - The test set provides an unbiased evaluation of the final model‚Äôs performance.\n\n\nFactors Affecting Data Splitting\nThe way we split our data can significantly impact our model‚Äôs performance. Let‚Äôs explore how this split changes based on various factors:\n\n1. Amount of Data (n)\n\nSmall datasets (n &lt; 1,000): Allocate a larger proportion to the training set.\nMedium datasets (1,000 &lt; n &lt; 100,000): More balanced allocation.\nLarge datasets (n &gt; 100,000): Can maintain large training sets while also having substantial validation and test sets.\n\n\n\n2. Noise in the Data\n\nLow noise: Fewer examples needed in validation and test sets.\nHigh noise: Larger validation and test sets to average out the noise.\n\n\n\n3. Richness of Structure in the Data\n\nSimple structure: Smaller training sets, larger validation and test sets.\nComplex structure: Larger training sets to learn intricate patterns.\n\n\n\n\nData Split Table\nHere‚Äôs a table suggesting possible splits for different dataset sizes, assuming moderate noise and complexity:\n\n\n\n\n\n\n\n\n\n\nDataset Size (n)\nTraining Set\nValidation Set\nTest Set\nExample Models/Datasets\n\n\n\n\n100\n70-80%\n10-15%\n10-15%\nSmall custom datasets, toy problems\n\n\n1,000\n70-75%\n15-20%\n10-15%\nIris dataset, small NLP tasks\n\n\n10,000\n70-75%\n15-20%\n10-15%\nMNIST, small to medium Kaggle competitions\n\n\n100,000\n70-80%\n10-15%\n10-15%\nCIFAR-100, medium-sized NLP tasks\n\n\n1 million\n80-85%\n5-10%\n5-10%\nImageNet, large NLP datasets\n\n\n1 billion\n90-95%\n2.5-5%\n2.5-5%\nVery large language models, recommendation systems\n\n\n\n\n\nExamples of Well-Known Models and Their Data Splits\n\nMNIST (70,000 images)\n\nTraining: 60,000 (85.7%)\nTest: 10,000 (14.3%)\nNote: Often, users create their own validation set from the training data.\n\nImageNet (1.2 million images)\n\nTraining: 1,281,167 (85.4%)\nValidation: 50,000 (3.3%)\nTest: 100,000 (6.7%)\n\nBERT (BookCorpus + English Wikipedia, ~3.3 billion words)\n\nUsed a 90-10 split for pre-training and fine-tuning\nExact validation and test set sizes vary by downstream task\n\nGPT-3 (Trained on 300 billion tokens)\n\nTraining: Vast majority of the data\nTest: Varies by task, but typically small (&lt; 1%)\nNote: Uses few-shot learning, so traditional splits are less applicable\n\nNetflix Prize Dataset (~100 million ratings)\n\nTraining: 98,074,901 (98.1%)\nTest: 1,408,395 (1.4%)\nProbe set (public test): 1,408,395 (1.4%)"
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#implementing-data-splitting-in-popular-libraries",
    "href": "posts/train-dev-test-splits/index.html#implementing-data-splitting-in-popular-libraries",
    "title": "Train Dev Test Data Splits",
    "section": "Implementing Data Splitting in Popular Libraries",
    "text": "Implementing Data Splitting in Popular Libraries\nLet‚Äôs look at how to implement data splitting in three popular machine learning libraries: scikit-learn, Keras, and PyTorch.\n\n\nCode\n# install dependencies\n!pip --quiet install datasets tensorflow pandas scikit-learn gdown optuna\n\n\nWe‚Äôll use sentiment140 as our example data, hosted on huggingface by the stanfordnlp group, a dataset of tweets labeled as positive or negative, for our examples. The dataset contains 1.6 million tweets.\nThe dataset comes pre-split into training and test sets, so we will be a bit contrived and first combine the data splits, before using the combined data to demonstrate the splitting process with some popular libraries.\n\n\nCode\nimport os\nfrom datasets import load_dataset, concatenate_datasets\nimport pandas as pd\n\n# Set the environment variable to disable the prompt\nos.environ['HF_DATASETS_OFFLINE'] = '1'\n\n# Load the train and test splits\ntrain_dataset = load_dataset('sentiment140', split='train')\ntest_dataset = load_dataset('sentiment140', split='test')\n\n# Concatenate the splits\ncombined_dataset = concatenate_datasets([train_dataset, test_dataset])\n\n# Shuffle the combined dataset\nshuffled_dataset = combined_dataset.shuffle(seed=42)\n\n# Convert to a DataFrame\ndf = shuffled_dataset.to_pandas()\n\n# Separate features (X) and target (y)\nX = df.drop(columns=['sentiment'])\ny = df['sentiment']\n\n# Print the first 5 examples\nprint(X.head())\nprint(X.shape)\nprint(y.head())\nprint(y.shape)\n\n\n                                                text  \\\n0   External HDD crashed !!! Volumes of data lost      \n1  @R33S Are you going to her concert in Sydney? ...   \n2  not as good at super smash bros 64 as I remember    \n3  I want a convertible. A nice black one - hard ...   \n4  nooooo! why isn't Public Enemies being release...   \n\n                           date      user     query  \n0  Sun May 31 10:10:40 PDT 2009  twishmay  NO_QUERY  \n1  Sun May 17 01:20:02 PDT 2009    iB3nji  NO_QUERY  \n2  Fri Jun 05 23:48:43 PDT 2009    bendur  NO_QUERY  \n3  Sat May 30 11:46:52 PDT 2009      ihug  NO_QUERY  \n4  Wed Jun 24 23:16:39 PDT 2009   jssavvy  NO_QUERY  \n(1600498, 4)\n0    0\n1    4\n2    0\n3    4\n4    0\nName: sentiment, dtype: int32\n(1600498,)\n\n\nGiven this data size, of roughly 1.6 million tweets, we will use the following splits:\n\n\n\nSplit\nPercentage\nNumber of Examples\n\n\n\n\nTrain\n80%\n1,280,398\n\n\nDev\n10%\n160,050\n\n\nTest\n10%\n160,050\n\n\n\nThis split works with the rule of thumb and is a common practice in the industry. Because of the noise in the data, we want to ensure that we have enough examples in the validation and test sets to get a good estimate of the model‚Äôs performance, so we could have increased the size of the validation and test sets. However, for the sake of simplicity, we will stick with this split.\n\nScikit-learn\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into train and temporary sets (80% train, 20% temp)\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Split the temporary set into validation (dev) and test sets (50% dev, 50% test of the remaining 20%)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Calculate the number of examples\ntotal_examples = len(X)\ntrain_examples = len(X_train)\nval_examples = len(X_val)\ntest_examples = len(X_test)\n\n# Calculate the percentages\ntrain_percentage = (train_examples / total_examples) * 100\nval_percentage = (val_examples / total_examples) * 100\ntest_percentage = (test_examples / total_examples) * 100\n\n# Create a DataFrame to store the split information\nsplit_info = pd.DataFrame({\n    'Split': ['Train', 'Dev', 'Test'],\n    'Percentage': [f'{train_percentage:.2f}%', f'{val_percentage:.2f}%', f'{test_percentage:.2f}%'],\n    'Number of Examples': [train_examples, val_examples, test_examples]\n})\n\n# Print the DataFrame\nprint(split_info)\n\n\n   Split Percentage  Number of Examples\n0  Train     80.00%             1280398\n1    Dev     10.00%              160050\n2   Test     10.00%              160050\n\n\n\n\nKeras\nLet‚Äôs do it in Keras now. We‚Äôll use a different dataset - Fashion-MNIST.\nThis is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST.\n\n\nCode\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Load the Fashion MNIST dataset\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n\n# Split the full training set into train and dev sets (80% train, 20% dev)\nX_train, X_dev, y_train, y_dev = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n\n# Calculate the number of examples\ntotal_examples = len(X_train_full) + len(X_test)\ntrain_examples = len(X_train)\ndev_examples = len(X_dev)\ntest_examples = len(X_test)\n\n# Calculate the percentages\ntrain_percentage = (train_examples / total_examples) * 100\ndev_percentage = (dev_examples / total_examples) * 100\ntest_percentage = (test_examples / total_examples) * 100\n\n# Create a DataFrame to store the split information\nsplit_info = pd.DataFrame({\n    'Split': ['Train', 'Dev', 'Test'],\n    'Percentage': [f'{train_percentage:.2f}%', f'{dev_percentage:.2f}%', f'{test_percentage:.2f}%'],\n    'Number of Examples': [train_examples, dev_examples, test_examples]\n})\n\n# Print the DataFrame\nprint(split_info)\n\n# Print the shapes of the splits\nprint(f\"Train set shape: {X_train.shape}, {y_train.shape}\")\nprint(f\"Dev set shape: {X_dev.shape}, {y_dev.shape}\")\nprint(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 2us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 1us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5s 1us/step\n   Split Percentage  Number of Examples\n0  Train     68.57%               48000\n1    Dev     17.14%               12000\n2   Test     14.29%               10000\nTrain set shape: (48000, 28, 28), (48000,)\nDev set shape: (12000, 28, 28), (12000,)\nTest set shape: (10000, 28, 28), (10000,)\n\n\n\n\nPyTorch\n\n\nCode\nimport torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\n\n# Define the transform (resizing, converting to tensor, normalization)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize all images to 224x224\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Download and load the Caltech-101 dataset\ndataset = datasets.Caltech101(root='data', download=True, transform=transform)\n\n# Split dataset into train (80%), dev (10%), and test (10%)\ntrain_size = int(0.8 * len(dataset))\ndev_size = int(0.1 * len(dataset))\ntest_size = len(dataset) - train_size - dev_size\n\ntrain_set, dev_set, test_set = random_split(dataset, [train_size, dev_size, test_size])\n\n# Create DataLoaders for each set\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\ndev_loader = DataLoader(dev_set, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n\nfor images, labels in train_loader:\n    print(images.shape)\n    print(labels)\n    break \n\n\nFiles already downloaded and verified\ntorch.Size([32, 3, 224, 224])\ntensor([37, 76, 82,  3,  3, 87,  0, 55,  5,  2,  2,  5, 79, 94, 74, 14, 78,  3,\n         3, 86, 54,  5, 68, 28,  3,  0, 21, 61, 85, 31, 56,  0])\n\n\n\n\nHugging Face\n\n\nCode\nfrom datasets import load_dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Load the emotion dataset\ndataset = load_dataset('emotion')\n\n# Convert the dataset to a pandas DataFrame\ndf = pd.DataFrame(dataset['train'])\n\n# Split the dataset into train and dev sets (80% train, 20% dev)\ntrain_df, dev_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Convert the DataFrames back to Hugging Face datasets\ntrain_dataset = DatasetDict({'train': dataset['train'].select(train_df.index)})\ndev_dataset = DatasetDict({'dev': dataset['train'].select(dev_df.index)})\ntest_dataset = DatasetDict({'test': dataset['test']})\n\n# Calculate the number of examples\ntotal_examples = len(dataset['train']) + len(dataset['test'])\ntrain_examples = len(train_dataset['train'])\ndev_examples = len(dev_dataset['dev'])\ntest_examples = len(test_dataset['test'])\n\n# Calculate the percentages\ntrain_percentage = (train_examples / total_examples) * 100\ndev_percentage = (dev_examples / total_examples) * 100\ntest_percentage = (test_examples / total_examples) * 100\n\n# Create a DataFrame to store the split information\nsplit_info = pd.DataFrame({\n    'Split': ['Train', 'Dev', 'Test'],\n    'Percentage': [f'{train_percentage:.2f}%', f'{dev_percentage:.2f}%', f'{test_percentage:.2f}%'],\n    'Number of Examples': [train_examples, dev_examples, test_examples]\n})\n\n# Print the DataFrame\nprint(split_info)\n\n# Print the sizes of the splits\nprint(f\"Train set size: {train_examples}\")\nprint(f\"Dev set size: {dev_examples}\")\nprint(f\"Test set size: {test_examples}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   Split Percentage  Number of Examples\n0  Train     71.11%               12800\n1    Dev     17.78%                3200\n2   Test     11.11%                2000\nTrain set size: 12800\nDev set size: 3200\nTest set size: 2000"
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#hyperparameter-tuning-and-bayesian-optimization",
    "href": "posts/train-dev-test-splits/index.html#hyperparameter-tuning-and-bayesian-optimization",
    "title": "Train Dev Test Data Splits",
    "section": "Hyperparameter Tuning and Bayesian Optimization",
    "text": "Hyperparameter Tuning and Bayesian Optimization\nChoosing the right hyperparameters is crucial for model performance. While grid search and random search are common methods for hyperparameter tuning, Bayesian optimization has emerged as a more efficient alternative, especially for computationally expensive models.\n\nUnderstanding Bayesian Optimization\nBayesian optimization is a sequential design strategy for global optimization of black-box functions. In the context of machine learning, it‚Äôs used to find the best hyperparameters for a given model.\nKey concepts in Bayesian optimization include:\n\nSurrogate Model: A probabilistic model (often Gaussian Process) that approximates the true objective function (model performance).\nAcquisition Function: A function that determines which hyperparameter configuration to try next, balancing exploration (trying new areas) and exploitation (focusing on promising areas).\nObjective Function: The function we‚Äôre trying to optimize, typically the model‚Äôs performance on a validation set.\n\n\n\nHow Bayesian Optimization Works\n\nInitialize with a few random hyperparameter configurations and evaluate their performance.\nFit a surrogate model to these observations.\nUse the acquisition function to determine the next promising hyperparameter configuration to try.\nEvaluate the objective function at this new point.\nUpdate the surrogate model with the new observation.\nRepeat steps 3-5 for a specified number of iterations or until a stopping criterion is met.\n\n\n\nAdvantages of Bayesian Optimization\n\nMore efficient than grid or random search, especially for expensive-to-evaluate objective functions.\nCan handle complex hyperparameter spaces with dependencies between parameters.\nProvides uncertainty estimates for its predictions, allowing for more informed decisions.\n\n\n\nImplementing Bayesian Optimization\nThere are a few well-known libraries for implementing Bayesian optimization in Python, including * hyperopt * keras-tuner * optuna\nThese libraries provide easy-to-use interfaces for optimizing hyperparameters of machine learning models.\nHere‚Äôs a simple example using the optuna library to perform Bayesian optimization for a Random Forest Classifier from scikit-learn.\n\n\nCode\nimport optuna\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Step 2: Load the dataset\ndata = load_iris()\nX, y = data.data, data.target\n\n# Step 3: Define the objective function\ndef objective(trial):\n    # Define the hyperparameter search space\n    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n    max_depth = trial.suggest_int('max_depth', 1, 10)\n    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n    \n    # Create the model with the suggested hyperparameters\n    model = RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        min_samples_leaf=min_samples_leaf,\n        bootstrap=bootstrap,\n        random_state=42\n    )\n    \n    # Perform cross-validation and return the mean score\n    score = cross_val_score(model, X, y, cv=3, n_jobs=1, scoring='accuracy').mean()\n    return score\n\n# Step 4: Create a study and optimize the objective function\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\n\n# Step 5: Print the results\nprint(f\"Best hyperparameters: {study.best_params}\")\nprint(f\"Best cross-validated score: {study.best_value}\")\n\n\n[I 2024-09-19 19:33:06,430] A new study created in memory with name: no-name-32e3b206-2b7e-49ad-81fb-252e23db6c6f\n[I 2024-09-19 19:33:06,510] Trial 0 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 71, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.9533333333333333.\n[I 2024-09-19 19:33:06,550] Trial 1 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 29, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 0 with value: 0.9533333333333333.\n[I 2024-09-19 19:33:06,628] Trial 2 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 63, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 2 with value: 0.9666666666666667.\n[I 2024-09-19 19:33:06,675] Trial 3 finished with value: 0.6999999999999998 and parameters: {'n_estimators': 56, 'max_depth': 1, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 2 with value: 0.9666666666666667.\n[I 2024-09-19 19:33:06,720] Trial 4 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:06,802] Trial 5 finished with value: 0.94 and parameters: {'n_estimators': 96, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:06,851] Trial 6 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 38, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:06,953] Trial 7 finished with value: 0.9333333333333332 and parameters: {'n_estimators': 85, 'max_depth': 1, 'min_samples_split': 10, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,026] Trial 8 finished with value: 0.94 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,081] Trial 9 finished with value: 0.94 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,143] Trial 10 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 40, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,208] Trial 11 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 45, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,236] Trial 12 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 13, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,268] Trial 13 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 17, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,356] Trial 14 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,403] Trial 15 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,502] Trial 16 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,573] Trial 17 finished with value: 0.96 and parameters: {'n_estimators': 49, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,619] Trial 18 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 28, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,718] Trial 19 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 70, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,793] Trial 20 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,884] Trial 21 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:07,992] Trial 22 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 80, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,076] Trial 23 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,136] Trial 24 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 38, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,231] Trial 25 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,288] Trial 26 finished with value: 0.94 and parameters: {'n_estimators': 53, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,393] Trial 27 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 78, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,455] Trial 28 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 42, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,485] Trial 29 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 21, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,538] Trial 30 finished with value: 0.96 and parameters: {'n_estimators': 33, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,608] Trial 31 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,677] Trial 32 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 45, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,730] Trial 33 finished with value: 0.96 and parameters: {'n_estimators': 33, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,772] Trial 34 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 23, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,839] Trial 35 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 45, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,900] Trial 36 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 57, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:08,955] Trial 37 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 38, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,007] Trial 38 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 32, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,056] Trial 39 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 42, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,183] Trial 40 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 97, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,254] Trial 41 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 49, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,324] Trial 42 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 47, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,401] Trial 43 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,465] Trial 44 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 43, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,541] Trial 45 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,627] Trial 46 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 61, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,673] Trial 47 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 36, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,719] Trial 48 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 25, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n[I 2024-09-19 19:33:09,783] Trial 49 finished with value: 0.9733333333333333 and parameters: {'n_estimators': 41, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 4 with value: 0.9733333333333333.\n\n\nBest hyperparameters: {'n_estimators': 34, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}\nBest cross-validated score: 0.9733333333333333\n\n\n\n\nWhen to Use Bayesian Optimization\nBayesian optimization is particularly useful when:\n\nThe objective function is expensive to evaluate (e.g., training deep neural networks).\nThe hyperparameter space is complex or high-dimensional.\nYou have a limited budget for hyperparameter tuning.\n\nHowever, for simpler models or when you have ample computational resources, simpler methods like grid search or random search might be sufficient."
  },
  {
    "objectID": "posts/train-dev-test-splits/index.html#conclusion",
    "href": "posts/train-dev-test-splits/index.html#conclusion",
    "title": "Train Dev Test Data Splits",
    "section": "Conclusion",
    "text": "Conclusion\nChoosing the right data split and tuning hyperparameters are crucial steps in the machine learning pipeline. By considering factors such as dataset size, noise levels, and data complexity, you can optimize your split to balance between model training and performance estimation. Remember, these are guidelines, and the best split for your project may require some experimentation and adjustment.\nAs you work with larger datasets, you might find that you can allocate smaller percentages to validation and test sets while still maintaining statistical significance. However, always ensure that your validation and test sets are large enough to provide reliable performance estimates for your specific problem.\nBy understanding the relationships between models, data, and hyperparameters, implementing effective data splitting strategies, and utilizing advanced techniques like Bayesian optimization for hyperparameter tuning, you can make more informed decisions and develop more effective machine learning solutions."
  }
]
