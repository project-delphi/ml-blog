[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To Synthetic Musings",
    "section": "",
    "text": "This is the first blog entry by me Ravi (@project-delphi). Welcome!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code and Plot",
    "section": "",
    "text": "Letâ€™s see if blogging with code and plots works here:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(0, 10, 100)\n\nfig = plt.figure()\nplt.plot(x, np.sin(x), '-')\nplt.plot(x, np.cos(x), '--')\n\n\n\n\n\n\n\n\n\n\nkindly taken from Jake Vanderplasâ€™s blog\n\nSuccess!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Synthetic Musings",
    "section": "",
    "text": "Featured Writing\n\n\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nApr 11, 2024\n\n\nSparsity with PyTorch Tensors\n\n\n9 min\n\n\n\n\n\n\n\nMar 3, 2024\n\n\nDeveloping Pytorch Geometric on M1 Apple Silicon\n\n\n7 min\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nPost With Code and Plot\n\n\n1 min\n\n\n\n\n\n\n\nFeb 6, 2024\n\n\nWelcome To Synthetic Musings\n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "",
    "text": "TLDR: My investigation indicates that the library pytorch geometric (also referred to as pyg, using package name torch_geometric) on Apple Silicon (AS) - particularly the M1 chip - has partial developer support.\nA bit more: It is now feasible to perform a full developer installation of torch_geometric using PyTorch on AS with Appleâ€™s native GPU compute framework, Metal Performance Shaders - mps - (which includes its own kind of embedded BLAS). The only remaining challenge is testing with a developer installation. The test suite does not currently build for AS.\nIâ€™ve been talking with the pyg-team and they are interested in supporting AS more fully. Itâ€™s a matter of time and resources. rusty1s (the lead developer) has been very helpful and responsive, adding a test runner for Apple Silicon."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#user-installation",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#user-installation",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "User Installation",
    "text": "User Installation\nThe installation of the package as a user, utilizing a wheels distribution, is generally straightforward across most CPU/GPU architectures, including AS. Here are the steps:\n\nCheck for conda, install if missing.\nEstablish a clean Python virtual environment.\nActivate the newly created virtual environment.\nInstall the latest version of PyTorch.\nProceed with the installation of PyTorch Geometric.\nCheck that it imports without errors.\n\nThereâ€™s a gist of what worked for me. The cell below uses the %load magic command to load the bash script into the code cell, followed by running it with insertion of the %%bash magic command at the top of the code block.\n\n%%bash\n\n# %load https://gist.githubusercontent.com/project-delphi/38d1db47ed28dde3c8418d5f435c865c/raw/665c079a1f6eff72207309ed97dd6b49194df812/pyg_user_install.sh\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-user-install\"\nPYTHON_VERSION=3.11\nRECENT_TORCH_VERSION=2.2.0\n\n# install miniconda for apple silicon, if not already installed\nif [ -d \"$HOME/anaconda3\" ] || [ -d \"$HOME/miniconda3\" ]\nthen\n    echo \"Conda is installed\"\nelse\n    curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n    sh Miniconda3-latest-MacOSX-arm64.sh -b -u  &gt; /dev/null 2&gt;&1\nfi\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nconda create --yes  -p $DIR/.venv python=$PYTHON_VERSION &gt; /dev/null 2&gt;&1\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\npip install -q --upgrade pip\n\n##### TORCH BUILD AND INSTALL ON M1, to use GPUs #####\npip install -q numpy # to remove user warning with torch install\npip install -q mpmath==1.3.0 # bugfix\nxcode-select --install  &gt; /dev/null 2&gt;&1 # if xcode not installed\n\n###### install torch ######\npip install -q --pre torch==$RECENT_TORCH_VERSION torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu \n\n# install torch geometric\npip install -q torch-geometric\n\n# check\npython --version\npython -c \"import torch; print(f'torch version: {torch.__version__}')\"\npython -c \"import torch_geometric as pyg; print(f'torch geometric version: {pyg.__version__}')\"\n\nConda is installed\nPython 3.11.8\ntorch version: 2.2.0\ntorch geometric version: 2.5.1\n\n\nWhich is great for using torch_geometric on my M1 Pro.\nThe problem is that I want to develop (and not just use) locally - that is to have an editable local install on my 2021 16 inch Macbook Pro M1 Pro. Sadly the M1 architecture does not have official support by pyg-team ðŸ˜” (I suspect the issues observed also apply to later Apple Silicon too.)\nLetâ€™s see how far we can get with the installation process."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#developer-installation",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#developer-installation",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "Developer Installation",
    "text": "Developer Installation\n\nNon Apple Silicon Machines\nFrom the project contributing guidelines, the instructions are clear.\n\nInstall a recent version of PyTorch\nOptionally install some dependencies if changes make use of them\nBe sure to uninstall the pytorch_geometric package\nClone the repo\nRun an editable install command for the repo\nRun pytest: local testing is kind of essential for a developer install.\n\nDevelop away - (as long as itâ€™s a supported architecture).\n\n\nM1, Possibly All Apple Silicon\nThis M1 hardware problem for developers has been noted.\nFor developers, if feature development on pytorch_geometric makes use of the listed package dependencies, several M1/AS issues have been raised.\n\npyg-lib\npytorch scatter\npytorch sparse\npytorch cluster\n\n(Itâ€™s likely that the package torch-spline-conv, another package dependency, is also an issue for M1/AS users - though no issues mentioning this are given.)\nThese dependencies are being subsumed into other packages (for example torch.scatter); at some point they wonâ€™t be a problem.\n\nWhy is Apple Silicon a Problem?\nTo develop locally, I need a an editable install version of pytorch geometric. This editable install needs additional dependencies (for fuller developer functionality such as testing, type checking, compiling, linting and documentation) some of which depend on C++ extensions which are not compiled for the M1/AS architecture. The project founder (@rusty1s) has noted that M1 was not supported from the onset - when it wasnâ€™t available on github actions, and there are no plans to support it now. Later Apple Silicon is supported, but developer build are variable.\n\n\nThe Solution\npyg-team suggested earlier that M1 users wanting the fuller editable version of the package can use the cmake & ninja build systems to create libraries and dependencies that target M1 - this will give a working modifiable install of pytorch geometric. Some OS and compiler flags need to be set.\nLetâ€™s see if I can do this and get a development environment setup.\nWhat Iâ€™ll do is as follows:\n\ncheck the OS & Hardware\nmake sure to uninstall all versions of pytorch geometric for all locations.\ncreate and activate a clean Python virtual environment (seems that conda is the best way to go)\ninstall a specific version of PyTorch using conda, as recommended by Apple\nbuild dependencies for clang and macos on my M1 Pro\nbuild the editable install\n\n\nOS and Hardware\nLetâ€™s start by listing my hardware:\n\n%%bash\necho \"Operating System: $(uname -s)\"\necho \"Hardware: $(uname -m)\"\necho \"macOS Version: $(sw_vers -productVersion)\"\necho \"Chipset: $(sysctl -n machdep.cpu.brand_string)\"\n\nOperating System: Darwin\nHardware: arm64\nmacOS Version: 14.4\nChipset: Apple M1 Pro\n\n\n\n\nEditable Developer Install\nIâ€™ve put this gist together from responses in github issues raised relating to AS. It installs, but doesnâ€™t pass all tests - it seems because the tests are composed from objects that donâ€™t work well with Apple Silicon, rather than anything fundamentally broken in AS.\n\n%%bash\n# %load https://gist.githubusercontent.com/project-delphi/b3b5cc91386997ff882f0a3f04a4b89a/raw/6146ec6cf950c2eeb184e0da3e59ff6fdd69550a/pytorch_geometric_apple_silicon_developer_install.sh\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-developer-install\"\nPYTHON_VERSION=3.11\nRECENT_TORCH_VERSION=2.2.0\nGITHUB_USERNAME=\"project-delphi\"\nMIN_MACOSX_DEPLOYMENT_TARGET=$(sw_vers -productVersion)\n\n# install miniconda for apple silicon, if not already installed\nif [ ! -d \"$HOME/anaconda3\" ] && [ ! -d \"$HOME/miniconda3\" ]\nthen\n    echo \"installing conda...\"\n    curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n    sh Miniconda3-latest-MacOSX-arm64.sh -b -u  &gt; /dev/null 2&gt;&1\nfi\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nconda create --yes  -p $DIR/.venv python=$PYTHON_VERSION  &gt; /dev/null 2&gt;&1\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\n\npip install -q --upgrade pip\n\n##### TORCH BUILD AND INSTALL ON M1, to use GPUs #####\npip install -q numpy # to remove user warning with torch install\npip install -q mpmath==1.3.0 # bugfix\nxcode-select --install  &gt; /dev/null 2&gt;&1 # if xcode not installed\n\n###### install pytorch ######\npip install -q --pre torch==$RECENT_TORCH_VERSION torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n\n# install dev build dependencies\npip install -q cmake\npip install -q ninja wheel\npip install -q git+https://github.com/pyg-team/pyg-lib.git\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-scatter\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-sparse\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-cluster\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-spline-conv\n\n# clone the forked repository and rebase to original\ngit clone \"https://github.com/$GITHUB_USERNAME/pytorch_geometric.git\"  2&gt;/dev/null\ncd pytorch_geometric\nif ! git remote | grep -q 'upstream'; then\n    git remote add upstream \"https://github.com/pyg-team/pytorch_geometric\"\nfi\ngit fetch upstream  -q\ngit rebase upstream/master\n\n# build dev install\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip install -q --no-cache-dir -e \".[dev,full]\"  #&gt; /dev/null 2&gt;&1\n\n# check\npython --version\npython -c \"import torch; print(f'torch version: {torch.__version__}')\"\npython -c \"import torch_geometric as pyg; print(f'torch geometric version: {pyg.__version__}')\"\n\nSo a kind of success. I can install a full developer version pytorch_geometric on my M1 Pro.\nHowever, we also need to check regarding testing (of which there are several undocumented flavours in the project).\nFor the standard set of tests, today I get this:\n\n%%bash\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-developer-install\"\ncd \"$DIR\"\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\n# install missing packages needed for testing\npip install -q matplotlib-inline ipython\npytest -q --tb=no | tail -n 1\n\nFatal Python error: Segmentation fault\n\nCurrent thread 0x00000001f82fbac0 (most recent call first):\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/torch/_ops.py\", line 755 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pyg_lib/partition/__init__.py\", line 35 in metis\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/torch_geometric/testing/decorators.py\", line 224 in withMETIS\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/test/distributed/test_dist_link_neighbor_loader.py\", line 140 in &lt;module&gt;\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py\", line 178 in exec_module\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 690 in _load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1147 in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1176 in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1204 in _gcd_import\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/importlib/__init__.py\", line 126 in import_module\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/pathlib.py\", line 584 in import_path\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 520 in importtestmodule\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 573 in _getobj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 315 in obj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 589 in _register_setup_module_fixture\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 576 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 388 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 340 in from_call\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 390 in pytest_make_collect_report\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 565 in collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 839 in _collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 976 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 813 in perform_collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 349 in pytest_collection\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 338 in _main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 285 in wrap_session\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/main.py\", line 332 in pytest_cmdline_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 174 in main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.11/site-packages/_pytest/config/__init__.py\", line 197 in console_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/bin/pytest\", line 8 in &lt;module&gt;\n\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._flinalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, scipy.cluster._vq, scipy.cluster._hierarchy, scipy.cluster._optimal_leaf_ordering, yaml._yaml, numba.core.typeconv._typeconv, numba._helperlib, numba._dynfunc, numba._dispatcher, numba.core.runtime._nrt_python, numba.np.ufunc._internal, numba.experimental.jitclass._box, psutil._psutil_osx, psutil._psutil_posix, markupsafe._speedups, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, matplotlib._c_internal_utils, PIL._imaging, matplotlib._path, kiwisolver._cext, matplotlib._image, rdkit.rdBase (total: 116)\n\n\nA week ago I noticed that the tests were failing, and then a few days ago they were passing. Today they are not passing, due to new tests. This is caused by commit updates which donâ€™t test on Apple Silicon.\nThis inconsistency is a problem for contributing to the project. As mentioned, @rusty1s has committed changes to the tests which accommodate Apple Silicon using his own device - but this is not a sustainable approach.\nThereâ€™s not a good solution to variable pytest runs, since feature updates (commits) to the main line branch â€“ which donâ€™t build for Apple Silicon â€“ are likely to break some test at least some of the time.\nIn some issues, @rusty1s mentioned a community effort to help test Apple Silicon builds, specifically the M1 architecture. Iâ€™d like to contribute, itâ€™s just figuring out how to do so for the long term.\nElse, the path of least resistance is to move to the cloud - Iâ€™ve recently received cloud credit from major providers."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#takeaways",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#takeaways",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "Takeaways",
    "text": "Takeaways\nChecking with @rusty1s, this is a problem with the type of tensors used in tests. Iâ€™m going to work on replacing COO tensors with CSR tensors for testing. A conversation with chatGPT helped to explain the differences between the two types of tensors.\nAlso, mkl is part of Intelâ€™s oneAPI project. It seems that supporting apple silicon is out of scope at this time.\nSo, developing pyg on recent Apple devices may just not be possible, but running on Apple Silicon is. Well if that is true, thereâ€™s always the cloud for Apple based developers who want to contribute.\nUPDATE: @rusty1s made a pull request that updates testing, accounting for MKL. pytorch-geometric as of now works great.\nOne just needs to install a few undeclared test dependencies and specific packages versions to fix downstream PyTorch dependencies breaking tests.\n\n%%bash\n# set variables here\nDIR=\"$HOME/Code/throwaway/pytorch-geometric-developer-install\"\nRECENT_TORCH_VERSION=2.2.0\nGITHUB_USERNAME=\"project-delphi\"\nMIN_MACOSX_DEPLOYMENT_TARGET=$(sw_vers -productVersion)\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nconda create --yes  -p $DIR/.venv python=3.12  &gt; /dev/null 2&gt;&1\neval \"$(conda shell.bash hook)\"\nconda activate $DIR/.venv\nwhich python\npython --version\npip install -q --upgrade pip\n\n##### TORCH BUILD AND INSTALL ON M1, to use GPUs #####\npip install -q numpy # to remove user warning with torch install\npip install -q mpmath==1.3.0 # bugfix\nxcode-select --install  &gt; /dev/null 2&gt;&1 # if xcode not installed\n# install miniconda for apple silicon, if not already installed\nif [ ! -d \"$HOME/anaconda3\" ] && [ ! -d \"$HOME/miniconda3\" ]\nthen\n    echo \"installing conda...\"\n    curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n    sh Miniconda3-latest-MacOSX-arm64.sh -b -u  &gt; /dev/null 2&gt;&1\nfi\n###### install pytorch ######\npip install -q --pre torch==$RECENT_TORCH_VERSION torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n\n\n# install dev build dependencies\npip install -q cmake\npip install -q ninja wheel\npip install -q git+https://github.com/pyg-team/pyg-lib.git\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-scatter\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-sparse\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-cluster\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip -q --no-cache-dir  install  torch-spline-conv\n\n# clone the forked repository and rebase to original\ngit clone \"https://github.com/$GITHUB_USERNAME/pytorch_geometric.git\"  2&gt;/dev/null\ncd pytorch_geometric\nif ! git remote | grep -q 'upstream'; then\n    git remote add upstream \"https://github.com/pyg-team/pytorch_geometric\"\nfi\ngit fetch upstream  -q\ngit rebase upstream/master\n\n# build dev install\nMACOSX_DEPLOYMENT_TARGET=$MIN_MACOSX_DEPLOYMENT_TARGET CC=clang CXX=clang++ python -m pip install -q --no-cache-dir -e \".[dev,full]\"  #&gt; /dev/null 2&gt;&1\n\n# check\npython --version\npython -c \"import torch; print(f'torch version: {torch.__version__}')\"\npython -c \"import torch_geometric as pyg; print(f'torch geometric version: {pyg.__version__}')\"\n# install missing packages\npip install -q matplotlib-inline ipython\npytest -q --tb=no | tail -n 1\n\nChannels:\n - defaults\nPlatform: osx-arm64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv\n\n  added / updated specs:\n    - python=3.12\n\n\nThe following NEW packages will be INSTALLED:\n\n  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h80987f9_5 \n  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2023.12.12-hca03da5_0 \n  expat              pkgs/main/osx-arm64::expat-2.5.0-h313beb8_0 \n  libcxx             pkgs/main/osx-arm64::libcxx-14.0.6-h848a8c0_0 \n  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_0 \n  ncurses            pkgs/main/osx-arm64::ncurses-6.4-h313beb8_0 \n  openssl            pkgs/main/osx-arm64::openssl-3.0.13-h1a28f6b_0 \n  pip                pkgs/main/osx-arm64::pip-23.3.1-py312hca03da5_0 \n  python             pkgs/main/osx-arm64::python-3.12.2-h99e199e_0 \n  readline           pkgs/main/osx-arm64::readline-8.2-h1a28f6b_0 \n  setuptools         pkgs/main/osx-arm64::setuptools-68.2.2-py312hca03da5_0 \n  sqlite             pkgs/main/osx-arm64::sqlite-3.41.2-h80987f9_0 \n  tk                 pkgs/main/osx-arm64::tk-8.6.12-hb8d0fd4_0 \n  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 \n  wheel              pkgs/main/osx-arm64::wheel-0.41.2-py312hca03da5_0 \n  xz                 pkgs/main/osx-arm64::xz-5.4.6-h80987f9_0 \n  zlib               pkgs/main/osx-arm64::zlib-1.2.13-h5a0b063_0 \n\n\n\nDownloading and Extracting Packages: ...working... done\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n#\n# To activate this environment, use\n#\n#     $ conda activate /Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/bin/python\nPython 3.12.2\nPython 3.12.2\ntorch version: 2.2.0\ntorch geometric version: 2.6.0\ncollecting ... \n\n\nSuccessfully rebased and updated refs/heads/master.\nFatal Python error: Segmentation fault\n\nCurrent thread 0x00000001f82fbac0 (most recent call first):\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/torch/_ops.py\", line 755 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pyg_lib/partition/__init__.py\", line 35 in metis\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/torch_geometric/testing/decorators.py\", line 224 in withMETIS\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/pytorch_geometric/test/distributed/test_dist_link_neighbor_loader.py\", line 140 in &lt;module&gt;\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/assertion/rewrite.py\", line 178 in exec_module\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 935 in _load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1331 in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1360 in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 1387 in _gcd_import\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/importlib/__init__.py\", line 90 in import_module\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/pathlib.py\", line 584 in import_path\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/python.py\", line 520 in importtestmodule\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/python.py\", line 573 in _getobj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/python.py\", line 315 in obj\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/python.py\", line 589 in _register_setup_module_fixture\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/python.py\", line 576 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/runner.py\", line 388 in collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/runner.py\", line 340 in from_call\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/runner.py\", line 390 in pytest_make_collect_report\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/runner.py\", line 565 in collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 839 in _collect_one_node\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 976 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 981 in genitems\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 813 in perform_collect\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 349 in pytest_collection\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 338 in _main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 285 in wrap_session\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/main.py\", line 332 in pytest_cmdline_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_callers.py\", line 102 in _multicall\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_manager.py\", line 119 in _hookexec\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/pluggy/_hooks.py\", line 501 in __call__\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py\", line 174 in main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/lib/python3.12/site-packages/_pytest/config/__init__.py\", line 197 in console_main\n  File \"/Users/ravikalia/Code/throwaway/pytorch-geometric-developer-install/.venv/bin/pytest\", line 8 in &lt;module&gt;\n\nExtension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._flinalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, scipy.cluster._vq, scipy.cluster._hierarchy, scipy.cluster._optimal_leaf_ordering, yaml._yaml, numba.core.typeconv._typeconv, numba._helperlib, numba._dynfunc, numba._dispatcher, numba.core.runtime._nrt_python, numba.np.ufunc._internal, numba.experimental.jitclass._box, psutil._psutil_osx, psutil._psutil_posix, markupsafe._speedups, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, matplotlib._c_internal_utils, PIL._imaging, matplotlib._path, kiwisolver._cext, matplotlib._image, rdkit.rdBase (total: 116)\n\n\nSuccess! As of now it works.\nHowever, as I looked over the github actions workflows, I noticed that full testing and gpu testing are not set up for apple silicon and also have to install undeclared dependencies. These minor issues could be fun useful to work on."
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#references",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#references",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "References",
    "text": "References\n\npytorch on Apple Metal\npyg-lib M1 issues\npytorch-scatter M1 issue\npytorch-spars M1 issues\npytorch-cluster M1 issues"
  },
  {
    "objectID": "posts/developing-pytorch-geometric-on-m1/index.html#more-on-testing",
    "href": "posts/developing-pytorch-geometric-on-m1/index.html#more-on-testing",
    "title": "Developing Pytorch Geometric on M1 Apple Silicon",
    "section": "More On Testing",
    "text": "More On Testing\nThese test related issues are not unique to the default testing for the package. The package has several kinds of tests, including: full, gpu, previous version, and nightly.\nI looked over the github actions workflows, I noticed that full testing and gpu testing are not set up for apple silicon and also have to install undeclared dependencies, such as graphviz and bugfix pinned versions of packages (e.g.Â mpmath==1.3.0). These minor issues could be useful to work on - even with current default testing this seems to be the case.\nIâ€™m thinking of a Makefile to compose the different installation and testing steps into higher level portable grammars. This would be useful for the community, and also for me to use in the future.\nUpdate, @rusty1s suggested more specific testing for mps (and by implication AS), starting with test decorators. That and test documentation could be a good place to start."
  },
  {
    "objectID": "posts/sparse_tensors/index.html",
    "href": "posts/sparse_tensors/index.html",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Image of Building\n\n\nPhoto by engin akyurt on Unsplash\n\n\nThe canonical format for representing tensors in PyTorch is the dense tensor, with associated contiguous memory proportional to the size of the tensor. However, in many applications, the data is sparse, that is most of the elements are zero. In this notebook, we will see how to work efficiently with sparse tensors in PyTorch.\n\n\nA dataset is considered sparse when most of its elements are zero, for some features of the dataset. The exact threshold for considering a dataset as sparse is not strictly defined and can depend on the context and the specific application. A common rule of thumb is that a dataset is sparse if over 50% of its elements are zero.\nIn many real-world applications, datasets can be extremely sparse, with over 90% or even 99% of elements being zero. For example, in a user-item interaction matrix in a recommendation system, each user typically interacts with only a small fraction of all possible items, so the vast majority of the matrix elements are zero.\nIn PyTorch, datasets are stored in tensors. A tensor is a multi-dimensional array, similar to a NumPy array. PyTorch provides some support for sparse tensors.\n\n\n\nIn a dense tensor, all elements are stored in memory, even if most of them are zero. In a sparse tensor, only the non-zero elements are stored, along with their indices. This can lead to significant memory savings and/or faster compute times, especially for very sparse datasets.\nFor several tasks which are computing on the tensor, sparse tensors can be more efficient than dense tensors. For example, consider matrix multiplication. If the matrices are sparse, then sparse tensors can be orders of magnitude faster than dense tensors - as we will demonstrate at the end.\n\n\n\nIn PyTorch there are several ways to create sparse tensors as containers for sparse data. We will see how to create a sparse tensor from a dense tensor, and how to create a sparse tensor from different formats: COO, CSR, and CSC.\nFirst weâ€™ll need example data to work with - letâ€™s use a graph dataset as an example to understand sparse tensors.\n\n\n\n\nGraph data is a commonly sparse. A graph is a collection of nodes (or vertices) and edges. The nodes represent entities, and the edges represent relationships between the entities. More often than not, graphs are sparse, i.e.Â most of the nodes are not connected to each other. It is common to see datasets where less than 1% of the possible edges are present.\nThere are many ways to represent a Graph. One common is an adjacency matrix, A. This is particularly bad for sparse graphs, as most of the elements in the matrix are zero.\nThe adjacency matrix is a square matrix A, of size N x N, where N is the number of nodes in the graph. The element A[i, j] is 1 if there is an edge between node i and node j, and 0 otherwise. Since most nodes are not connected to each other, the adjacency matrix is sparse.\nAnother more memory-efficient way to represent a graph is using a tensor of edges, E. Each edge is represented as a 2 long column (r, s) in E, where r and s are the indices of the nodes connected by the edge. This representation is more memory-efficient than the adjacency matrix, as it only stores the non-zero elements, itâ€™s size is 2 x number_edges.\nIn this notebook, we will see how to create a sparse tensor from an adjacency matrix, and how to create a sparse tensor from a list of edges. We will also see how to perform basic operations on sparse tensors, such as matrix multiplication and element-wise operations.\nLetâ€™s consider an example from the ModelNet10 dataset.\n\n\nModelNet10 is a subset of the ModelNet dataset, which is a large-scale 3D CAD model dataset. ModelNet10 specifically consists of 10 categories, with a total of 4899 3D CAD models. The categories include: bed, chair, monitor, desk, dresser, sofa, table, toilet, night stand, and bathtub.\nEach 3D model in the dataset is represented as a graph, where each node represents a point in the 3D object, and each edge represents a relationship between the points. The adjacency matrix of the graph is sparse, as most of the points are not connected to each other.\nThis dataset is commonly used for benchmarking in tasks such as 3D object recognition, shape classification, and other machine learning tasks involving 3D data.\nLetâ€™s look at a one: a Monitor from the training dataset. Weâ€™ll need to install some libraries to visualize the 3D object.\n\n!pip -q install numpy matplotlib networkx\n\nThe data is in off format - that is nodes and edges making faces. The particular file can be found here. The corners of the monitor are the nodes and the edges are the connections between the corners. Hereâ€™s a plot using matplotlib and another with trimesh.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\ndef read_off(file):\n    if 'OFF' != file.readline().strip():\n        raise('Not a valid OFF header')\n    n_verts, n_faces, _ = tuple(map(int, file.readline().strip().split(' ')))\n    verts = [[float(s) for s in file.readline().strip().split(' ')] for _ in range(n_verts)]\n    faces = [[int(s) for s in file.readline().strip().split(' ')[1:]] for _ in range(n_faces)]\n    return verts, faces\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Create a Poly3DCollection object\npolys = [np.array(verts)[face] for face in faces]\ncollection = Poly3DCollection(polys, linewidths=1, alpha=1)\ncollection.set_facecolor((0,0,1,0.5))  # Set the color of the object to blue\ncollection.set_edgecolor((0,0,1,0.5))  # Set the edge color to a darker blue\nax.add_collection3d(collection)\n\n# Add lighting\nax.add_collection3d(Poly3DCollection(polys, facecolors='r', linewidths=1, edgecolors='r', alpha=.20))\n\n# Remove the axes for a cleaner look\nax.axis('off')\n\n# Auto scale to the mesh size\nscale = np.array(verts).flatten()\nax.auto_scale_xyz(scale, scale, scale)\n\n# Add a title to the plot\nax.set_title('3D Model of Monitor')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npip -q install trimesh\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport trimesh\n\n# Load the mesh from the OFF file\nmesh = trimesh.load_mesh('./data/monitor_0001.off')\n\n# Plot the mesh\nmesh.show()\n\n\n\n\nTo see this data as a graph, we will feed in vertices and faces into the networkx package.\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\ndef off_to_graph(verts, faces):\n    # Create a new graph\n    G = nx.Graph()\n    # Add nodes to the graph\n    for i in range(len(verts)):\n        G.add_node(i)\n    # Add edges to the graph\n    for face in faces:\n        for i in range(len(face)):\n            # Add an edge between each pair of vertices in the face\n            G.add_edge(face[i], face[(i+1)%len(face)])\n    return G\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\n\n\nprint(G)\n\nGraph with 798 nodes and 1476 edges\n\n\n\n# Draw the graph\nnx.draw(G, edge_color=\"black\", width=1, node_size=5, with_labels=False)\nplt.show()\n\n\n\n\n\n\n\n\nSo, thatâ€™s the graph. Itâ€™s difficult to make out the shape of the monitor from the plot above, as weâ€™re not representing the features of the nodes (3d co-ordinates).\nWhat we can do is list out the edges and vertices of the graph. First in edge list format with the corresponding nodes.\n\nG.edges()\n\nEdgeView([(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (3, 4), (4, 5), (4, 6), (5, 6), (5, 7), (6, 7), (6, 8), (7, 8), (7, 9), (8, 9), (8, 10), (9, 10), (9, 11), (10, 11), (10, 12), (11, 12), (11, 13), (12, 13), (12, 14), (13, 14), (13, 15), (14, 15), (14, 16), (15, 16), (15, 17), (16, 17), (16, 18), (17, 18), (17, 19), (18, 19), (18, 20), (19, 20), (19, 21), (20, 21), (20, 22), (21, 22), (21, 23), (22, 23), (22, 24), (23, 24), (23, 25), (24, 25), (24, 26), (24, 27), (25, 26), (26, 27), (28, 29), (28, 30), (28, 31), (28, 32), (29, 30), (29, 85), (29, 87), (30, 31), (30, 87), (31, 32), (33, 34), (33, 35), (33, 88), (34, 35), (34, 88), (34, 36), (35, 36), (35, 37), (36, 37), (36, 38), (37, 38), (37, 39), (38, 39), (38, 40), (39, 40), (39, 41), (40, 41), (40, 42), (41, 42), (41, 43), (42, 43), (42, 44), (43, 44), (43, 45), (44, 45), (44, 46), (45, 46), (45, 47), (46, 47), (48, 49), (48, 50), (49, 50), (49, 51), (50, 52), (50, 51), (51, 52), (51, 53), (52, 54), (52, 53), (53, 54), (53, 55), (54, 56), (54, 55), (55, 56), (55, 57), (56, 58), (56, 57), (57, 58), (57, 59), (58, 60), (58, 59), (59, 60), (59, 61), (60, 62), (60, 61), (61, 62), (61, 89), (62, 89), (63, 64), (63, 65), (63, 66), (63, 90), (64, 65), (64, 67), (64, 66), (65, 90), (66, 67), (66, 68), (67, 69), (67, 68), (68, 69), (68, 70), (69, 71), (69, 70), (70, 71), (70, 72), (71, 73), (71, 72), (72, 73), (72, 74), (73, 75), (73, 74), (74, 75), (74, 76), (75, 77), (75, 76), (76, 77), (78, 79), (78, 80), (78, 81), (78, 82), (79, 80), (79, 91), (80, 91), (80, 82), (81, 82), (81, 83), (81, 84), (82, 84), (83, 84), (83, 85), (83, 86), (84, 86), (85, 86), (85, 87), (86, 87), (92, 93), (92, 94), (92, 95), (92, 147), (92, 148), (92, 170), (92, 171), (93, 94), (93, 95), (93, 96), (93, 97), (94, 147), (94, 146), (95, 96), (95, 148), (95, 149), (95, 150), (96, 97), (96, 98), (96, 150), (96, 151), (96, 152), (96, 153), (96, 154), (96, 104), (97, 98), (97, 99), (98, 99), (98, 100), (98, 104), (99, 100), (99, 101), (99, 102), (100, 101), (100, 104), (101, 102), (101, 103), (101, 104), (102, 103), (102, 104), (102, 105), (102, 106), (103, 104), (104, 105), (104, 119), (104, 154), (104, 112), (104, 114), (104, 116), (104, 117), (105, 106), (105, 107), (105, 119), (105, 118), (105, 120), (105, 121), (106, 107), (108, 109), (108, 110), (108, 111), (108, 134), (108, 135), (109, 110), (109, 111), (109, 112), (109, 155), (109, 157), (109, 158), (110, 135), (110, 155), (110, 156), (110, 166), (111, 112), (111, 113), (112, 113), (112, 114), (112, 158), (112, 159), (112, 160), (112, 154), (113, 114), (113, 115), (114, 115), (114, 116), (115, 116), (115, 117), (115, 118), (116, 117), (117, 118), (117, 119), (118, 119), (118, 120), (120, 121), (122, 123), (122, 124), (122, 125), (123, 124), (123, 125), (123, 126), (123, 127), (123, 136), (123, 138), (123, 139), (123, 161), (123, 141), (124, 136), (124, 137), (125, 126), (126, 127), (126, 128), (127, 128), (127, 129), (127, 161), (128, 129), (128, 130), (128, 131), (129, 130), (129, 161), (130, 131), (130, 132), (130, 161), (131, 132), (131, 133), (131, 134), (132, 133), (132, 161), (133, 134), (133, 135), (133, 161), (133, 162), (134, 135), (135, 162), (135, 163), (135, 164), (135, 165), (135, 166), (136, 137), (136, 138), (138, 139), (138, 140), (139, 140), (139, 141), (140, 141), (140, 142), (140, 143), (141, 142), (141, 161), (142, 143), (142, 144), (142, 161), (143, 144), (143, 145), (143, 146), (144, 145), (144, 161), (145, 146), (145, 147), (145, 161), (146, 147), (147, 161), (147, 167), (147, 168), (147, 169), (147, 170), (148, 149), (148, 171), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 160), (155, 156), (155, 157), (156, 166), (157, 158), (158, 159), (159, 160), (161, 162), (161, 167), (162, 163), (163, 164), (164, 165), (165, 166), (167, 168), (168, 169), (169, 170), (170, 171), (172, 173), (172, 174), (172, 175), (173, 174), (173, 175), (173, 176), (175, 176), (175, 177), (176, 177), (176, 178), (177, 178), (177, 179), (178, 179), (178, 180), (178, 181), (179, 180), (180, 181), (180, 182), (181, 182), (181, 183), (182, 183), (182, 184), (183, 184), (183, 185), (184, 185), (186, 187), (186, 188), (186, 189), (187, 188), (187, 189), (187, 190), (188, 190), (188, 191), (190, 191), (190, 192), (191, 192), (191, 193), (192, 193), (192, 194), (192, 195), (193, 194), (194, 195), (194, 196), (195, 196), (195, 197), (196, 197), (196, 198), (197, 198), (197, 199), (198, 199), (200, 201), (200, 202), (200, 203), (201, 202), (201, 203), (201, 204), (203, 204), (203, 205), (204, 205), (204, 206), (205, 206), (205, 207), (206, 207), (206, 208), (206, 209), (207, 208), (208, 209), (208, 210), (209, 210), (209, 211), (210, 211), (210, 212), (211, 212), (211, 213), (212, 213), (214, 215), (214, 216), (214, 217), (214, 218), (215, 216), (215, 217), (217, 218), (217, 219), (218, 219), (218, 220), (219, 220), (219, 221), (220, 221), (220, 222), (220, 223), (221, 222), (222, 223), (222, 224), (223, 224), (223, 225), (224, 225), (224, 226), (225, 226), (225, 227), (226, 227), (228, 229), (228, 230), (228, 231), (228, 232), (229, 230), (229, 231), (231, 232), (231, 233), (232, 233), (232, 234), (233, 234), (233, 235), (234, 235), (234, 236), (235, 236), (235, 237), (236, 237), (236, 238), (237, 238), (237, 239), (238, 239), (238, 240), (239, 240), (239, 241), (240, 241), (240, 242), (241, 242), (241, 243), (242, 243), (242, 244), (243, 244), (243, 245), (244, 245), (244, 246), (245, 246), (245, 247), (246, 247), (246, 248), (247, 248), (247, 249), (248, 249), (248, 250), (249, 250), (249, 251), (250, 251), (252, 253), (252, 254), (253, 254), (253, 255), (254, 255), (254, 256), (255, 256), (255, 257), (256, 257), (256, 258), (257, 258), (257, 259), (258, 259), (258, 260), (259, 260), (259, 261), (260, 261), (260, 262), (261, 262), (261, 263), (262, 263), (262, 264), (263, 264), (263, 265), (264, 265), (264, 266), (265, 266), (265, 267), (266, 267), (266, 268), (267, 268), (267, 269), (268, 269), (268, 270), (269, 270), (269, 271), (270, 271), (270, 272), (271, 272), (271, 273), (272, 273), (272, 274), (273, 274), (273, 275), (274, 275), (276, 277), (276, 278), (276, 279), (277, 278), (277, 279), (277, 280), (277, 312), (279, 280), (280, 312), (281, 282), (281, 283), (281, 284), (282, 283), (282, 284), (285, 286), (285, 287), (285, 288), (286, 287), (286, 288), (286, 289), (286, 295), (287, 295), (287, 296), (288, 289), (288, 290), (288, 291), (288, 292), (288, 293), (289, 290), (290, 291), (291, 292), (292, 293), (292, 294), (293, 294), (293, 296), (294, 295), (294, 296), (295, 296), (297, 298), (297, 299), (297, 300), (298, 299), (298, 300), (301, 302), (301, 303), (301, 304), (302, 303), (302, 304), (302, 305), (302, 306), (302, 308), (303, 305), (304, 306), (304, 307), (304, 310), (304, 311), (305, 308), (305, 309), (306, 307), (307, 308), (307, 309), (307, 310), (308, 309), (309, 310), (310, 311), (313, 314), (313, 315), (313, 316), (314, 315), (314, 316), (317, 318), (317, 319), (317, 320), (317, 321), (318, 319), (318, 320), (320, 321), (322, 323), (322, 324), (322, 325), (323, 324), (323, 325), (323, 326), (323, 336), (324, 336), (324, 337), (325, 326), (325, 327), (326, 327), (326, 328), (327, 328), (327, 329), (328, 329), (328, 330), (329, 330), (329, 331), (330, 331), (330, 332), (331, 332), (331, 333), (331, 334), (332, 333), (333, 334), (333, 335), (334, 335), (334, 337), (334, 338), (335, 336), (335, 337), (336, 337), (337, 338), (337, 339), (338, 339), (340, 341), (340, 342), (340, 343), (341, 342), (341, 343), (344, 345), (344, 346), (344, 347), (345, 346), (345, 347), (348, 349), (348, 350), (348, 351), (348, 352), (348, 353), (349, 350), (349, 351), (349, 354), (349, 355), (349, 356), (349, 367), (349, 366), (349, 390), (350, 354), (351, 352), (352, 353), (352, 357), (353, 357), (353, 358), (353, 359), (353, 360), (353, 361), (353, 362), (353, 363), (353, 364), (353, 365), (354, 355), (355, 356), (356, 390), (356, 412), (357, 358), (358, 359), (359, 360), (360, 361), (361, 362), (362, 363), (363, 364), (364, 365), (366, 367), (366, 368), (366, 369), (367, 368), (367, 390), (367, 389), (368, 369), (368, 370), (369, 370), (369, 371), (370, 371), (370, 372), (371, 372), (371, 373), (372, 373), (372, 374), (373, 374), (373, 375), (374, 375), (374, 376), (375, 376), (375, 377), (376, 377), (376, 378), (377, 378), (377, 379), (378, 379), (378, 380), (379, 380), (379, 381), (380, 381), (380, 382), (381, 382), (381, 383), (382, 383), (382, 384), (383, 384), (383, 385), (384, 385), (384, 386), (385, 386), (385, 387), (386, 387), (386, 388), (387, 388), (389, 390), (389, 391), (389, 392), (390, 391), (390, 412), (390, 413), (391, 392), (391, 393), (392, 393), (392, 394), (393, 394), (393, 395), (394, 395), (394, 396), (395, 396), (395, 397), (396, 397), (396, 398), (397, 398), (397, 399), (398, 399), (398, 400), (399, 400), (399, 401), (400, 401), (400, 402), (401, 402), (401, 403), (402, 403), (402, 404), (403, 404), (403, 405), (404, 405), (404, 406), (405, 406), (405, 407), (406, 407), (406, 408), (407, 408), (407, 409), (408, 409), (408, 410), (409, 410), (409, 411), (410, 411), (412, 413), (412, 414), (412, 415), (412, 416), (412, 417), (412, 418), (412, 419), (412, 420), (412, 421), (412, 422), (412, 423), (413, 414), (414, 415), (415, 416), (416, 417), (417, 418), (418, 419), (419, 420), (420, 421), (421, 422), (422, 423), (424, 425), (424, 426), (424, 427), (425, 426), (425, 427), (428, 429), (428, 430), (428, 431), (429, 430), (429, 431), (429, 432), (431, 432), (431, 433), (431, 434), (431, 435), (431, 436), (431, 437), (432, 433), (433, 434), (434, 435), (435, 436), (436, 437), (438, 439), (438, 440), (439, 440), (439, 441), (439, 442), (439, 443), (439, 444), (439, 445), (439, 446), (440, 441), (441, 442), (442, 443), (443, 444), (444, 445), (445, 446), (445, 447), (446, 447), (448, 449), (448, 450), (448, 451), (448, 452), (449, 450), (449, 451), (451, 452), (453, 454), (453, 455), (454, 455), (454, 456), (454, 457), (455, 456), (456, 457), (458, 459), (458, 460), (458, 461), (459, 460), (459, 461), (459, 462), (461, 462), (461, 463), (462, 463), (462, 464), (463, 464), (463, 465), (463, 466), (464, 465), (465, 466), (465, 467), (466, 467), (466, 468), (467, 468), (467, 469), (468, 469), (468, 470), (469, 470), (469, 471), (470, 471), (470, 472), (471, 472), (471, 473), (472, 473), (472, 474), (473, 474), (473, 475), (474, 475), (474, 476), (475, 476), (475, 477), (476, 477), (476, 478), (477, 478), (477, 479), (478, 479), (478, 480), (479, 480), (481, 482), (481, 483), (482, 483), (482, 484), (482, 485), (483, 484), (484, 485), (484, 486), (485, 486), (485, 487), (486, 487), (486, 488), (487, 488), (487, 489), (488, 489), (488, 490), (489, 490), (489, 491), (490, 491), (490, 492), (491, 492), (491, 493), (492, 493), (492, 494), (493, 494), (493, 495), (494, 495), (494, 496), (495, 496), (495, 497), (496, 497), (496, 498), (497, 498), (497, 499), (497, 500), (498, 499), (499, 500), (499, 501), (500, 501), (500, 502), (501, 502), (501, 503), (502, 503), (504, 505), (504, 506), (504, 507), (504, 508), (505, 506), (505, 507), (505, 534), (505, 533), (506, 534), (507, 508), (509, 510), (509, 511), (510, 511), (510, 512), (510, 513), (511, 512), (512, 513), (512, 535), (512, 536), (513, 535), (514, 515), (514, 516), (514, 517), (515, 516), (515, 517), (515, 518), (517, 518), (517, 519), (518, 519), (518, 520), (519, 520), (519, 521), (519, 522), (520, 521), (521, 522), (521, 523), (522, 523), (522, 524), (523, 524), (523, 525), (524, 525), (524, 526), (525, 526), (525, 527), (526, 527), (526, 528), (527, 528), (527, 529), (528, 529), (528, 530), (529, 530), (529, 531), (530, 531), (530, 532), (531, 532), (531, 533), (532, 533), (532, 534), (533, 534), (535, 536), (535, 537), (536, 537), (536, 538), (537, 538), (537, 539), (538, 539), (538, 540), (539, 540), (539, 541), (540, 541), (540, 542), (541, 542), (541, 543), (542, 543), (542, 544), (543, 544), (543, 545), (544, 545), (544, 546), (545, 546), (545, 547), (546, 547), (546, 548), (547, 548), (547, 549), (548, 549), (548, 550), (549, 550), (549, 551), (549, 552), (550, 551), (551, 552), (551, 553), (552, 553), (552, 554), (553, 554), (553, 555), (554, 555), (556, 557), (556, 558), (556, 559), (556, 560), (557, 558), (557, 559), (557, 586), (557, 585), (558, 586), (559, 560), (561, 562), (561, 563), (562, 563), (562, 564), (562, 565), (563, 564), (564, 565), (564, 587), (564, 588), (565, 587), (566, 567), (566, 568), (566, 569), (567, 568), (567, 569), (567, 570), (569, 570), (569, 571), (570, 571), (570, 572), (571, 572), (571, 573), (571, 574), (572, 573), (573, 574), (573, 575), (574, 575), (574, 576), (575, 576), (575, 577), (576, 577), (576, 578), (577, 578), (577, 579), (578, 579), (578, 580), (579, 580), (579, 581), (580, 581), (580, 582), (581, 582), (581, 583), (582, 583), (582, 584), (583, 584), (583, 585), (584, 585), (584, 586), (585, 586), (587, 588), (587, 589), (588, 589), (588, 590), (589, 590), (589, 591), (590, 591), (590, 592), (591, 592), (591, 593), (592, 593), (592, 594), (593, 594), (593, 595), (594, 595), (594, 596), (595, 596), (595, 597), (596, 597), (596, 598), (597, 598), (597, 599), (598, 599), (598, 600), (599, 600), (599, 601), (600, 601), (600, 602), (601, 602), (601, 603), (601, 604), (602, 603), (603, 604), (603, 605), (604, 605), (604, 606), (605, 606), (605, 607), (606, 607), (608, 609), (608, 610), (608, 611), (609, 610), (609, 611), (609, 612), (611, 612), (611, 613), (612, 613), (612, 614), (613, 614), (613, 615), (613, 616), (614, 615), (615, 616), (615, 617), (616, 617), (616, 618), (617, 618), (617, 619), (618, 619), (618, 620), (619, 620), (619, 621), (620, 621), (620, 622), (621, 622), (621, 623), (622, 623), (622, 624), (623, 624), (623, 625), (624, 625), (624, 626), (625, 626), (625, 627), (626, 627), (626, 628), (627, 628), (627, 629), (628, 629), (628, 630), (629, 630), (631, 632), (631, 633), (632, 633), (632, 634), (632, 635), (633, 634), (634, 635), (634, 636), (635, 636), (635, 637), (636, 637), (636, 638), (637, 638), (637, 639), (638, 639), (638, 640), (639, 640), (639, 641), (640, 641), (640, 642), (641, 642), (641, 643), (642, 643), (642, 644), (643, 644), (643, 645), (644, 645), (644, 646), (645, 646), (645, 647), (646, 647), (646, 648), (647, 648), (647, 649), (647, 650), (648, 649), (649, 650), (649, 651), (650, 651), (650, 652), (651, 652), (651, 653), (652, 653), (654, 655), (654, 656), (654, 657), (655, 656), (655, 657), (655, 658), (657, 658), (657, 659), (658, 659), (658, 660), (659, 660), (659, 661), (659, 662), (660, 661), (661, 662), (661, 663), (662, 663), (662, 664), (663, 664), (663, 665), (664, 665), (664, 666), (665, 666), (665, 667), (666, 667), (666, 668), (667, 668), (667, 669), (668, 669), (668, 670), (669, 670), (669, 671), (670, 671), (670, 672), (671, 672), (671, 673), (672, 673), (672, 674), (673, 674), (673, 675), (674, 675), (674, 676), (675, 676), (677, 678), (677, 679), (678, 679), (678, 680), (678, 681), (679, 680), (680, 681), (680, 682), (681, 682), (681, 683), (682, 683), (682, 684), (683, 684), (683, 685), (684, 685), (684, 686), (685, 686), (685, 687), (686, 687), (686, 688), (687, 688), (687, 689), (688, 689), (688, 690), (689, 690), (689, 691), (690, 691), (690, 692), (691, 692), (691, 693), (692, 693), (692, 694), (693, 694), (693, 695), (693, 696), (694, 695), (695, 696), (695, 697), (696, 697), (696, 698), (697, 698), (697, 699), (698, 699), (700, 701), (700, 702), (700, 703), (701, 702), (701, 703), (701, 704), (703, 704), (703, 705), (704, 705), (704, 706), (705, 706), (705, 707), (705, 708), (706, 707), (707, 708), (707, 709), (708, 709), (708, 710), (709, 710), (709, 711), (710, 711), (710, 712), (711, 712), (711, 713), (712, 713), (712, 714), (713, 714), (713, 715), (714, 715), (714, 716), (715, 716), (715, 717), (716, 717), (716, 718), (717, 718), (717, 719), (718, 719), (718, 720), (719, 720), (719, 721), (720, 721), (720, 722), (721, 722), (723, 724), (723, 725), (724, 725), (724, 726), (724, 727), (725, 726), (726, 727), (726, 728), (727, 728), (727, 729), (728, 729), (728, 730), (729, 730), (729, 731), (730, 731), (730, 732), (731, 732), (731, 733), (732, 733), (732, 734), (733, 734), (733, 735), (734, 735), (734, 736), (735, 736), (735, 737), (736, 737), (736, 738), (737, 738), (737, 739), (738, 739), (738, 740), (739, 740), (739, 741), (739, 742), (740, 741), (741, 742), (741, 743), (742, 743), (742, 744), (743, 744), (743, 745), (744, 745), (746, 747), (746, 748), (746, 749), (746, 750), (747, 748), (747, 749), (749, 750), (749, 751), (749, 752), (749, 753), (750, 751), (751, 752), (752, 753), (754, 755), (754, 756), (754, 757), (755, 756), (755, 757), (758, 759), (758, 760), (759, 760), (759, 761), (760, 761), (762, 763), (762, 764), (762, 765), (763, 764), (763, 765), (766, 767), (766, 768), (766, 769), (767, 768), (767, 769), (770, 771), (770, 772), (770, 773), (771, 772), (771, 773), (774, 775), (774, 776), (775, 776), (777, 778), (777, 779), (778, 779), (780, 781), (780, 782), (780, 783), (781, 782), (781, 783), (784, 785), (784, 786), (785, 786), (785, 787), (786, 787), (790, 791), (790, 792), (791, 792), (791, 793), (792, 793), (794, 795), (794, 796), (794, 797), (795, 796), (795, 797)])\n\n\n\nG.nodes()\n\nNodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797))\n\n\nAnd then as a an adjacency matrix.\n\nA = nx.to_numpy_array(G)\n\n\nA.shape\n\n(798, 798)\n\n\n\nprint(A)\n\n[[0. 1. 1. ... 0. 0. 0.]\n [1. 0. 1. ... 0. 0. 0.]\n [1. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 1. 1.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]]\n\n\nLetâ€™s verify that the number of edges match the adjacency matrix.\n\nA.sum() / 2\n\n1476.0\n\n\n\nA.sum()/2 == len(G.edges()) # The number of edges.\n\nTrue\n\n\n\n\n\n\nThe adjacency is sparse. We can quantify this sparsity - the ratio of the number of non-zero elements to the total number of elements in the tensor.\n\n# the ratio of the number of non-zero elements to the total number of elements in the tensor A.\nnp.count_nonzero(A) / (A.shape[0] * A.shape[1])\n\n0.004635649273559839\n\n\nStoring data in this format is inefficient. We can convert it to a sparse tensor. Weâ€™ll create functions for popular formats, as well as look at the native PyTorch implementations.\n\n\n\nSome well known sparse tensor representation formats are:\n\nCoordinate (COO)\nCompressed Sparse Row (CSR)\nCompressed Sparse Column (CSC)\nBlock Compressed Sparse Row (BSR)\nDictionary of Keys (DOK)\nList of Lists (LIL)\n\nWeâ€™ll look at COO, CSR, and CSC formats.\nThe monitor graph is too large and sparse for illustration purposes. Weâ€™ll create a smaller graph to demonstrate the conversion back and forth to sparse tensors.\n\n# Create a new graph\nG = nx.Graph()\n\n# Add some edges to the graph\nG.add_edge(0, 1)\nG.add_edge(0, 2)\nG.add_edge(3, 4)\n\n# Draw the graph\nnx.draw(G, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\npip -q install torch\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport torch\n\nA = nx.to_numpy_array(G)\nprint(torch.from_numpy(A))\nA_torch = torch.from_numpy(A).bool()\nA_torch\n\ntensor([[0., 1., 1., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0.]], dtype=torch.float64)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\nA.sum()/2\n\n3.0\n\n\nLetâ€™s express as a pandas dataframe with source and target nodes for edges.\n\npip -q install pandas\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport numpy as np\n\n# Get the number of nodes\nnum_nodes = A_torch.shape[0]\n\n# Create a list of all pairs of nodes\nsource_node, destination_node = np.meshgrid(np.arange(num_nodes), np.arange(num_nodes))\n\n# Flatten the arrays\nsource_node = source_node.flatten()\ndestination_node = destination_node.flatten()\n\n# Get the edge values\nhas_edge = A_torch[source_node, destination_node] &gt; 0\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\n\ndf\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n0\nFalse\n\n\n1\n1\n0\nTrue\n\n\n2\n2\n0\nTrue\n\n\n3\n3\n0\nFalse\n\n\n4\n4\n0\nFalse\n\n\n5\n0\n1\nTrue\n\n\n6\n1\n1\nFalse\n\n\n7\n2\n1\nFalse\n\n\n8\n3\n1\nFalse\n\n\n9\n4\n1\nFalse\n\n\n10\n0\n2\nTrue\n\n\n11\n1\n2\nFalse\n\n\n12\n2\n2\nFalse\n\n\n13\n3\n2\nFalse\n\n\n14\n4\n2\nFalse\n\n\n15\n0\n3\nFalse\n\n\n16\n1\n3\nFalse\n\n\n17\n2\n3\nFalse\n\n\n18\n3\n3\nFalse\n\n\n19\n4\n3\nTrue\n\n\n20\n0\n4\nFalse\n\n\n21\n1\n4\nFalse\n\n\n22\n2\n4\nFalse\n\n\n23\n3\n4\nTrue\n\n\n24\n4\n4\nFalse\n\n\n\n\n\n\n\n\n\nThe COO format is simple and flexible for sparse matrices. It consists of three arrays: row, col, and data. The row array contains the row indices of the non-zero elements, the col array contains the column indices of the non-zero elements, and the data array contains the values of the non-zero elements.\nLuckily, PyTorch has built in methods for converting between dense and sparse tensors. We can convert the adjacency matrix to a COO sparse tensor using the .to_sparse() method.\n\nA_coo_pytorch = A_torch.to_sparse()\nA_coo_pytorch\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\nAnd convert back\n\nA_coo_pytorch.to_dense()\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nLetâ€™s look at the sparse tensor as a dataframe of source to destination nodes, but this time only for those pairs where there is an edge.\n\n# Get the source and destination nodes and the edge values\nsource_node = A_coo_pytorch.indices()[0].numpy()\ndestination_node = A_coo_pytorch.indices()[1].numpy()\nhas_edge = A_coo_pytorch.values().numpy()\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\ndf\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n1\nTrue\n\n\n1\n0\n2\nTrue\n\n\n2\n1\n0\nTrue\n\n\n3\n2\n0\nTrue\n\n\n4\n3\n4\nTrue\n\n\n5\n4\n3\nTrue\n\n\n\n\n\n\n\nWriting our own homebrew function to convert to COO format, is straightforward.\n\ndef to_sparse(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor).t()\n    # Get the values of the non-zero elements\n    values = tensor[indices[0], indices[1]]  # assuming 2D tensor\n    # Get the size of the original tensor\n    size = tensor.size()\n    # Create a sparse tensor\n    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n    return sparse_tensor\n\n\nto_sparse(A_torch)\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\n\ndef to_dense(sparse_tensor):\n    # Get the size of the original tensor\n    size = sparse_tensor.size()\n    # Get the indices and values from the sparse tensor\n    indices = sparse_tensor.coalesce().indices()\n    values = sparse_tensor.coalesce().values()\n    # Create a dense tensor of the same size and data type as values, initialized with zeros\n    dense_tensor = torch.zeros(size, dtype=values.dtype)\n    # Convert indices to a tuple of tensors\n    indices_tuple = tuple(indices[i] for i in range(indices.shape[0]))\n    # Use index_put_ to put the values in the dense tensor at the right indices\n    dense_tensor.index_put_(indices_tuple, values, accumulate=False)\n    return dense_tensor\n\n\nto_dense(A_coo_pytorch)\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nCSR is an even more efficient compact format for sparse data. Details can be found here.\nValues and column indices are stored in the same way as COO format. The row indices are stored in a separate array, which can seem strange at first glance.\nBroadly it relies on slicing the values into per row chunks. The row chunk lengths are calculated as the difference between the row indices of the non-zero elements. The row chunk lengths are stored in a separate array, row_ptr.\nSo, if your original matrix has m rows, n columns, and nnz non-zero values, then:\n\nThe shape of values is [nnz].\nThe shape of column_indices is [nnz].\nThe shape of row_pointers is [m+1].\n\nIn index notation, the row pointer array is defined as:\nrow_ptr[i] = row_ptr[i-1] + number of non-zero elements in row i-1\nSo, the row pointer array stores the cumulative sum of the number of non-zero elements in each row.\nthe row and column number can be determined by the index of the non-zero element in the values array. That is the i-th non-zero element (in the values array) is at row row_ptr[i] and column col[i]. That is:\nvalues[i] = A[row_ptr[i], col[i]]\n\nA_torch.to_sparse_csr()\n\n/var/folders/p9/vwq0gfs15vb07tg6xw1r14180000gn/T/ipykernel_58234/2480968404.py:1: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n  A_torch.to_sparse_csr()\n\n\ntensor(crow_indices=tensor([0, 2, 3, 4, 5, 6]),\n       col_indices=tensor([1, 2, 0, 0, 4, 3]),\n       values=tensor([True, True, True, True, True, True]), size=(5, 5), nnz=6,\n       layout=torch.sparse_csr)\n\n\nWhich can be recovered by chaining with the .to_dense() method.\n\nA_torch.to_sparse_csr().to_dense()\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nAnd here we write our homebrew version of to_csr() and from_csr() functions:\n\ndef to_csr(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor, as_tuple=True)\n    # Get the values of the non-zero elements\n    values = tensor[indices]\n    # Get the column indices of the non-zero elements\n    column_indices = indices[1]\n    # Get the row pointers\n    row_pointers = torch.zeros(tensor.size(0) + 1, dtype=torch.long)\n    row_pointers[1:] = torch.bincount(indices[0])\n    row_pointers = torch.cumsum(row_pointers, dim=0)\n\n    return values, column_indices, row_pointers\n\n\nto_csr(A_torch)\n\n(tensor([True, True, True, True, True, True]),\n tensor([1, 2, 0, 0, 4, 3]),\n tensor([0, 2, 3, 4, 5, 6]))\n\n\n\ndef from_csr(values, column_indices, row_pointers):\n    # Get the number of rows and columns\n    num_rows = row_pointers.size(0) - 1\n    num_cols = torch.max(column_indices).item() + 1\n    # Create a dense tensor of the right size, initialized with zeros\n    tensor = torch.zeros((num_rows, num_cols), dtype=values.dtype)\n    # Loop over the rows\n    for i in range(num_rows):\n        # Get the start and end indices for this row in the values and column_indices arrays\n        start = row_pointers[i].item()\n        end = row_pointers[i + 1].item()\n        # Set the values in the dense tensor for this row\n        tensor[i, column_indices[start:end]] = values[start:end]\n\n    return tensor\n\n\nfrom_csr(*to_csr(A_torch))\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nThe CSC format is similar to the CSR format, but with the rows and columns swapped. The values and row indices are stored in the same way as the CSR format. The column indices are stored in a separate array, col_ptr.\nThis format is efficient for certain slicing operations, such as extracting a column from a matrix.\n\n\n\n\nLetâ€™s see how much faster it is to perform matrix multiplication on the sparse tensor compared to the dense tensor. For this weâ€™ll use the ModelNet10 monitor graph seen earlier.\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\nA = nx.adjacency_matrix(G)\nA\n\n&lt;798x798 sparse array of type '&lt;class 'numpy.int64'&gt;'\n    with 2952 stored elements in Compressed Sparse Row format&gt;\n\n\nA is already a sparse matrix, but in numpy. Weâ€™ll convert it to a PyTorch dense tensor first.\n\nA_dense = torch.from_numpy(A.toarray())\nA_dense.shape\n\ntorch.Size([798, 798])\n\n\n\ndef tensor_memory_usage_str(tensor=None):\n    if tensor is None:\n        return \"No tensor provided\"\n    bytes = tensor.element_size() * tensor.nelement()\n    kilobytes = bytes / 1024\n    return f\"Memory usage: {bytes} bytes ({kilobytes} KB)\"\n\n\ntensor_memory_usage_str(A_dense)\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\n\ntensor_memory_usage_str(A_dense.to_sparse())\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nSomewhat unexpectedly, the sparse and dense tensors have the same memory usage.\n\nA_sparse = A_dense.to_sparse_csr()\nA_sparse\n\ntensor(crow_indices=tensor([   0,    5,    8,   10,   13,   17,   21,   25,\n                              29,   33,   37,   41,   45,   49,   53,   57,\n                              61,   65,   69,   73,   77,   81,   85,   89,\n                              93,   98,  101,  104,  106,  110,  114,  118,\n                             121,  123,  126,  130,  134,  138,  142,  146,\n                             150,  154,  158,  162,  166,  170,  174,  177,\n                             179,  181,  184,  188,  192,  196,  200,  204,\n                             208,  212,  216,  220,  224,  228,  232,  235,\n                             239,  243,  246,  250,  254,  258,  262,  266,\n                             270,  274,  278,  282,  286,  289,  291,  295,\n                             298,  302,  306,  310,  314,  318,  322,  326,\n                             330,  332,  334,  336,  338,  345,  350,  354,\n                             360,  370,  374,  379,  384,  388,  393,  399,\n                             402,  415,  423,  426,  428,  433,  440,  446,\n                             450,  459,  463,  468,  473,  477,  482,  487,\n                             491,  494,  496,  499,  509,  513,  516,  520,\n                             525,  530,  534,  539,  544,  548,  554,  558,\n                             567,  571,  573,  577,  581,  586,  591,  596,\n                             601,  605,  610,  614,  623,  627,  630,  634,\n                             637,  640,  643,  648,  652,  655,  658,  662,\n                             665,  668,  681,  685,  688,  691,  694,  698,\n                             701,  704,  707,  711,  714,  717,  721,  723,\n                             727,  731,  735,  740,  743,  747,  751,  755,\n                             759,  762,  764,  767,  771,  775,  777,  781,\n                             785,  790,  793,  797,  801,  805,  809,  812,\n                             814,  817,  821,  823,  827,  831,  835,  840,\n                             843,  847,  851,  855,  859,  862,  864,  868,\n                             871,  873,  877,  881,  885,  890,  893,  897,\n                             901,  905,  909,  912,  914,  918,  921,  923,\n                             927,  931,  935,  939,  943,  947,  951,  955,\n                             959,  963,  967,  971,  975,  979,  983,  987,\n                             991,  995,  999, 1002, 1004, 1006, 1009, 1013,\n                            1017, 1021, 1025, 1029, 1033, 1037, 1041, 1045,\n                            1049, 1053, 1057, 1061, 1065, 1069, 1073, 1077,\n                            1081, 1085, 1089, 1092, 1094, 1097, 1102, 1104,\n                            1107, 1110, 1113, 1116, 1118, 1120, 1123, 1128,\n                            1132, 1139, 1142, 1145, 1148, 1152, 1156, 1160,\n                            1164, 1168, 1171, 1174, 1176, 1178, 1181, 1187,\n                            1190, 1196, 1200, 1203, 1208, 1212, 1216, 1220,\n                            1222, 1224, 1227, 1230, 1232, 1234, 1238, 1241,\n                            1243, 1246, 1248, 1251, 1256, 1260, 1264, 1268,\n                            1272, 1276, 1280, 1284, 1289, 1292, 1296, 1301,\n                            1305, 1309, 1315, 1318, 1320, 1323, 1326, 1328,\n                            1330, 1333, 1336, 1338, 1340, 1345, 1354, 1357,\n                            1360, 1364, 1375, 1378, 1381, 1385, 1388, 1391,\n                            1394, 1397, 1400, 1403, 1406, 1409, 1411, 1415,\n                            1420, 1424, 1428, 1432, 1436, 1440, 1444, 1448,\n                            1452, 1456, 1460, 1464, 1468, 1472, 1476, 1480,\n                            1484, 1488, 1492, 1496, 1499, 1501, 1505, 1512,\n                            1516, 1520, 1524, 1528, 1532, 1536, 1540, 1544,\n                            1548, 1552, 1556, 1560, 1564, 1568, 1572, 1576,\n                            1580, 1584, 1588, 1591, 1593, 1606, 1609, 1612,\n                            1615, 1618, 1621, 1624, 1627, 1630, 1633, 1636,\n                            1638, 1641, 1644, 1646, 1648, 1651, 1655, 1657,\n                            1665, 1668, 1671, 1674, 1677, 1680, 1682, 1684,\n                            1692, 1695, 1698, 1701, 1704, 1707, 1711, 1714,\n                            1716, 1720, 1723, 1725, 1728, 1730, 1732, 1736,\n                            1739, 1742, 1744, 1747, 1751, 1753, 1757, 1761,\n                            1766, 1769, 1773, 1777, 1781, 1785, 1789, 1793,\n                            1797, 1801, 1805, 1809, 1813, 1817, 1821, 1825,\n                            1828, 1830, 1832, 1836, 1839, 1843, 1847, 1851,\n                            1855, 1859, 1863, 1867, 1871, 1875, 1879, 1883,\n                            1887, 1891, 1896, 1899, 1903, 1907, 1911, 1914,\n                            1916, 1920, 1925, 1928, 1931, 1933, 1935, 1939,\n                            1942, 1947, 1950, 1953, 1957, 1959, 1963, 1967,\n                            1972, 1975, 1979, 1983, 1987, 1991, 1995, 1999,\n                            2003, 2007, 2011, 2015, 2019, 2023, 2027, 2031,\n                            2035, 2039, 2043, 2047, 2051, 2055, 2059, 2063,\n                            2067, 2071, 2075, 2079, 2083, 2087, 2092, 2095,\n                            2099, 2103, 2107, 2110, 2112, 2116, 2121, 2124,\n                            2127, 2129, 2131, 2135, 2138, 2143, 2146, 2149,\n                            2153, 2155, 2159, 2163, 2168, 2171, 2175, 2179,\n                            2183, 2187, 2191, 2195, 2199, 2203, 2207, 2211,\n                            2215, 2219, 2223, 2227, 2231, 2235, 2239, 2243,\n                            2247, 2251, 2255, 2259, 2263, 2267, 2271, 2275,\n                            2279, 2283, 2288, 2291, 2295, 2299, 2303, 2306,\n                            2308, 2311, 2315, 2317, 2321, 2325, 2330, 2333,\n                            2337, 2341, 2345, 2349, 2353, 2357, 2361, 2365,\n                            2369, 2373, 2377, 2381, 2385, 2389, 2392, 2394,\n                            2396, 2400, 2403, 2407, 2411, 2415, 2419, 2423,\n                            2427, 2431, 2435, 2439, 2443, 2447, 2451, 2455,\n                            2460, 2463, 2467, 2471, 2475, 2478, 2480, 2483,\n                            2487, 2489, 2493, 2497, 2502, 2505, 2509, 2513,\n                            2517, 2521, 2525, 2529, 2533, 2537, 2541, 2545,\n                            2549, 2553, 2557, 2561, 2564, 2566, 2568, 2572,\n                            2575, 2579, 2583, 2587, 2591, 2595, 2599, 2603,\n                            2607, 2611, 2615, 2619, 2623, 2627, 2632, 2635,\n                            2639, 2643, 2647, 2650, 2652, 2655, 2659, 2661,\n                            2665, 2669, 2674, 2677, 2681, 2685, 2689, 2693,\n                            2697, 2701, 2705, 2709, 2713, 2717, 2721, 2725,\n                            2729, 2733, 2736, 2738, 2740, 2744, 2747, 2751,\n                            2755, 2759, 2763, 2767, 2771, 2775, 2779, 2783,\n                            2787, 2791, 2795, 2799, 2804, 2807, 2811, 2815,\n                            2819, 2822, 2824, 2828, 2831, 2833, 2839, 2842,\n                            2845, 2848, 2850, 2853, 2856, 2858, 2860, 2862,\n                            2865, 2868, 2870, 2873, 2876, 2878, 2880, 2883,\n                            2886, 2888, 2890, 2893, 2896, 2898, 2900, 2902,\n                            2904, 2906, 2908, 2910, 2912, 2915, 2918, 2920,\n                            2922, 2924, 2927, 2930, 2932, 2932, 2932, 2934,\n                            2937, 2940, 2942, 2945, 2948, 2950, 2952]),\n       col_indices=tensor([  1,   2,   3,  ..., 795, 794, 795]),\n       values=tensor([1, 1, 1,  ..., 1, 1, 1]), size=(798, 798), nnz=2952,\n       layout=torch.sparse_csr)\n\n\n\ntensor_memory_usage_str(A_sparse)\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nOK, so there was no improvement in memory usage for this particular case. Letâ€™s time the matrix multiplication operations.\n\nimport timeit\n\ndef multiply_tensors():\n    return A_dense @ A_dense\n\nnum_runs = 10\ntime_taken_dense = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken} seconds\")\n\nTime taken by my_function over 10 runs: 2.5863237919984385 seconds\n\n\n\nimport timeit\n\nA_coo = A\n\ndef multiply_tensors():\n    return A_coo@A_coo\n\nnum_runs = 10\ntime_taken_sparse = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken} seconds\")\n\nTime taken by my_function over 10 runs: 2.5863237919984385 seconds\n\n\nThatâ€™s almost 1000x difference when using coo encoding.\nWith CSR encoding of sparse tensors, it might be even better - however Iâ€™m on Apple Silicon, and the csr sparse tensor support is not yet available for this architecture.\n\n\n\nWe just saw how to work with sparse tensors in PyTorch. We created a sparse tensor from an adjacency matrix and a list of edges, and converted it to different sparse formats. We also saw the performance benefits of using sparse tensors for matrix multiplication. Thereâ€™s a lot more to sparsity, and PyTorch is actively developing its sparse tensor support. Things will break, but expect ramp up in performance gains."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#introduction",
    "href": "posts/sparse_tensors/index.html#introduction",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "The canonical format for representing tensors in PyTorch is the dense tensor, with associated contiguous memory proportional to the size of the tensor. However, in many applications, the data is sparse, that is most of the elements are zero. In this notebook, we will see how to work efficiently with sparse tensors in PyTorch.\n\n\nA dataset is considered sparse when most of its elements are zero, for some features of the dataset. The exact threshold for considering a dataset as sparse is not strictly defined and can depend on the context and the specific application. A common rule of thumb is that a dataset is sparse if over 50% of its elements are zero.\nIn many real-world applications, datasets can be extremely sparse, with over 90% or even 99% of elements being zero. For example, in a user-item interaction matrix in a recommendation system, each user typically interacts with only a small fraction of all possible items, so the vast majority of the matrix elements are zero.\nIn PyTorch, datasets are stored in tensors. A tensor is a multi-dimensional array, similar to a NumPy array. PyTorch provides some support for sparse tensors.\n\n\n\nIn a dense tensor, all elements are stored in memory, even if most of them are zero. In a sparse tensor, only the non-zero elements are stored, along with their indices. This can lead to significant memory savings and/or faster compute times, especially for very sparse datasets.\nFor several tasks which are computing on the tensor, sparse tensors can be more efficient than dense tensors. For example, consider matrix multiplication. If the matrices are sparse, then sparse tensors can be orders of magnitude faster than dense tensors - as we will demonstrate at the end.\n\n\n\nIn PyTorch there are several ways to create sparse tensors as containers for sparse data. We will see how to create a sparse tensor from a dense tensor, and how to create a sparse tensor from different formats: COO, CSR, and CSC.\nFirst weâ€™ll need example data to work with - letâ€™s use a graph dataset as an example to understand sparse tensors."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#example-graph-data",
    "href": "posts/sparse_tensors/index.html#example-graph-data",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Graph data is a commonly sparse. A graph is a collection of nodes (or vertices) and edges. The nodes represent entities, and the edges represent relationships between the entities. More often than not, graphs are sparse, i.e.Â most of the nodes are not connected to each other. It is common to see datasets where less than 1% of the possible edges are present.\nThere are many ways to represent a Graph. One common is an adjacency matrix, A. This is particularly bad for sparse graphs, as most of the elements in the matrix are zero.\nThe adjacency matrix is a square matrix A, of size N x N, where N is the number of nodes in the graph. The element A[i, j] is 1 if there is an edge between node i and node j, and 0 otherwise. Since most nodes are not connected to each other, the adjacency matrix is sparse.\nAnother more memory-efficient way to represent a graph is using a tensor of edges, E. Each edge is represented as a 2 long column (r, s) in E, where r and s are the indices of the nodes connected by the edge. This representation is more memory-efficient than the adjacency matrix, as it only stores the non-zero elements, itâ€™s size is 2 x number_edges.\nIn this notebook, we will see how to create a sparse tensor from an adjacency matrix, and how to create a sparse tensor from a list of edges. We will also see how to perform basic operations on sparse tensors, such as matrix multiplication and element-wise operations.\nLetâ€™s consider an example from the ModelNet10 dataset.\n\n\nModelNet10 is a subset of the ModelNet dataset, which is a large-scale 3D CAD model dataset. ModelNet10 specifically consists of 10 categories, with a total of 4899 3D CAD models. The categories include: bed, chair, monitor, desk, dresser, sofa, table, toilet, night stand, and bathtub.\nEach 3D model in the dataset is represented as a graph, where each node represents a point in the 3D object, and each edge represents a relationship between the points. The adjacency matrix of the graph is sparse, as most of the points are not connected to each other.\nThis dataset is commonly used for benchmarking in tasks such as 3D object recognition, shape classification, and other machine learning tasks involving 3D data.\nLetâ€™s look at a one: a Monitor from the training dataset. Weâ€™ll need to install some libraries to visualize the 3D object.\n\n!pip -q install numpy matplotlib networkx\n\nThe data is in off format - that is nodes and edges making faces. The particular file can be found here. The corners of the monitor are the nodes and the edges are the connections between the corners. Hereâ€™s a plot using matplotlib and another with trimesh.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\ndef read_off(file):\n    if 'OFF' != file.readline().strip():\n        raise('Not a valid OFF header')\n    n_verts, n_faces, _ = tuple(map(int, file.readline().strip().split(' ')))\n    verts = [[float(s) for s in file.readline().strip().split(' ')] for _ in range(n_verts)]\n    faces = [[int(s) for s in file.readline().strip().split(' ')[1:]] for _ in range(n_faces)]\n    return verts, faces\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Create a Poly3DCollection object\npolys = [np.array(verts)[face] for face in faces]\ncollection = Poly3DCollection(polys, linewidths=1, alpha=1)\ncollection.set_facecolor((0,0,1,0.5))  # Set the color of the object to blue\ncollection.set_edgecolor((0,0,1,0.5))  # Set the edge color to a darker blue\nax.add_collection3d(collection)\n\n# Add lighting\nax.add_collection3d(Poly3DCollection(polys, facecolors='r', linewidths=1, edgecolors='r', alpha=.20))\n\n# Remove the axes for a cleaner look\nax.axis('off')\n\n# Auto scale to the mesh size\nscale = np.array(verts).flatten()\nax.auto_scale_xyz(scale, scale, scale)\n\n# Add a title to the plot\nax.set_title('3D Model of Monitor')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npip -q install trimesh\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport trimesh\n\n# Load the mesh from the OFF file\nmesh = trimesh.load_mesh('./data/monitor_0001.off')\n\n# Plot the mesh\nmesh.show()\n\n\n\n\nTo see this data as a graph, we will feed in vertices and faces into the networkx package.\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\ndef off_to_graph(verts, faces):\n    # Create a new graph\n    G = nx.Graph()\n    # Add nodes to the graph\n    for i in range(len(verts)):\n        G.add_node(i)\n    # Add edges to the graph\n    for face in faces:\n        for i in range(len(face)):\n            # Add an edge between each pair of vertices in the face\n            G.add_edge(face[i], face[(i+1)%len(face)])\n    return G\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\n\n\nprint(G)\n\nGraph with 798 nodes and 1476 edges\n\n\n\n# Draw the graph\nnx.draw(G, edge_color=\"black\", width=1, node_size=5, with_labels=False)\nplt.show()\n\n\n\n\n\n\n\n\nSo, thatâ€™s the graph. Itâ€™s difficult to make out the shape of the monitor from the plot above, as weâ€™re not representing the features of the nodes (3d co-ordinates).\nWhat we can do is list out the edges and vertices of the graph. First in edge list format with the corresponding nodes.\n\nG.edges()\n\nEdgeView([(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (3, 4), (4, 5), (4, 6), (5, 6), (5, 7), (6, 7), (6, 8), (7, 8), (7, 9), (8, 9), (8, 10), (9, 10), (9, 11), (10, 11), (10, 12), (11, 12), (11, 13), (12, 13), (12, 14), (13, 14), (13, 15), (14, 15), (14, 16), (15, 16), (15, 17), (16, 17), (16, 18), (17, 18), (17, 19), (18, 19), (18, 20), (19, 20), (19, 21), (20, 21), (20, 22), (21, 22), (21, 23), (22, 23), (22, 24), (23, 24), (23, 25), (24, 25), (24, 26), (24, 27), (25, 26), (26, 27), (28, 29), (28, 30), (28, 31), (28, 32), (29, 30), (29, 85), (29, 87), (30, 31), (30, 87), (31, 32), (33, 34), (33, 35), (33, 88), (34, 35), (34, 88), (34, 36), (35, 36), (35, 37), (36, 37), (36, 38), (37, 38), (37, 39), (38, 39), (38, 40), (39, 40), (39, 41), (40, 41), (40, 42), (41, 42), (41, 43), (42, 43), (42, 44), (43, 44), (43, 45), (44, 45), (44, 46), (45, 46), (45, 47), (46, 47), (48, 49), (48, 50), (49, 50), (49, 51), (50, 52), (50, 51), (51, 52), (51, 53), (52, 54), (52, 53), (53, 54), (53, 55), (54, 56), (54, 55), (55, 56), (55, 57), (56, 58), (56, 57), (57, 58), (57, 59), (58, 60), (58, 59), (59, 60), (59, 61), (60, 62), (60, 61), (61, 62), (61, 89), (62, 89), (63, 64), (63, 65), (63, 66), (63, 90), (64, 65), (64, 67), (64, 66), (65, 90), (66, 67), (66, 68), (67, 69), (67, 68), (68, 69), (68, 70), (69, 71), (69, 70), (70, 71), (70, 72), (71, 73), (71, 72), (72, 73), (72, 74), (73, 75), (73, 74), (74, 75), (74, 76), (75, 77), (75, 76), (76, 77), (78, 79), (78, 80), (78, 81), (78, 82), (79, 80), (79, 91), (80, 91), (80, 82), (81, 82), (81, 83), (81, 84), (82, 84), (83, 84), (83, 85), (83, 86), (84, 86), (85, 86), (85, 87), (86, 87), (92, 93), (92, 94), (92, 95), (92, 147), (92, 148), (92, 170), (92, 171), (93, 94), (93, 95), (93, 96), (93, 97), (94, 147), (94, 146), (95, 96), (95, 148), (95, 149), (95, 150), (96, 97), (96, 98), (96, 150), (96, 151), (96, 152), (96, 153), (96, 154), (96, 104), (97, 98), (97, 99), (98, 99), (98, 100), (98, 104), (99, 100), (99, 101), (99, 102), (100, 101), (100, 104), (101, 102), (101, 103), (101, 104), (102, 103), (102, 104), (102, 105), (102, 106), (103, 104), (104, 105), (104, 119), (104, 154), (104, 112), (104, 114), (104, 116), (104, 117), (105, 106), (105, 107), (105, 119), (105, 118), (105, 120), (105, 121), (106, 107), (108, 109), (108, 110), (108, 111), (108, 134), (108, 135), (109, 110), (109, 111), (109, 112), (109, 155), (109, 157), (109, 158), (110, 135), (110, 155), (110, 156), (110, 166), (111, 112), (111, 113), (112, 113), (112, 114), (112, 158), (112, 159), (112, 160), (112, 154), (113, 114), (113, 115), (114, 115), (114, 116), (115, 116), (115, 117), (115, 118), (116, 117), (117, 118), (117, 119), (118, 119), (118, 120), (120, 121), (122, 123), (122, 124), (122, 125), (123, 124), (123, 125), (123, 126), (123, 127), (123, 136), (123, 138), (123, 139), (123, 161), (123, 141), (124, 136), (124, 137), (125, 126), (126, 127), (126, 128), (127, 128), (127, 129), (127, 161), (128, 129), (128, 130), (128, 131), (129, 130), (129, 161), (130, 131), (130, 132), (130, 161), (131, 132), (131, 133), (131, 134), (132, 133), (132, 161), (133, 134), (133, 135), (133, 161), (133, 162), (134, 135), (135, 162), (135, 163), (135, 164), (135, 165), (135, 166), (136, 137), (136, 138), (138, 139), (138, 140), (139, 140), (139, 141), (140, 141), (140, 142), (140, 143), (141, 142), (141, 161), (142, 143), (142, 144), (142, 161), (143, 144), (143, 145), (143, 146), (144, 145), (144, 161), (145, 146), (145, 147), (145, 161), (146, 147), (147, 161), (147, 167), (147, 168), (147, 169), (147, 170), (148, 149), (148, 171), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 160), (155, 156), (155, 157), (156, 166), (157, 158), (158, 159), (159, 160), (161, 162), (161, 167), (162, 163), (163, 164), (164, 165), (165, 166), (167, 168), (168, 169), (169, 170), (170, 171), (172, 173), (172, 174), (172, 175), (173, 174), (173, 175), (173, 176), (175, 176), (175, 177), (176, 177), (176, 178), (177, 178), (177, 179), (178, 179), (178, 180), (178, 181), (179, 180), (180, 181), (180, 182), (181, 182), (181, 183), (182, 183), (182, 184), (183, 184), (183, 185), (184, 185), (186, 187), (186, 188), (186, 189), (187, 188), (187, 189), (187, 190), (188, 190), (188, 191), (190, 191), (190, 192), (191, 192), (191, 193), (192, 193), (192, 194), (192, 195), (193, 194), (194, 195), (194, 196), (195, 196), (195, 197), (196, 197), (196, 198), (197, 198), (197, 199), (198, 199), (200, 201), (200, 202), (200, 203), (201, 202), (201, 203), (201, 204), (203, 204), (203, 205), (204, 205), (204, 206), (205, 206), (205, 207), (206, 207), (206, 208), (206, 209), (207, 208), (208, 209), (208, 210), (209, 210), (209, 211), (210, 211), (210, 212), (211, 212), (211, 213), (212, 213), (214, 215), (214, 216), (214, 217), (214, 218), (215, 216), (215, 217), (217, 218), (217, 219), (218, 219), (218, 220), (219, 220), (219, 221), (220, 221), (220, 222), (220, 223), (221, 222), (222, 223), (222, 224), (223, 224), (223, 225), (224, 225), (224, 226), (225, 226), (225, 227), (226, 227), (228, 229), (228, 230), (228, 231), (228, 232), (229, 230), (229, 231), (231, 232), (231, 233), (232, 233), (232, 234), (233, 234), (233, 235), (234, 235), (234, 236), (235, 236), (235, 237), (236, 237), (236, 238), (237, 238), (237, 239), (238, 239), (238, 240), (239, 240), (239, 241), (240, 241), (240, 242), (241, 242), (241, 243), (242, 243), (242, 244), (243, 244), (243, 245), (244, 245), (244, 246), (245, 246), (245, 247), (246, 247), (246, 248), (247, 248), (247, 249), (248, 249), (248, 250), (249, 250), (249, 251), (250, 251), (252, 253), (252, 254), (253, 254), (253, 255), (254, 255), (254, 256), (255, 256), (255, 257), (256, 257), (256, 258), (257, 258), (257, 259), (258, 259), (258, 260), (259, 260), (259, 261), (260, 261), (260, 262), (261, 262), (261, 263), (262, 263), (262, 264), (263, 264), (263, 265), (264, 265), (264, 266), (265, 266), (265, 267), (266, 267), (266, 268), (267, 268), (267, 269), (268, 269), (268, 270), (269, 270), (269, 271), (270, 271), (270, 272), (271, 272), (271, 273), (272, 273), (272, 274), (273, 274), (273, 275), (274, 275), (276, 277), (276, 278), (276, 279), (277, 278), (277, 279), (277, 280), (277, 312), (279, 280), (280, 312), (281, 282), (281, 283), (281, 284), (282, 283), (282, 284), (285, 286), (285, 287), (285, 288), (286, 287), (286, 288), (286, 289), (286, 295), (287, 295), (287, 296), (288, 289), (288, 290), (288, 291), (288, 292), (288, 293), (289, 290), (290, 291), (291, 292), (292, 293), (292, 294), (293, 294), (293, 296), (294, 295), (294, 296), (295, 296), (297, 298), (297, 299), (297, 300), (298, 299), (298, 300), (301, 302), (301, 303), (301, 304), (302, 303), (302, 304), (302, 305), (302, 306), (302, 308), (303, 305), (304, 306), (304, 307), (304, 310), (304, 311), (305, 308), (305, 309), (306, 307), (307, 308), (307, 309), (307, 310), (308, 309), (309, 310), (310, 311), (313, 314), (313, 315), (313, 316), (314, 315), (314, 316), (317, 318), (317, 319), (317, 320), (317, 321), (318, 319), (318, 320), (320, 321), (322, 323), (322, 324), (322, 325), (323, 324), (323, 325), (323, 326), (323, 336), (324, 336), (324, 337), (325, 326), (325, 327), (326, 327), (326, 328), (327, 328), (327, 329), (328, 329), (328, 330), (329, 330), (329, 331), (330, 331), (330, 332), (331, 332), (331, 333), (331, 334), (332, 333), (333, 334), (333, 335), (334, 335), (334, 337), (334, 338), (335, 336), (335, 337), (336, 337), (337, 338), (337, 339), (338, 339), (340, 341), (340, 342), (340, 343), (341, 342), (341, 343), (344, 345), (344, 346), (344, 347), (345, 346), (345, 347), (348, 349), (348, 350), (348, 351), (348, 352), (348, 353), (349, 350), (349, 351), (349, 354), (349, 355), (349, 356), (349, 367), (349, 366), (349, 390), (350, 354), (351, 352), (352, 353), (352, 357), (353, 357), (353, 358), (353, 359), (353, 360), (353, 361), (353, 362), (353, 363), (353, 364), (353, 365), (354, 355), (355, 356), (356, 390), (356, 412), (357, 358), (358, 359), (359, 360), (360, 361), (361, 362), (362, 363), (363, 364), (364, 365), (366, 367), (366, 368), (366, 369), (367, 368), (367, 390), (367, 389), (368, 369), (368, 370), (369, 370), (369, 371), (370, 371), (370, 372), (371, 372), (371, 373), (372, 373), (372, 374), (373, 374), (373, 375), (374, 375), (374, 376), (375, 376), (375, 377), (376, 377), (376, 378), (377, 378), (377, 379), (378, 379), (378, 380), (379, 380), (379, 381), (380, 381), (380, 382), (381, 382), (381, 383), (382, 383), (382, 384), (383, 384), (383, 385), (384, 385), (384, 386), (385, 386), (385, 387), (386, 387), (386, 388), (387, 388), (389, 390), (389, 391), (389, 392), (390, 391), (390, 412), (390, 413), (391, 392), (391, 393), (392, 393), (392, 394), (393, 394), (393, 395), (394, 395), (394, 396), (395, 396), (395, 397), (396, 397), (396, 398), (397, 398), (397, 399), (398, 399), (398, 400), (399, 400), (399, 401), (400, 401), (400, 402), (401, 402), (401, 403), (402, 403), (402, 404), (403, 404), (403, 405), (404, 405), (404, 406), (405, 406), (405, 407), (406, 407), (406, 408), (407, 408), (407, 409), (408, 409), (408, 410), (409, 410), (409, 411), (410, 411), (412, 413), (412, 414), (412, 415), (412, 416), (412, 417), (412, 418), (412, 419), (412, 420), (412, 421), (412, 422), (412, 423), (413, 414), (414, 415), (415, 416), (416, 417), (417, 418), (418, 419), (419, 420), (420, 421), (421, 422), (422, 423), (424, 425), (424, 426), (424, 427), (425, 426), (425, 427), (428, 429), (428, 430), (428, 431), (429, 430), (429, 431), (429, 432), (431, 432), (431, 433), (431, 434), (431, 435), (431, 436), (431, 437), (432, 433), (433, 434), (434, 435), (435, 436), (436, 437), (438, 439), (438, 440), (439, 440), (439, 441), (439, 442), (439, 443), (439, 444), (439, 445), (439, 446), (440, 441), (441, 442), (442, 443), (443, 444), (444, 445), (445, 446), (445, 447), (446, 447), (448, 449), (448, 450), (448, 451), (448, 452), (449, 450), (449, 451), (451, 452), (453, 454), (453, 455), (454, 455), (454, 456), (454, 457), (455, 456), (456, 457), (458, 459), (458, 460), (458, 461), (459, 460), (459, 461), (459, 462), (461, 462), (461, 463), (462, 463), (462, 464), (463, 464), (463, 465), (463, 466), (464, 465), (465, 466), (465, 467), (466, 467), (466, 468), (467, 468), (467, 469), (468, 469), (468, 470), (469, 470), (469, 471), (470, 471), (470, 472), (471, 472), (471, 473), (472, 473), (472, 474), (473, 474), (473, 475), (474, 475), (474, 476), (475, 476), (475, 477), (476, 477), (476, 478), (477, 478), (477, 479), (478, 479), (478, 480), (479, 480), (481, 482), (481, 483), (482, 483), (482, 484), (482, 485), (483, 484), (484, 485), (484, 486), (485, 486), (485, 487), (486, 487), (486, 488), (487, 488), (487, 489), (488, 489), (488, 490), (489, 490), (489, 491), (490, 491), (490, 492), (491, 492), (491, 493), (492, 493), (492, 494), (493, 494), (493, 495), (494, 495), (494, 496), (495, 496), (495, 497), (496, 497), (496, 498), (497, 498), (497, 499), (497, 500), (498, 499), (499, 500), (499, 501), (500, 501), (500, 502), (501, 502), (501, 503), (502, 503), (504, 505), (504, 506), (504, 507), (504, 508), (505, 506), (505, 507), (505, 534), (505, 533), (506, 534), (507, 508), (509, 510), (509, 511), (510, 511), (510, 512), (510, 513), (511, 512), (512, 513), (512, 535), (512, 536), (513, 535), (514, 515), (514, 516), (514, 517), (515, 516), (515, 517), (515, 518), (517, 518), (517, 519), (518, 519), (518, 520), (519, 520), (519, 521), (519, 522), (520, 521), (521, 522), (521, 523), (522, 523), (522, 524), (523, 524), (523, 525), (524, 525), (524, 526), (525, 526), (525, 527), (526, 527), (526, 528), (527, 528), (527, 529), (528, 529), (528, 530), (529, 530), (529, 531), (530, 531), (530, 532), (531, 532), (531, 533), (532, 533), (532, 534), (533, 534), (535, 536), (535, 537), (536, 537), (536, 538), (537, 538), (537, 539), (538, 539), (538, 540), (539, 540), (539, 541), (540, 541), (540, 542), (541, 542), (541, 543), (542, 543), (542, 544), (543, 544), (543, 545), (544, 545), (544, 546), (545, 546), (545, 547), (546, 547), (546, 548), (547, 548), (547, 549), (548, 549), (548, 550), (549, 550), (549, 551), (549, 552), (550, 551), (551, 552), (551, 553), (552, 553), (552, 554), (553, 554), (553, 555), (554, 555), (556, 557), (556, 558), (556, 559), (556, 560), (557, 558), (557, 559), (557, 586), (557, 585), (558, 586), (559, 560), (561, 562), (561, 563), (562, 563), (562, 564), (562, 565), (563, 564), (564, 565), (564, 587), (564, 588), (565, 587), (566, 567), (566, 568), (566, 569), (567, 568), (567, 569), (567, 570), (569, 570), (569, 571), (570, 571), (570, 572), (571, 572), (571, 573), (571, 574), (572, 573), (573, 574), (573, 575), (574, 575), (574, 576), (575, 576), (575, 577), (576, 577), (576, 578), (577, 578), (577, 579), (578, 579), (578, 580), (579, 580), (579, 581), (580, 581), (580, 582), (581, 582), (581, 583), (582, 583), (582, 584), (583, 584), (583, 585), (584, 585), (584, 586), (585, 586), (587, 588), (587, 589), (588, 589), (588, 590), (589, 590), (589, 591), (590, 591), (590, 592), (591, 592), (591, 593), (592, 593), (592, 594), (593, 594), (593, 595), (594, 595), (594, 596), (595, 596), (595, 597), (596, 597), (596, 598), (597, 598), (597, 599), (598, 599), (598, 600), (599, 600), (599, 601), (600, 601), (600, 602), (601, 602), (601, 603), (601, 604), (602, 603), (603, 604), (603, 605), (604, 605), (604, 606), (605, 606), (605, 607), (606, 607), (608, 609), (608, 610), (608, 611), (609, 610), (609, 611), (609, 612), (611, 612), (611, 613), (612, 613), (612, 614), (613, 614), (613, 615), (613, 616), (614, 615), (615, 616), (615, 617), (616, 617), (616, 618), (617, 618), (617, 619), (618, 619), (618, 620), (619, 620), (619, 621), (620, 621), (620, 622), (621, 622), (621, 623), (622, 623), (622, 624), (623, 624), (623, 625), (624, 625), (624, 626), (625, 626), (625, 627), (626, 627), (626, 628), (627, 628), (627, 629), (628, 629), (628, 630), (629, 630), (631, 632), (631, 633), (632, 633), (632, 634), (632, 635), (633, 634), (634, 635), (634, 636), (635, 636), (635, 637), (636, 637), (636, 638), (637, 638), (637, 639), (638, 639), (638, 640), (639, 640), (639, 641), (640, 641), (640, 642), (641, 642), (641, 643), (642, 643), (642, 644), (643, 644), (643, 645), (644, 645), (644, 646), (645, 646), (645, 647), (646, 647), (646, 648), (647, 648), (647, 649), (647, 650), (648, 649), (649, 650), (649, 651), (650, 651), (650, 652), (651, 652), (651, 653), (652, 653), (654, 655), (654, 656), (654, 657), (655, 656), (655, 657), (655, 658), (657, 658), (657, 659), (658, 659), (658, 660), (659, 660), (659, 661), (659, 662), (660, 661), (661, 662), (661, 663), (662, 663), (662, 664), (663, 664), (663, 665), (664, 665), (664, 666), (665, 666), (665, 667), (666, 667), (666, 668), (667, 668), (667, 669), (668, 669), (668, 670), (669, 670), (669, 671), (670, 671), (670, 672), (671, 672), (671, 673), (672, 673), (672, 674), (673, 674), (673, 675), (674, 675), (674, 676), (675, 676), (677, 678), (677, 679), (678, 679), (678, 680), (678, 681), (679, 680), (680, 681), (680, 682), (681, 682), (681, 683), (682, 683), (682, 684), (683, 684), (683, 685), (684, 685), (684, 686), (685, 686), (685, 687), (686, 687), (686, 688), (687, 688), (687, 689), (688, 689), (688, 690), (689, 690), (689, 691), (690, 691), (690, 692), (691, 692), (691, 693), (692, 693), (692, 694), (693, 694), (693, 695), (693, 696), (694, 695), (695, 696), (695, 697), (696, 697), (696, 698), (697, 698), (697, 699), (698, 699), (700, 701), (700, 702), (700, 703), (701, 702), (701, 703), (701, 704), (703, 704), (703, 705), (704, 705), (704, 706), (705, 706), (705, 707), (705, 708), (706, 707), (707, 708), (707, 709), (708, 709), (708, 710), (709, 710), (709, 711), (710, 711), (710, 712), (711, 712), (711, 713), (712, 713), (712, 714), (713, 714), (713, 715), (714, 715), (714, 716), (715, 716), (715, 717), (716, 717), (716, 718), (717, 718), (717, 719), (718, 719), (718, 720), (719, 720), (719, 721), (720, 721), (720, 722), (721, 722), (723, 724), (723, 725), (724, 725), (724, 726), (724, 727), (725, 726), (726, 727), (726, 728), (727, 728), (727, 729), (728, 729), (728, 730), (729, 730), (729, 731), (730, 731), (730, 732), (731, 732), (731, 733), (732, 733), (732, 734), (733, 734), (733, 735), (734, 735), (734, 736), (735, 736), (735, 737), (736, 737), (736, 738), (737, 738), (737, 739), (738, 739), (738, 740), (739, 740), (739, 741), (739, 742), (740, 741), (741, 742), (741, 743), (742, 743), (742, 744), (743, 744), (743, 745), (744, 745), (746, 747), (746, 748), (746, 749), (746, 750), (747, 748), (747, 749), (749, 750), (749, 751), (749, 752), (749, 753), (750, 751), (751, 752), (752, 753), (754, 755), (754, 756), (754, 757), (755, 756), (755, 757), (758, 759), (758, 760), (759, 760), (759, 761), (760, 761), (762, 763), (762, 764), (762, 765), (763, 764), (763, 765), (766, 767), (766, 768), (766, 769), (767, 768), (767, 769), (770, 771), (770, 772), (770, 773), (771, 772), (771, 773), (774, 775), (774, 776), (775, 776), (777, 778), (777, 779), (778, 779), (780, 781), (780, 782), (780, 783), (781, 782), (781, 783), (784, 785), (784, 786), (785, 786), (785, 787), (786, 787), (790, 791), (790, 792), (791, 792), (791, 793), (792, 793), (794, 795), (794, 796), (794, 797), (795, 796), (795, 797)])\n\n\n\nG.nodes()\n\nNodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797))\n\n\nAnd then as a an adjacency matrix.\n\nA = nx.to_numpy_array(G)\n\n\nA.shape\n\n(798, 798)\n\n\n\nprint(A)\n\n[[0. 1. 1. ... 0. 0. 0.]\n [1. 0. 1. ... 0. 0. 0.]\n [1. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 1. 1.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]]\n\n\nLetâ€™s verify that the number of edges match the adjacency matrix.\n\nA.sum() / 2\n\n1476.0\n\n\n\nA.sum()/2 == len(G.edges()) # The number of edges.\n\nTrue"
  },
  {
    "objectID": "posts/sparse_tensors/index.html#sparse-adjacency",
    "href": "posts/sparse_tensors/index.html#sparse-adjacency",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "The adjacency is sparse. We can quantify this sparsity - the ratio of the number of non-zero elements to the total number of elements in the tensor.\n\n# the ratio of the number of non-zero elements to the total number of elements in the tensor A.\nnp.count_nonzero(A) / (A.shape[0] * A.shape[1])\n\n0.004635649273559839\n\n\nStoring data in this format is inefficient. We can convert it to a sparse tensor. Weâ€™ll create functions for popular formats, as well as look at the native PyTorch implementations."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#sparse-formats",
    "href": "posts/sparse_tensors/index.html#sparse-formats",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Some well known sparse tensor representation formats are:\n\nCoordinate (COO)\nCompressed Sparse Row (CSR)\nCompressed Sparse Column (CSC)\nBlock Compressed Sparse Row (BSR)\nDictionary of Keys (DOK)\nList of Lists (LIL)\n\nWeâ€™ll look at COO, CSR, and CSC formats.\nThe monitor graph is too large and sparse for illustration purposes. Weâ€™ll create a smaller graph to demonstrate the conversion back and forth to sparse tensors.\n\n# Create a new graph\nG = nx.Graph()\n\n# Add some edges to the graph\nG.add_edge(0, 1)\nG.add_edge(0, 2)\nG.add_edge(3, 4)\n\n# Draw the graph\nnx.draw(G, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\npip -q install torch\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport torch\n\nA = nx.to_numpy_array(G)\nprint(torch.from_numpy(A))\nA_torch = torch.from_numpy(A).bool()\nA_torch\n\ntensor([[0., 1., 1., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0.]], dtype=torch.float64)\n\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\nA.sum()/2\n\n3.0\n\n\nLetâ€™s express as a pandas dataframe with source and target nodes for edges.\n\npip -q install pandas\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport pandas as pd\nimport numpy as np\n\n# Get the number of nodes\nnum_nodes = A_torch.shape[0]\n\n# Create a list of all pairs of nodes\nsource_node, destination_node = np.meshgrid(np.arange(num_nodes), np.arange(num_nodes))\n\n# Flatten the arrays\nsource_node = source_node.flatten()\ndestination_node = destination_node.flatten()\n\n# Get the edge values\nhas_edge = A_torch[source_node, destination_node] &gt; 0\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\n\ndf\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n0\nFalse\n\n\n1\n1\n0\nTrue\n\n\n2\n2\n0\nTrue\n\n\n3\n3\n0\nFalse\n\n\n4\n4\n0\nFalse\n\n\n5\n0\n1\nTrue\n\n\n6\n1\n1\nFalse\n\n\n7\n2\n1\nFalse\n\n\n8\n3\n1\nFalse\n\n\n9\n4\n1\nFalse\n\n\n10\n0\n2\nTrue\n\n\n11\n1\n2\nFalse\n\n\n12\n2\n2\nFalse\n\n\n13\n3\n2\nFalse\n\n\n14\n4\n2\nFalse\n\n\n15\n0\n3\nFalse\n\n\n16\n1\n3\nFalse\n\n\n17\n2\n3\nFalse\n\n\n18\n3\n3\nFalse\n\n\n19\n4\n3\nTrue\n\n\n20\n0\n4\nFalse\n\n\n21\n1\n4\nFalse\n\n\n22\n2\n4\nFalse\n\n\n23\n3\n4\nTrue\n\n\n24\n4\n4\nFalse\n\n\n\n\n\n\n\n\n\nThe COO format is simple and flexible for sparse matrices. It consists of three arrays: row, col, and data. The row array contains the row indices of the non-zero elements, the col array contains the column indices of the non-zero elements, and the data array contains the values of the non-zero elements.\nLuckily, PyTorch has built in methods for converting between dense and sparse tensors. We can convert the adjacency matrix to a COO sparse tensor using the .to_sparse() method.\n\nA_coo_pytorch = A_torch.to_sparse()\nA_coo_pytorch\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\nAnd convert back\n\nA_coo_pytorch.to_dense()\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nLetâ€™s look at the sparse tensor as a dataframe of source to destination nodes, but this time only for those pairs where there is an edge.\n\n# Get the source and destination nodes and the edge values\nsource_node = A_coo_pytorch.indices()[0].numpy()\ndestination_node = A_coo_pytorch.indices()[1].numpy()\nhas_edge = A_coo_pytorch.values().numpy()\n\n# Create the DataFrame\ndf = pd.DataFrame({\n    'source_node': source_node,\n    'destination_node': destination_node,\n    'has_edge': has_edge\n})\ndf\n\n\n\n\n\n\n\n\nsource_node\ndestination_node\nhas_edge\n\n\n\n\n0\n0\n1\nTrue\n\n\n1\n0\n2\nTrue\n\n\n2\n1\n0\nTrue\n\n\n3\n2\n0\nTrue\n\n\n4\n3\n4\nTrue\n\n\n5\n4\n3\nTrue\n\n\n\n\n\n\n\nWriting our own homebrew function to convert to COO format, is straightforward.\n\ndef to_sparse(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor).t()\n    # Get the values of the non-zero elements\n    values = tensor[indices[0], indices[1]]  # assuming 2D tensor\n    # Get the size of the original tensor\n    size = tensor.size()\n    # Create a sparse tensor\n    sparse_tensor = torch.sparse_coo_tensor(indices, values, size)\n    return sparse_tensor\n\n\nto_sparse(A_torch)\n\ntensor(indices=tensor([[0, 0, 1, 2, 3, 4],\n                       [1, 2, 0, 0, 4, 3]]),\n       values=tensor([True, True, True, True, True, True]),\n       size=(5, 5), nnz=6, layout=torch.sparse_coo)\n\n\n\ndef to_dense(sparse_tensor):\n    # Get the size of the original tensor\n    size = sparse_tensor.size()\n    # Get the indices and values from the sparse tensor\n    indices = sparse_tensor.coalesce().indices()\n    values = sparse_tensor.coalesce().values()\n    # Create a dense tensor of the same size and data type as values, initialized with zeros\n    dense_tensor = torch.zeros(size, dtype=values.dtype)\n    # Convert indices to a tuple of tensors\n    indices_tuple = tuple(indices[i] for i in range(indices.shape[0]))\n    # Use index_put_ to put the values in the dense tensor at the right indices\n    dense_tensor.index_put_(indices_tuple, values, accumulate=False)\n    return dense_tensor\n\n\nto_dense(A_coo_pytorch)\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nCSR is an even more efficient compact format for sparse data. Details can be found here.\nValues and column indices are stored in the same way as COO format. The row indices are stored in a separate array, which can seem strange at first glance.\nBroadly it relies on slicing the values into per row chunks. The row chunk lengths are calculated as the difference between the row indices of the non-zero elements. The row chunk lengths are stored in a separate array, row_ptr.\nSo, if your original matrix has m rows, n columns, and nnz non-zero values, then:\n\nThe shape of values is [nnz].\nThe shape of column_indices is [nnz].\nThe shape of row_pointers is [m+1].\n\nIn index notation, the row pointer array is defined as:\nrow_ptr[i] = row_ptr[i-1] + number of non-zero elements in row i-1\nSo, the row pointer array stores the cumulative sum of the number of non-zero elements in each row.\nthe row and column number can be determined by the index of the non-zero element in the values array. That is the i-th non-zero element (in the values array) is at row row_ptr[i] and column col[i]. That is:\nvalues[i] = A[row_ptr[i], col[i]]\n\nA_torch.to_sparse_csr()\n\n/var/folders/p9/vwq0gfs15vb07tg6xw1r14180000gn/T/ipykernel_58234/2480968404.py:1: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n  A_torch.to_sparse_csr()\n\n\ntensor(crow_indices=tensor([0, 2, 3, 4, 5, 6]),\n       col_indices=tensor([1, 2, 0, 0, 4, 3]),\n       values=tensor([True, True, True, True, True, True]), size=(5, 5), nnz=6,\n       layout=torch.sparse_csr)\n\n\nWhich can be recovered by chaining with the .to_dense() method.\n\nA_torch.to_sparse_csr().to_dense()\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\nAnd here we write our homebrew version of to_csr() and from_csr() functions:\n\ndef to_csr(tensor):\n    # Get the indices of the non-zero elements\n    indices = torch.nonzero(tensor, as_tuple=True)\n    # Get the values of the non-zero elements\n    values = tensor[indices]\n    # Get the column indices of the non-zero elements\n    column_indices = indices[1]\n    # Get the row pointers\n    row_pointers = torch.zeros(tensor.size(0) + 1, dtype=torch.long)\n    row_pointers[1:] = torch.bincount(indices[0])\n    row_pointers = torch.cumsum(row_pointers, dim=0)\n\n    return values, column_indices, row_pointers\n\n\nto_csr(A_torch)\n\n(tensor([True, True, True, True, True, True]),\n tensor([1, 2, 0, 0, 4, 3]),\n tensor([0, 2, 3, 4, 5, 6]))\n\n\n\ndef from_csr(values, column_indices, row_pointers):\n    # Get the number of rows and columns\n    num_rows = row_pointers.size(0) - 1\n    num_cols = torch.max(column_indices).item() + 1\n    # Create a dense tensor of the right size, initialized with zeros\n    tensor = torch.zeros((num_rows, num_cols), dtype=values.dtype)\n    # Loop over the rows\n    for i in range(num_rows):\n        # Get the start and end indices for this row in the values and column_indices arrays\n        start = row_pointers[i].item()\n        end = row_pointers[i + 1].item()\n        # Set the values in the dense tensor for this row\n        tensor[i, column_indices[start:end]] = values[start:end]\n\n    return tensor\n\n\nfrom_csr(*to_csr(A_torch))\n\ntensor([[False,  True,  True, False, False],\n        [ True, False, False, False, False],\n        [ True, False, False, False, False],\n        [False, False, False, False,  True],\n        [False, False, False,  True, False]])\n\n\n\n\n\nThe CSC format is similar to the CSR format, but with the rows and columns swapped. The values and row indices are stored in the same way as the CSR format. The column indices are stored in a separate array, col_ptr.\nThis format is efficient for certain slicing operations, such as extracting a column from a matrix."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#memory-usage-speed-up-with-sparse-tensors-on-the-monitor-graph",
    "href": "posts/sparse_tensors/index.html#memory-usage-speed-up-with-sparse-tensors-on-the-monitor-graph",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "Letâ€™s see how much faster it is to perform matrix multiplication on the sparse tensor compared to the dense tensor. For this weâ€™ll use the ModelNet10 monitor graph seen earlier.\n\nwith open('./data/monitor_0001.off', 'r') as f:\n    verts, faces = read_off(f)\n\nG = off_to_graph(verts, faces)\nA = nx.adjacency_matrix(G)\nA\n\n&lt;798x798 sparse array of type '&lt;class 'numpy.int64'&gt;'\n    with 2952 stored elements in Compressed Sparse Row format&gt;\n\n\nA is already a sparse matrix, but in numpy. Weâ€™ll convert it to a PyTorch dense tensor first.\n\nA_dense = torch.from_numpy(A.toarray())\nA_dense.shape\n\ntorch.Size([798, 798])\n\n\n\ndef tensor_memory_usage_str(tensor=None):\n    if tensor is None:\n        return \"No tensor provided\"\n    bytes = tensor.element_size() * tensor.nelement()\n    kilobytes = bytes / 1024\n    return f\"Memory usage: {bytes} bytes ({kilobytes} KB)\"\n\n\ntensor_memory_usage_str(A_dense)\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\n\ntensor_memory_usage_str(A_dense.to_sparse())\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nSomewhat unexpectedly, the sparse and dense tensors have the same memory usage.\n\nA_sparse = A_dense.to_sparse_csr()\nA_sparse\n\ntensor(crow_indices=tensor([   0,    5,    8,   10,   13,   17,   21,   25,\n                              29,   33,   37,   41,   45,   49,   53,   57,\n                              61,   65,   69,   73,   77,   81,   85,   89,\n                              93,   98,  101,  104,  106,  110,  114,  118,\n                             121,  123,  126,  130,  134,  138,  142,  146,\n                             150,  154,  158,  162,  166,  170,  174,  177,\n                             179,  181,  184,  188,  192,  196,  200,  204,\n                             208,  212,  216,  220,  224,  228,  232,  235,\n                             239,  243,  246,  250,  254,  258,  262,  266,\n                             270,  274,  278,  282,  286,  289,  291,  295,\n                             298,  302,  306,  310,  314,  318,  322,  326,\n                             330,  332,  334,  336,  338,  345,  350,  354,\n                             360,  370,  374,  379,  384,  388,  393,  399,\n                             402,  415,  423,  426,  428,  433,  440,  446,\n                             450,  459,  463,  468,  473,  477,  482,  487,\n                             491,  494,  496,  499,  509,  513,  516,  520,\n                             525,  530,  534,  539,  544,  548,  554,  558,\n                             567,  571,  573,  577,  581,  586,  591,  596,\n                             601,  605,  610,  614,  623,  627,  630,  634,\n                             637,  640,  643,  648,  652,  655,  658,  662,\n                             665,  668,  681,  685,  688,  691,  694,  698,\n                             701,  704,  707,  711,  714,  717,  721,  723,\n                             727,  731,  735,  740,  743,  747,  751,  755,\n                             759,  762,  764,  767,  771,  775,  777,  781,\n                             785,  790,  793,  797,  801,  805,  809,  812,\n                             814,  817,  821,  823,  827,  831,  835,  840,\n                             843,  847,  851,  855,  859,  862,  864,  868,\n                             871,  873,  877,  881,  885,  890,  893,  897,\n                             901,  905,  909,  912,  914,  918,  921,  923,\n                             927,  931,  935,  939,  943,  947,  951,  955,\n                             959,  963,  967,  971,  975,  979,  983,  987,\n                             991,  995,  999, 1002, 1004, 1006, 1009, 1013,\n                            1017, 1021, 1025, 1029, 1033, 1037, 1041, 1045,\n                            1049, 1053, 1057, 1061, 1065, 1069, 1073, 1077,\n                            1081, 1085, 1089, 1092, 1094, 1097, 1102, 1104,\n                            1107, 1110, 1113, 1116, 1118, 1120, 1123, 1128,\n                            1132, 1139, 1142, 1145, 1148, 1152, 1156, 1160,\n                            1164, 1168, 1171, 1174, 1176, 1178, 1181, 1187,\n                            1190, 1196, 1200, 1203, 1208, 1212, 1216, 1220,\n                            1222, 1224, 1227, 1230, 1232, 1234, 1238, 1241,\n                            1243, 1246, 1248, 1251, 1256, 1260, 1264, 1268,\n                            1272, 1276, 1280, 1284, 1289, 1292, 1296, 1301,\n                            1305, 1309, 1315, 1318, 1320, 1323, 1326, 1328,\n                            1330, 1333, 1336, 1338, 1340, 1345, 1354, 1357,\n                            1360, 1364, 1375, 1378, 1381, 1385, 1388, 1391,\n                            1394, 1397, 1400, 1403, 1406, 1409, 1411, 1415,\n                            1420, 1424, 1428, 1432, 1436, 1440, 1444, 1448,\n                            1452, 1456, 1460, 1464, 1468, 1472, 1476, 1480,\n                            1484, 1488, 1492, 1496, 1499, 1501, 1505, 1512,\n                            1516, 1520, 1524, 1528, 1532, 1536, 1540, 1544,\n                            1548, 1552, 1556, 1560, 1564, 1568, 1572, 1576,\n                            1580, 1584, 1588, 1591, 1593, 1606, 1609, 1612,\n                            1615, 1618, 1621, 1624, 1627, 1630, 1633, 1636,\n                            1638, 1641, 1644, 1646, 1648, 1651, 1655, 1657,\n                            1665, 1668, 1671, 1674, 1677, 1680, 1682, 1684,\n                            1692, 1695, 1698, 1701, 1704, 1707, 1711, 1714,\n                            1716, 1720, 1723, 1725, 1728, 1730, 1732, 1736,\n                            1739, 1742, 1744, 1747, 1751, 1753, 1757, 1761,\n                            1766, 1769, 1773, 1777, 1781, 1785, 1789, 1793,\n                            1797, 1801, 1805, 1809, 1813, 1817, 1821, 1825,\n                            1828, 1830, 1832, 1836, 1839, 1843, 1847, 1851,\n                            1855, 1859, 1863, 1867, 1871, 1875, 1879, 1883,\n                            1887, 1891, 1896, 1899, 1903, 1907, 1911, 1914,\n                            1916, 1920, 1925, 1928, 1931, 1933, 1935, 1939,\n                            1942, 1947, 1950, 1953, 1957, 1959, 1963, 1967,\n                            1972, 1975, 1979, 1983, 1987, 1991, 1995, 1999,\n                            2003, 2007, 2011, 2015, 2019, 2023, 2027, 2031,\n                            2035, 2039, 2043, 2047, 2051, 2055, 2059, 2063,\n                            2067, 2071, 2075, 2079, 2083, 2087, 2092, 2095,\n                            2099, 2103, 2107, 2110, 2112, 2116, 2121, 2124,\n                            2127, 2129, 2131, 2135, 2138, 2143, 2146, 2149,\n                            2153, 2155, 2159, 2163, 2168, 2171, 2175, 2179,\n                            2183, 2187, 2191, 2195, 2199, 2203, 2207, 2211,\n                            2215, 2219, 2223, 2227, 2231, 2235, 2239, 2243,\n                            2247, 2251, 2255, 2259, 2263, 2267, 2271, 2275,\n                            2279, 2283, 2288, 2291, 2295, 2299, 2303, 2306,\n                            2308, 2311, 2315, 2317, 2321, 2325, 2330, 2333,\n                            2337, 2341, 2345, 2349, 2353, 2357, 2361, 2365,\n                            2369, 2373, 2377, 2381, 2385, 2389, 2392, 2394,\n                            2396, 2400, 2403, 2407, 2411, 2415, 2419, 2423,\n                            2427, 2431, 2435, 2439, 2443, 2447, 2451, 2455,\n                            2460, 2463, 2467, 2471, 2475, 2478, 2480, 2483,\n                            2487, 2489, 2493, 2497, 2502, 2505, 2509, 2513,\n                            2517, 2521, 2525, 2529, 2533, 2537, 2541, 2545,\n                            2549, 2553, 2557, 2561, 2564, 2566, 2568, 2572,\n                            2575, 2579, 2583, 2587, 2591, 2595, 2599, 2603,\n                            2607, 2611, 2615, 2619, 2623, 2627, 2632, 2635,\n                            2639, 2643, 2647, 2650, 2652, 2655, 2659, 2661,\n                            2665, 2669, 2674, 2677, 2681, 2685, 2689, 2693,\n                            2697, 2701, 2705, 2709, 2713, 2717, 2721, 2725,\n                            2729, 2733, 2736, 2738, 2740, 2744, 2747, 2751,\n                            2755, 2759, 2763, 2767, 2771, 2775, 2779, 2783,\n                            2787, 2791, 2795, 2799, 2804, 2807, 2811, 2815,\n                            2819, 2822, 2824, 2828, 2831, 2833, 2839, 2842,\n                            2845, 2848, 2850, 2853, 2856, 2858, 2860, 2862,\n                            2865, 2868, 2870, 2873, 2876, 2878, 2880, 2883,\n                            2886, 2888, 2890, 2893, 2896, 2898, 2900, 2902,\n                            2904, 2906, 2908, 2910, 2912, 2915, 2918, 2920,\n                            2922, 2924, 2927, 2930, 2932, 2932, 2932, 2934,\n                            2937, 2940, 2942, 2945, 2948, 2950, 2952]),\n       col_indices=tensor([  1,   2,   3,  ..., 795, 794, 795]),\n       values=tensor([1, 1, 1,  ..., 1, 1, 1]), size=(798, 798), nnz=2952,\n       layout=torch.sparse_csr)\n\n\n\ntensor_memory_usage_str(A_sparse)\n\n'Memory usage: 5094432 bytes (4975.03125 KB)'\n\n\nOK, so there was no improvement in memory usage for this particular case. Letâ€™s time the matrix multiplication operations.\n\nimport timeit\n\ndef multiply_tensors():\n    return A_dense @ A_dense\n\nnum_runs = 10\ntime_taken_dense = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken} seconds\")\n\nTime taken by my_function over 10 runs: 2.5863237919984385 seconds\n\n\n\nimport timeit\n\nA_coo = A\n\ndef multiply_tensors():\n    return A_coo@A_coo\n\nnum_runs = 10\ntime_taken_sparse = timeit.timeit( multiply_tensors, number=num_runs)\n\nprint(f\"Time taken by my_function over {num_runs} runs: {time_taken} seconds\")\n\nTime taken by my_function over 10 runs: 2.5863237919984385 seconds\n\n\nThatâ€™s almost 1000x difference when using coo encoding.\nWith CSR encoding of sparse tensors, it might be even better - however Iâ€™m on Apple Silicon, and the csr sparse tensor support is not yet available for this architecture."
  },
  {
    "objectID": "posts/sparse_tensors/index.html#conclusion",
    "href": "posts/sparse_tensors/index.html#conclusion",
    "title": "Sparsity with PyTorch Tensors",
    "section": "",
    "text": "We just saw how to work with sparse tensors in PyTorch. We created a sparse tensor from an adjacency matrix and a list of edges, and converted it to different sparse formats. We also saw the performance benefits of using sparse tensors for matrix multiplication. Thereâ€™s a lot more to sparsity, and PyTorch is actively developing its sparse tensor support. Things will break, but expect ramp up in performance gains."
  }
]
