{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Model Speciation\"\n",
    "author: \"Ravi Kalia\"\n",
    "date: \"2024-09-19\"\n",
    "categories: [machine-learning, development, evolution]\n",
    "image: \"./ml_map.svg\"\n",
    "draft: true\n",
    "format:\n",
    "    html:\n",
    "        code-copy: true\n",
    "        code-fold: true \n",
    "        toc: true\n",
    "        toc-depth: 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection: An Evolutionary Perspective\n",
    "\n",
    "![\"A Graph of Model Species\"](./ml_map.svg)\n",
    "\n",
    "by <a href=\"https://scikit-learn.org/1.5/index.html\"> scikit-learn project </a> at <a href=\"https://scikit-learn.org/1.5/machine_learning_map.html\">Machine Learning Map</a>\n",
    "\n",
    "## TL;DR: Machine Learning Model Selection as Evolution\n",
    "\n",
    "Viewing machine learning through the lens of evolution:\n",
    "\n",
    "- **Proto-programs = protocells**: Basic building blocks of ML algorithms, like affine transformations, recursion, iteration, object templates; small modular reusable code pieces represent the \"simplest forms of life.\"\n",
    "- **Models = Species**: Each ML model (e.g., linear regression, neural networks) represents a distinct \"species\" in the ecosystem.\n",
    "- **Data = Environment**: The dataset shapes and tests models just as environments influence species' survival and adaptation.\n",
    "- **Training = Adaptation**: During training, models learn and adapt to better fit their data environment.\n",
    "- **Hyperparameter tuning = Sub-speciation**: Tuning hyperparameters is akin to the development of sub-species, where small variations emerge for optimization.\n",
    "- **Model selection = Survival of the fittest**: Only the best-performing models in a given environment (data) \"survive\" and are selected for deployment.\n",
    "\n",
    "This evolutionary perspective on model selection suggests that **phylogenetics** â€” the study of evolutionary relationships - could offer novel insights into understanding and categorizing machine learning model families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Evolutionary Analogy\n",
    "\n",
    "In the world of machine learning, the process of selecting and refining models can be complex and nuanced. To better understand this process, let's draw an analogy to biological evolution. This comparison can provide an intuitive framework for grasping the key concepts of model selection and optimization.\n",
    "\n",
    "\n",
    "### Proto-programs as protocells\n",
    "\n",
    "Simple programs or algorithms can be seen as the building blocks of more complex models. These proto-programs are like protocells in nature, capable of basic functions but not yet fully adapted to their environment.\n",
    "\n",
    "These would be the building blocks of more complex models, like the simplest organisms in nature, capable of basic functions but not yet fully adapted to their environment. Examples might be:\n",
    "\n",
    "* Tensor arithmetic\n",
    "* Branching logic\n",
    "* Basic object templates\n",
    "* Encapsulation\n",
    "* Recursion\n",
    "\n",
    "They combine to form more complex species, such as models - templates for a ML algorithm is run.\n",
    "\n",
    "### Models as Species\n",
    "\n",
    "Just as the natural world is populated by various species, the realm of machine learning is filled with different types of models. Each model type, like a species, has its own characteristics, strengths, and weaknesses. These models depend on receiving data and hyper-parameters, then learning parameters which mature to enable learned prediction function.\n",
    "\n",
    "### Model Instances as Complex Organisms\n",
    "\n",
    "Within each model type (species), we can create multiple instances. These instances are akin to individual organisms within a species. Each has its own set of parameters, just as organisms have their own genetic makeup.\n",
    "\n",
    "### Data as the Environment\n",
    "\n",
    "The data we use to train and evaluate our models serves as the environment in which our \"model organisms\" must survive and thrive. Different datasets present different resources and challenges, much like varied ecological niches in nature.\n",
    "\n",
    "### Training Loop as Organism Maturation\n",
    "\n",
    "The process of training a model is analogous to the maturation of an organism. Through repeated exposure to the data (environment), the model adjusts its parameters and improves its performance, much like an organism adapting to its surroundings as it grows.\n",
    "\n",
    "### Score Function as Survival Fitness\n",
    "\n",
    "In nature, organisms that are better adapted to their environment are more likely to survive. Similarly, in machine learning, we use a score function to evaluate how well a model performs. Models with better scores are more likely to be selected for further use or refinement.\n",
    "\n",
    "The score function does not depend on the model itself, but on the model's predictions vs observed reality relevant to some task of interest given the data. This is similar to how an organism's fitness is determined by its ability to survive in its habitat.\n",
    "\n",
    "### Hyperparameters as Creating Subspecies\n",
    "\n",
    "When we select the hyperparameters of a model, we're essentially creating a subspecies. These subspecies share the basic characteristics of the parent model but have unique traits that may make them better suited to certain types of data or problems.\n",
    "\n",
    "Default hyperparameters are like the default genetic code of an organism, while tuned hyperparameters are like genetic mutations that can lead to better adaptations.\n",
    "\n",
    "### Data Splitting as Creating Different Habitats\n",
    "\n",
    "The practice of splitting our data into training, validation, and test sets is akin to creating different habitats for our models:\n",
    "\n",
    "- **Training Data**: This is the primary environment where our model \"organisms\" mature and adapt.\n",
    "- **Validation Data**: This represents a similar but distinct habitat where we score each model's fitness, the best model selected to survive for downstream use. \n",
    "- **Test Data**: This is an unseen habitat to report unbiased fitness estimate of a selected model.\n",
    "\n",
    "### Best Scored Model as Natural Selection\n",
    "\n",
    "The process of selecting the best-performing model based on validation scores mirrors natural selection. The model that best adapts to both the training and validation environments is chosen to proceed to the test phase, much like the most fit organisms in nature are more likely to survive and change their environment.\n",
    "\n",
    "## Implications of the Evolutionary Perspective\n",
    "\n",
    "Viewing model selection through this evolutionary lens can provide several insights:\n",
    "\n",
    "1. **Diversity is Valuable**: Just as biodiversity is crucial in ecosystems, having a diverse set of models can be beneficial in machine learning. We just don't know a priori which model will be the best for a given dataset.\n",
    "\n",
    "2. **Adaptation is Key**: The best model for one dataset may not be the best for another, just as organisms adapted to one environment may struggle in a different one.\n",
    "\n",
    "3. **Overfitting as Over-specialization**: When a model performs well on training data but poorly on validation data, it's like an organism that's over-specialized for a very specific data environment and can't adapt to realistic changes in data.\n",
    "\n",
    "4. **Ensemble Methods as Ecosystems**: Ensemble methods, which combine multiple models, can be seen as creating a balanced ecosystem where different \"species\" of models cooperate to solve a problem.\n",
    "\n",
    "5. **Continuous Improvement**: The field of machine learning, like the process of evolution, is one of continuous adaptation and improvement as we develop new models and techniques.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "While the analogy between model selection and biological evolution isn't perfect, it provides a rich metaphor for understanding many aspects of the machine learning process. By thinking in these terms, we can gain new insights into how to approach model selection, hyperparameter tuning, and the overall process of developing effective machine learning solutions.\n",
    "\n",
    "It would be an interesting exercise to create a phylogenetic tree of models, showing how different models have evolved from simpler proto-programs and how they have adapted to different data environments over time. This could provide a fascinating perspective on the history and development of machine learning algorithms. Perhaps even find horizontal gene transfer between models, where ideas from one model are incorporated directly into another.\n",
    "\n",
    "From this perspective, geometric learning relates to encoding data regularities into model species internals, another way to view the inductive bias of a model.\n",
    "\n",
    "\n",
    "As a practical takeaway, expect that there is no perfect single model for all datasets and tasks, the best model is the one that is best adapted to the specific data environment at hand, while being able to generalize to similar environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
